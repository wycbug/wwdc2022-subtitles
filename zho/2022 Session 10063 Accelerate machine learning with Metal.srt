1
00:00:00,501 --> 00:00:08,509
♪ ♪

2
00:00:09,510 --> 00:00:12,913
Dhruva: 欢迎来到 WWDC 2022

3
00:00:12,946 --> 00:00:16,517
我叫 Dhruva 是一名 GPU 软件工程师

4
00:00:16,550 --> 00:00:21,522
今天 Matteo 和我将探索
今年在 Metal 中

5
00:00:21,555 --> 00:00:25,726
为机器学习引入的
所有新功能和增强功能

6
00:00:25,759 --> 00:00:29,730
机器学习训练是 ML 管线中

7
00:00:29,763 --> 00:00:31,665
计算最密集的过程

8
00:00:31,698 --> 00:00:37,371
由于其并行性
GPU 在 ML 工作负载方面表现出色

9
00:00:37,404 --> 00:00:41,074
Metal 机器学习 API
是通过一个

10
00:00:41,108 --> 00:00:44,811
叫做 Metal Performance Shaders
或者简写为 MPS 的框架公开的

11
00:00:44,845 --> 00:00:49,082
MPS 是一个高性能 GPU 元操作的集合

12
00:00:49,116 --> 00:00:53,387
用于图像处理 线性代数 光线跟踪

13
00:00:53,420 --> 00:00:56,290
和机器学习等各个领域

14
00:00:56,323 --> 00:01:00,460
这些 Metal 内核经过优化
可在我们的所有平台上

15
00:01:00,494 --> 00:01:02,362
提供最佳性能

16
00:01:02,396 --> 00:01:05,699
例如 MPSImageCanny 过滤器

17
00:01:05,732 --> 00:01:08,702
返回输入图像的边缘图

18
00:01:08,735 --> 00:01:12,773
这是图像分割 App 中的常见操作

19
00:01:12,806 --> 00:01:16,143
今年 Canny 滤波器处理

20
00:01:16,176 --> 00:01:21,181
4K 高分辨率图像的速度提高了八倍

21
00:01:21,215 --> 00:01:24,618
MPS Graph 是 GPU 的通用计算图

22
00:01:24,651 --> 00:01:28,188
基于 MPS 框架构建

23
00:01:28,222 --> 00:01:32,025
并扩展了对多维张量的支持

24
00:01:32,059 --> 00:01:35,429
我建议您观看上一个讲座 以获得更多

25
00:01:35,462 --> 00:01:38,532
关于如何使用
MPS Graph 的详细信息

26
00:01:38,565 --> 00:01:42,769
像 CoreML 和 Tensorflow 这样的
高层 ML 框架

27
00:01:42,803 --> 00:01:44,972
基于 MPS Graph 来实现

28
00:01:45,005 --> 00:01:48,809
您可以使用 TensorFlow Metal 插件

29
00:01:48,842 --> 00:01:51,411
在 GPU 上加速 TensorFlow 网络

30
00:01:51,445 --> 00:01:54,581
有关如何充分利用
TensorFlow 的更多信息

31
00:01:54,615 --> 00:01:57,417
请查看去年的讲座

32
00:01:57,451 --> 00:02:01,188
Matteo 和我将在这个讲座里
讨论三个主题

33
00:02:01,221 --> 00:02:06,727
首先 我将介绍 Apple GPU 支持的
最新 ML 框架

34
00:02:06,760 --> 00:02:07,828
PyTorch

35
00:02:07,861 --> 00:02:14,034
接下来 我将深入讨论
今年对 TensorFlow 所做的增强

36
00:02:14,067 --> 00:02:19,339
最后 Matteo 将介绍
MPS Graph 框架中的新功能

37
00:02:20,674 --> 00:02:25,913
我们非常高兴您现在能够
在 Mac GPUs 上

38
00:02:25,946 --> 00:02:27,948
加速 PyTorch 网络

39
00:02:27,981 --> 00:02:32,653
PyTorch 是一个流行的
开源机器学习框架

40
00:02:32,686 --> 00:02:37,057
PyTorch 社区中呼声最高的功能

41
00:02:37,090 --> 00:02:41,361
是支持 Apple 芯片上的 GPU 加速

42
00:02:41,395 --> 00:02:44,364
我们通过向 PyTorch 生态系统
引入新的 MPS 后端

43
00:02:44,398 --> 00:02:50,037
将 Metal 的能力带入 PyTorch

44
00:02:50,070 --> 00:02:56,210
这个后端将成为
PyTorch 1.12 官方版本的一部分

45
00:02:56,243 --> 00:03:00,380
MPS 后端实现了 PyTorch 操作内核

46
00:03:00,414 --> 00:03:02,749
以及运行时框架

47
00:03:02,783 --> 00:03:06,987
操作调用 MPS Graph 和 MPS

48
00:03:07,020 --> 00:03:10,424
运行时组件使用 Metal

49
00:03:10,457 --> 00:03:14,995
这使得 PyTorch 能够使用
MPS 的高效内核

50
00:03:15,028 --> 00:03:17,364
以及 Metal 的指令队列

51
00:03:17,397 --> 00:03:20,901
指令缓冲区和同步原语

52
00:03:22,336 --> 00:03:26,974
操作内核和
PyTorch MPS 运行时组件

53
00:03:27,007 --> 00:03:29,109
是开源代码的一部分

54
00:03:29,142 --> 00:03:32,579
合并到了官方的
PyTorch GitHub repo 中

55
00:03:32,613 --> 00:03:37,484
使用 MPS PyTorch 后端
是一个简单的三步过程

56
00:03:37,518 --> 00:03:40,854
首先 从 PyTorch 1.12 开始

57
00:03:40,888 --> 00:03:44,958
您可以使用
pip install torch 安装基础包

58
00:03:44,992 --> 00:03:49,329
这个包可以在官方 python
包存储库中找到

59
00:03:49,363 --> 00:03:53,033
有关环境设置和安装的更多详细信息

60
00:03:53,066 --> 00:03:57,237
请参阅
Metal Developer Resources 网页

61
00:03:57,271 --> 00:04:01,608
然后导入 PyTorch 并创建 MPS 设备

62
00:04:01,642 --> 00:04:04,945
如果 MPS 设备后端可用

63
00:04:04,978 --> 00:04:09,016
此代码段将使用该后端
否则将返回到 CPU

64
00:04:09,049 --> 00:04:14,621
最后一步是转换您的模型和输入
以使用 MPS 设备

65
00:04:14,655 --> 00:04:16,590
为了演示如何做到这一点

66
00:04:16,623 --> 00:04:19,493
我将使用一个示例 该示例在来自

67
00:04:19,526 --> 00:04:23,664
torchvision 预训练的
ResNet50 模型上运行推理

68
00:04:23,697 --> 00:04:27,301
默认情况下 该模型将在 CPU 上运行

69
00:04:27,334 --> 00:04:32,306
您可以使用 to 方法
将模型转换为使用 MPS 设备

70
00:04:32,339 --> 00:04:36,443
这确保了模型内部的中间张量

71
00:04:36,476 --> 00:04:39,813
也将使用加速的 MPS 后端

72
00:04:39,847 --> 00:04:42,249
最后 您可以运行模型了

73
00:04:42,282 --> 00:04:47,521
本示例将随机输入张量
传递给 MPS 模型

74
00:04:47,554 --> 00:04:51,592
默认情况下
所有张量都分配在 CPU 上

75
00:04:51,625 --> 00:04:53,694
为了使用 MPS 后端

76
00:04:53,727 --> 00:04:58,031
您还需要在此处提供 MPS 设备

77
00:04:58,065 --> 00:05:03,770
对这个张量的所有后续操作
都将在 GPU 上加速

78
00:05:03,804 --> 00:05:09,009
最后 将样本输入
传递给 MPS_model 以获得预测

79
00:05:09,042 --> 00:05:12,112
现在您已经知道了
如何使用 MPS 设备

80
00:05:12,145 --> 00:05:15,516
我将向您展示 PyTorch 的一个实例

81
00:05:15,549 --> 00:05:17,951
我一直想成为一名著名的艺术家

82
00:05:17,985 --> 00:05:21,889
所以我决定使用机器学习
和我的 GPU

83
00:05:21,922 --> 00:05:25,826
来帮助我使用 StyleTransfer 网络
创作艺术品

84
00:05:25,859 --> 00:05:30,564
这个网络允许您将不同的艺术风格
应用于一幅图像

85
00:05:30,597 --> 00:05:34,735
在本实例中 我们的目标是学习如何
将梵高在星夜中的风格

86
00:05:34,768 --> 00:05:37,437
应用于这张猫的照片

87
00:05:37,471 --> 00:05:41,575
借助新的 MPS 设备
您将能够使用 GPU

88
00:05:41,608 --> 00:05:45,312
更快地训练 PyTorch 网络

89
00:05:45,345 --> 00:05:48,615
为了演示这一点 我将在一台

90
00:05:48,649 --> 00:05:53,320
M1 Max 上同时
在 CPU 和 GPU 上训练这个网络

91
00:05:53,353 --> 00:05:56,857
学习这种风格需要数千次迭代

92
00:05:56,890 --> 00:06:01,929
但 GPU 能够在更短的时间内
收敛到一个合理的模型

93
00:06:03,897 --> 00:06:07,568
除了 StyleTransfer
我们还在所有 PyTorch 基准测试中

94
00:06:07,601 --> 00:06:10,137
看到了惊人的加速

95
00:06:10,170 --> 00:06:15,075
在 M1 Ultra 上
我们看到速度提高了 20 倍

96
00:06:15,108 --> 00:06:18,612
平均速度提高了 8.3 倍

97
00:06:18,645 --> 00:06:22,583
PyTorch 使机器学习模型的开发
变得很容易

98
00:06:22,616 --> 00:06:27,688
通过使用 Apple GPU 对其进行训练
您将节省大量时间

99
00:06:27,721 --> 00:06:33,727
接下来 我将深入讨论我们今年
对 TensorFlow 所做的所有增强

100
00:06:33,760 --> 00:06:37,331
从 Tensorflow 2.5 版开始

101
00:06:37,364 --> 00:06:40,200
Tensorflow Metal 加速就可以通过

102
00:06:40,234 --> 00:06:42,970
Tensorflow Metal 插件来使用了

103
00:06:43,003 --> 00:06:47,741
从那时起
又增加了一些附加功能和改进

104
00:06:47,774 --> 00:06:51,879
其中对训练的增强包括包括更大批量

105
00:06:51,912 --> 00:06:54,948
新的操作和定制操作支持

106
00:06:54,982 --> 00:06:58,452
RNN 改进和分布式训练

107
00:06:58,485 --> 00:07:00,854
TensorFlow Metal 插件版本

108
00:07:00,888 --> 00:07:04,091
与 TensorFlow 主要版本保持一致

109
00:07:04,124 --> 00:07:06,827
因此请确保更新
您的 TensorFlow 软件包

110
00:07:06,860 --> 00:07:10,397
以获得最新的功能和改进

111
00:07:10,430 --> 00:07:13,367
我们从更大批量开始

112
00:07:13,400 --> 00:07:17,938
今年 TensorFlow-Metal 的软件改进

113
00:07:17,971 --> 00:07:21,875
让您能够利用
Apple 芯片架构的独特优势

114
00:07:21,909 --> 00:07:26,513
此图显示了使用不同批量大小
训练 ResNet50 模型的

115
00:07:26,547 --> 00:07:28,782
加速效果

116
00:07:28,815 --> 00:07:33,587
数据显示 批量越大 性能越好

117
00:07:33,620 --> 00:07:38,659
因为每次梯度更新都更接近真实梯度

118
00:07:38,692 --> 00:07:41,461
Apple 芯片的统一内存架构

119
00:07:41,495 --> 00:07:45,999
允许您运行更大的网络或更大的批量

120
00:07:46,033 --> 00:07:49,670
现在您可以在单个
Mac Studio 上运行您的工作负载

121
00:07:49,703 --> 00:07:53,407
而不是将其拆分为一个云集群
这真的很棒

122
00:07:53,440 --> 00:07:57,311
Apple 芯片架构还具有高效能功耗比

123
00:07:57,344 --> 00:08:01,381
这意味着您的网络运行
比以往任何时候都更高效

124
00:08:01,415 --> 00:08:06,353
接下来我将谈谈新操作和自定义操作

125
00:08:06,386 --> 00:08:10,357
Tensorflow Metal
插件现在为各种新操作

126
00:08:10,390 --> 00:08:12,960
提供了 GPU 加速

127
00:08:12,993 --> 00:08:18,899
包括 argMin
all pack 以及 adadelta 等等

128
00:08:18,932 --> 00:08:22,569
但是如果您想要为 tensorflow API
当前不支持的操作

129
00:08:22,603 --> 00:08:26,073
提供 GPU 加速该怎么办呢

130
00:08:26,106 --> 00:08:30,844
为此 您需要创建一个自定义操作

131
00:08:30,878 --> 00:08:33,914
下面是一个简单的卷积网络

132
00:08:33,947 --> 00:08:36,149
运行两次迭代的示例

133
00:08:36,183 --> 00:08:40,387
时间线分别表示 GPU 和 CPU 上

134
00:08:40,420 --> 00:08:42,756
完成的工作

135
00:08:42,789 --> 00:08:46,460
网络先进行卷积
之后进行 maxpool-ing 运算

136
00:08:46,493 --> 00:08:50,230
然后进行 softmax 交叉熵损失运算

137
00:08:50,264 --> 00:08:53,033
所有这些操作都是通过 MPS Graph

138
00:08:53,066 --> 00:08:56,937
在 TensorFlow Metal 插件中
由 GPU 加速的

139
00:08:56,970 --> 00:09:00,507
但您可能希望使用自定义损失函数

140
00:09:00,541 --> 00:09:04,511
如果没有 MPS GPU 加速
来实现这一自定义损失

141
00:09:04,545 --> 00:09:08,782
则需要在 CPU 时间线上
执行这项工作

142
00:09:08,815 --> 00:09:13,687
这将引入同步开销并导致 GPU 饥饿状态

143
00:09:13,720 --> 00:09:18,926
通过在 GPU 上进行这种自定义损失
您可以获得更好的性能

144
00:09:18,959 --> 00:09:21,628
为了实现自定义操作

145
00:09:21,662 --> 00:09:26,500
您需要了解
TensorFlow MetalStream 协议

146
00:09:26,533 --> 00:09:31,405
这是用于编码 GPU 操作的协议

147
00:09:31,438 --> 00:09:35,576
MetalStream 会保留
对用于编码 GPU 内核的

148
00:09:35,609 --> 00:09:37,411
MTLCommandBuffer 的引用

149
00:09:37,444 --> 00:09:41,615
它还暴露出 dispatch_queue
以便在编码时用于

150
00:09:41,648 --> 00:09:45,786
CPU 端同步
因为可能有多个线程提交工作

151
00:09:45,819 --> 00:09:51,158
使用 commit 或 commitAndWait 方法
将工作提交给 GPU

152
00:09:51,191 --> 00:09:55,963
CommitAndWait 是一个调试工具
它会一直等待当前命令缓冲区完成

153
00:09:55,996 --> 00:09:59,666
这样您就可以观察序列化提交

154
00:09:59,700 --> 00:10:04,471
现在让我们看看如何使用
这些概念来实现自定义 op

155
00:10:04,505 --> 00:10:07,274
编写自定义操作有三个步骤

156
00:10:07,307 --> 00:10:09,877
首先是注册操作

157
00:10:09,910 --> 00:10:13,514
接下来 使用 MetalStream
实现该操作

158
00:10:13,547 --> 00:10:19,219
最后将操作导入训练脚本并开始使用

159
00:10:19,253 --> 00:10:22,189
我将从注册操作开始

160
00:10:22,222 --> 00:10:25,826
使用 TensorFlow 核心
公开的 REGISTER_OP 宏

161
00:10:25,859 --> 00:10:28,095
来指定 op 的语义

162
00:10:28,128 --> 00:10:32,165
以及如何在
TensorFlow Metal 插件中定义它

163
00:10:32,199 --> 00:10:36,603
接下来使用
TensorFlow_MetalStream 实现 op

164
00:10:36,637 --> 00:10:40,507
首先定义 compute 函数

165
00:10:40,541 --> 00:10:44,978
现在 在这个函数中
获取输入的 TensorFlow_Tensor 对象

166
00:10:45,012 --> 00:10:50,417
并定义输出 这可能需要分配

167
00:10:50,450 --> 00:10:55,022
然后使用 MetalStream 的命令缓冲区
创建一个编码器

168
00:10:55,055 --> 00:10:57,991
接下来 定义自定义 GPU 内核

169
00:10:58,025 --> 00:11:00,928
您的操作应该在 MetalStream

170
00:11:00,961 --> 00:11:02,763
提供的 dispatch_queue 中进行编码

171
00:11:02,796 --> 00:11:07,000
这确保了来自多个线程的提交
被序列化

172
00:11:08,802 --> 00:11:12,005
然后使用
TensorFlow_MetalStream 协议中

173
00:11:12,039 --> 00:11:14,374
提供的方法提交内核

174
00:11:16,143 --> 00:11:19,947
最后 删除对分配张量的引用

175
00:11:21,315 --> 00:11:27,955
最终 将操作导入到您的训练脚本中
开始使用它

176
00:11:27,988 --> 00:11:35,062
在这一步中 构建定制 op 的
共享动态库文件 zero_out.so

177
00:11:35,095 --> 00:11:37,130
有关如何构建和导入 .so 文件的信息

178
00:11:37,164 --> 00:11:41,235
请参阅 Metal Developer Resources

179
00:11:41,268 --> 00:11:45,172
此示例通过使用
TensorFlow load_op_library

180
00:11:45,205 --> 00:11:48,141
将操作导入到训练脚本中

181
00:11:48,175 --> 00:11:50,043
这是一个可选步骤

182
00:11:50,077 --> 00:11:52,746
现在 这就像一个 python 包装器

183
00:11:52,779 --> 00:11:56,884
我们的自定义 op
可以在训练脚本中调用

184
00:11:56,917 --> 00:12:00,687
接下来 我想给您看一个
有趣的应用例子

185
00:12:00,721 --> 00:12:04,024
叫做神经辐射场 或 NeRF

186
00:12:04,057 --> 00:12:08,328
我们编写了一个自定义操作
通过启用 GPU 加速

187
00:12:08,362 --> 00:12:12,766
实现更好的算法
从而提高了网络的性能

188
00:12:13,901 --> 00:12:18,472
NeRF 是一种用于合成
模型 3D 视图的网络

189
00:12:18,505 --> 00:12:23,710
为了训练 NeRF 从不同角度
获取一个物体的图像作为输入

190
00:12:23,744 --> 00:12:28,382
NeRF 网络由两个堆叠的
多层感知器组成

191
00:12:28,415 --> 00:12:32,819
输出模型的体积化表示

192
00:12:32,853 --> 00:12:35,956
实时训练的关键性能优化

193
00:12:35,989 --> 00:12:38,592
使用哈希表来实现

194
00:12:38,625 --> 00:12:43,564
更新的网络允许更小的多层感知器

195
00:12:43,597 --> 00:12:46,967
TensorFlow 本身不支持哈希表

196
00:12:47,000 --> 00:12:49,236
所以我们使用自定义 op 功能

197
00:12:49,269 --> 00:12:52,005
在 Metal 插件中实现它们

198
00:12:52,039 --> 00:12:58,011
哈希表的 GPU 加速
可以更快地训练 NeRF

199
00:12:58,045 --> 00:12:59,947
我将从这台 MacBook 开始

200
00:12:59,980 --> 00:13:03,817
运行原始的多层感知器实现过程

201
00:13:06,186 --> 00:13:10,724
为了呈现出合理的内容
我们至少需要 20 个 epoch

202
00:13:10,757 --> 00:13:13,727
但每个 epoch 大约需要 100 秒

203
00:13:13,760 --> 00:13:17,798
这意味着大约需要30分钟
才能看到一些东西

204
00:13:17,831 --> 00:13:22,636
因此 现在我将从预先训练的
检查点文件中重新开始训练

205
00:13:22,669 --> 00:13:26,073
该文件需要提前 30 分钟进行训练

206
00:13:26,106 --> 00:13:28,675
这要从 epoch 20 开始

207
00:13:28,709 --> 00:13:33,780
即使经过 30 分钟的训练
3D 模型也是模糊不清的

208
00:13:33,814 --> 00:13:37,017
网络需要更长的训练时间

209
00:13:37,050 --> 00:13:38,719
来学习更清晰的模型

210
00:13:38,752 --> 00:13:42,256
原有的两层堆叠多层感知器方法

211
00:13:42,289 --> 00:13:45,559
没有自定义哈希表 速度太慢

212
00:13:45,592 --> 00:13:49,363
现在 在这台 MacBook 上
我将推出使用自定义哈希表的

213
00:13:49,396 --> 00:13:52,299
优化版本

214
00:13:52,332 --> 00:13:57,037
这种实现过程已经能够
呈现更清晰的模型

215
00:13:57,070 --> 00:14:00,641
并且每个 epoch 仅需要 10 秒来学习

216
00:14:00,674 --> 00:14:02,910
有关该项目的更多信息

217
00:14:02,943 --> 00:14:07,981
请查看我们上传到
Metal Developer Resources 的示例代码

218
00:14:09,683 --> 00:14:13,253
NeRF 只是众多网络中的一个

219
00:14:13,287 --> 00:14:17,958
它展示了如何为您自己的
定制操作实现 GPU 加速

220
00:14:17,991 --> 00:14:20,727
从而使您的网络运行得非常快

221
00:14:20,761 --> 00:14:24,331
我期待着进一步了解

222
00:14:24,364 --> 00:14:26,400
您所做的所有创造性定制

223
00:14:26,433 --> 00:14:30,270
现在我想向您展示如何使用

224
00:14:30,304 --> 00:14:33,207
Apple GPU 来分布
ML 工作负载的训练

225
00:14:33,240 --> 00:14:35,976
为了分布工作负载的训练

226
00:14:36,009 --> 00:14:40,848
您可以在单独的流程中
运行训练脚本的多个实例

227
00:14:40,881 --> 00:14:45,018
其中每个进程评估模型的单个迭代

228
00:14:46,286 --> 00:14:50,090
每个进程将从中央数据存储中
读取数据

229
00:14:50,123 --> 00:14:55,662
之后 它将运行模型并计算模型梯度

230
00:14:55,696 --> 00:15:00,167
接下来 该进程将计算梯度的平均值
并相互通信

231
00:15:00,200 --> 00:15:06,073
以便在下一次迭代之前
每个进程都具有相同的梯度

232
00:15:06,106 --> 00:15:10,043
最后 模型被更新 您可以重复这个过程

233
00:15:10,077 --> 00:15:13,180
直到所有的迭代都结束

234
00:15:13,213 --> 00:15:15,415
为了在 TensorFlow 上演示这一点

235
00:15:15,449 --> 00:15:18,118
我将使用一个分布式训练的例子

236
00:15:18,151 --> 00:15:22,155
我将使用一个流行的开源框架
Horovod 来进行分布式训练

237
00:15:23,724 --> 00:15:27,194
Horovod 使用环形全归约算法

238
00:15:27,227 --> 00:15:31,064
在该算法中 N 个节点中的每个节点
与其两个对等节点

239
00:15:31,098 --> 00:15:34,101
进行多次通信

240
00:15:34,134 --> 00:15:37,938
使用这种通信方式
工作进程在每次迭代之前

241
00:15:37,971 --> 00:15:40,741
同步梯度

242
00:15:40,774 --> 00:15:44,211
我将使用四个通过
Thunderbolt 电缆相互连接的

243
00:15:44,244 --> 00:15:47,414
Mac Studio 来展示这一点

244
00:15:47,447 --> 00:15:53,120
在这个示例中 我将训练 ResNet
这是一个图像分类器

245
00:15:53,153 --> 00:15:58,025
每个 Mac Studio 旁边的柱状图
显示了训练此网络时

246
00:15:58,058 --> 00:15:59,793
GPU 的利用率

247
00:15:59,826 --> 00:16:04,665
对于单个 Mac Studio
性能约为每秒 200 张图像

248
00:16:04,698 --> 00:16:08,468
当我添加另一个通过 Thunderbolt
连接的 Mac Studio 时

249
00:16:08,502 --> 00:16:12,706
性能几乎翻了一番
达到每秒 400 张图像

250
00:16:12,739 --> 00:16:16,710
因为两个 GPU 都得到了充分利用

251
00:16:16,743 --> 00:16:19,713
最后 当我连接
两个以上的 Mac Studio 时

252
00:16:19,746 --> 00:16:24,051
性能提升到每秒 800 张图像

253
00:16:24,084 --> 00:16:28,322
受限于计算的训练工作负载
几乎是以线性扩展

254
00:16:30,090 --> 00:16:34,995
现在我们来看一下
TensorFlow 的分布式训练性能

255
00:16:35,028 --> 00:16:41,034
这个图表显示了一个 两个和四个
Mac Studio 的相对加速

256
00:16:41,068 --> 00:16:45,939
它们以环形拓扑连接
并使用最新的 TensorFlow Metal 插件

257
00:16:45,973 --> 00:16:48,442
和 Horovod 运行计算
绑定 TensorFlow 网络

258
00:16:48,475 --> 00:16:52,813
如 resNet 和 DistilBERT

259
00:16:52,846 --> 00:16:57,050
基础是单个 Mac Studio 上的性能

260
00:16:57,084 --> 00:17:02,422
该图显示 随着每个 GPU 的增加
网络性能会随之扩展

261
00:17:02,456 --> 00:17:05,859
因此您现在可以
在多个设备上使用 GPU

262
00:17:05,893 --> 00:17:07,394
以加快您的训练时间

263
00:17:07,427 --> 00:17:10,697
并充分利用所有 Apple 设备

264
00:17:12,032 --> 00:17:15,636
今年针对 TensorFlow 的所有改进

265
00:17:15,669 --> 00:17:19,373
和功能最终都体现在这张图表中

266
00:17:19,406 --> 00:17:21,542
该图表显示了
相对于 CPU 实现的性能

267
00:17:21,575 --> 00:17:24,344
未来还会有更多改进

268
00:17:24,378 --> 00:17:29,449
现在 Matteo 将分享
MPS Graph 框架中的新内容

269
00:17:30,184 --> 00:17:31,318
Matteo: 谢谢您 Dhruva

270
00:17:31,351 --> 00:17:35,756
大家好 我叫 Matteo
是一名 GPU 软件工程师

271
00:17:35,789 --> 00:17:41,028
PyTorch 和 TensorFlow
位于 MPS 图形框架之上

272
00:17:41,061 --> 00:17:45,199
反过来 MPS Graph 使用 MPS 框架

273
00:17:45,232 --> 00:17:50,103
提供的并行原语
来加速 GPU 上的工作

274
00:17:50,137 --> 00:17:54,241
今天我将讨论使用 MPS Graph

275
00:17:54,274 --> 00:17:58,979
进一步加速计算工作负载的两个功能

276
00:17:59,012 --> 00:18:02,216
首先 我将展示新的共享事件 API

277
00:18:02,249 --> 00:18:05,953
它允许您在两个Graph 之间同步工作

278
00:18:05,986 --> 00:18:08,922
接着 我将介绍新的操作

279
00:18:08,956 --> 00:18:13,060
您可以使用 MPS Graph
做更多的事情

280
00:18:13,093 --> 00:18:15,996
我将从共享事件 API 开始

281
00:18:16,029 --> 00:18:19,132
在同一个命令队列上运行应用

282
00:18:19,166 --> 00:18:22,736
可以确保工作负载之间的同步

283
00:18:22,769 --> 00:18:26,440
在本例中 保证计算工作负载

284
00:18:26,473 --> 00:18:29,209
总是在调度其他工作负载之前终止

285
00:18:29,243 --> 00:18:33,380
如后期处理和显示

286
00:18:33,413 --> 00:18:37,150
在这种情况下 您将在每个调用中

287
00:18:37,184 --> 00:18:39,753
利用 GPU 并行性

288
00:18:39,786 --> 00:18:44,358
然而 一些 App 可能会受益于
更多的并行性

289
00:18:44,391 --> 00:18:47,995
其中 GPU 的第一部分用于计算

290
00:18:48,028 --> 00:18:52,666
第二部分用于后处理和显示

291
00:18:52,699 --> 00:18:58,605
这可以通过在多个命令队列上
向 GPU 提交工作来实现

292
00:18:58,639 --> 00:19:01,975
不幸的是 在这种情况下
可能会在

293
00:19:02,009 --> 00:19:06,146
计算产生结果之前调度后处理管道

294
00:19:06,180 --> 00:19:09,449
从而引入数据竞争

295
00:19:09,483 --> 00:19:13,554
Shared Event API 可以用来解决这个问题

296
00:19:13,587 --> 00:19:16,723
并引入跨命令队列的同步

297
00:19:16,757 --> 00:19:21,428
以确保满足工作流依赖性

298
00:19:21,461 --> 00:19:25,566
在代码中使用共享事件非常简单

299
00:19:25,599 --> 00:19:29,169
我们假设您正在处理两个 Graph

300
00:19:29,203 --> 00:19:32,873
第一个负责计算工作负载

301
00:19:32,906 --> 00:19:37,277
第二个负责后处理工作量

302
00:19:37,311 --> 00:19:41,815
我们还要假设计算图的结果被用作

303
00:19:41,849 --> 00:19:43,550
后处理图的输入

304
00:19:43,584 --> 00:19:47,187
并且它们运行在不同的命令队列上

305
00:19:47,221 --> 00:19:51,258
Metal System Trace 中的
新 MPS Graph 轨迹

306
00:19:51,291 --> 00:19:55,329
表明命令队列相互重叠

307
00:19:55,362 --> 00:19:58,398
这会产生数据竞争

308
00:19:58,432 --> 00:20:01,902
您可以使用共享事件来解决这个问题

309
00:20:01,935 --> 00:20:05,906
首先 使用 Metal 设备创建事件

310
00:20:05,939 --> 00:20:10,477
接下来 调用执行描述符中的
信号方法

311
00:20:10,511 --> 00:20:14,248
提供事件 动作和值

312
00:20:14,281 --> 00:20:18,552
然后您所要做的就是
在第二个描述符上

313
00:20:18,585 --> 00:20:20,087
调用 wait 方法

314
00:20:20,120 --> 00:20:23,156
提供事件变量和值

315
00:20:24,658 --> 00:20:29,596
现在 Metal System Trace 表明
两个命令队列是

316
00:20:29,630 --> 00:20:32,866
按顺序运行的
并且计算和后处理图之间的

317
00:20:32,900 --> 00:20:37,137
依赖关系已经解决

318
00:20:37,171 --> 00:20:41,141
这就是如何使用共享事件
来解决 App 中的

319
00:20:41,175 --> 00:20:43,043
同步问题

320
00:20:43,076 --> 00:20:48,348
接着 我来说说
MPS Graph 支持的新操作

321
00:20:48,382 --> 00:20:52,619
这些操作允许您
使用框架做更多的事情

322
00:20:52,653 --> 00:20:58,458
我将从 RNNs 开始
介绍这些新操作的一些细节

323
00:20:59,760 --> 00:21:03,797
MPS Graph 现在公开了
递归神经网络 App 中

324
00:21:03,830 --> 00:21:07,334
常用的三种操作

325
00:21:07,367 --> 00:21:12,172
就是 RNN LSTM 和 GRU 层

326
00:21:12,206 --> 00:21:14,808
这些操作都是相似的

327
00:21:14,842 --> 00:21:18,979
所以我今天只关注 LSTM

328
00:21:19,012 --> 00:21:23,217
LSTM 运算通常用于自然语言处理

329
00:21:23,250 --> 00:21:25,552
和其他 App

330
00:21:25,586 --> 00:21:29,790
下图显示了 LSTM 操作的工作原理

331
00:21:29,823 --> 00:21:35,529
想了解更多信息
请查看我们之前的 WWDC 讲座

332
00:21:35,562 --> 00:21:39,600
您可以自己完成 LSTM 单元

333
00:21:39,633 --> 00:21:43,637
但要做到这一点
您必须构建这个相当复杂的自定义子图

334
00:21:43,670 --> 00:21:47,508
相反 您可以使用新的 LSTM 操作

335
00:21:47,541 --> 00:21:53,647
它可以有效地对重复单元所需的
所有 GPU 工作进行编码

336
00:21:53,680 --> 00:21:59,586
这种新操作大大加快了
基于 LSTM 的 CoreML 推理模型的速度

337
00:22:01,388 --> 00:22:03,557
要使用新的 LSTM 操作

338
00:22:03,590 --> 00:22:08,529
首先创建一个
MPS GraphLSTMDescriptor

339
00:22:08,562 --> 00:22:11,798
您可以根据需要修改描述符属性

340
00:22:11,832 --> 00:22:15,636
例如选择激活函数

341
00:22:15,669 --> 00:22:18,705
接下来 将 LSTM 单元添加到图中

342
00:22:18,739 --> 00:22:21,275
提供输入张量

343
00:22:21,308 --> 00:22:23,911
您还可以提供一个偏差向量

344
00:22:23,944 --> 00:22:27,714
以及操作的初始状态和单元格

345
00:22:27,748 --> 00:22:30,450
最后 提供描述符

346
00:22:30,484 --> 00:22:34,154
这就是设置 LSTM 所需要做的全部工作

347
00:22:34,188 --> 00:22:38,058
RNN 的其他操作也类似

348
00:22:38,091 --> 00:22:40,694
我鼓励您尝试这些操作

349
00:22:40,727 --> 00:22:44,431
看看您的 App
可以获得什么样的加速

350
00:22:44,464 --> 00:22:48,869
接下来 我将向您展示
对 Max Pooling 的改进支持

351
00:22:48,902 --> 00:22:53,540
Max Pooling 操作采用
输入张量和窗口大小

352
00:22:53,574 --> 00:22:56,543
为窗口的每个应用

353
00:22:56,577 --> 00:23:00,314
计算窗口内输入的最大值

354
00:23:00,347 --> 00:23:05,686
它通常用于计算机视觉中
以降低图像的维度

355
00:23:05,719 --> 00:23:10,891
该 API 已被扩展为
返回池化操作符提取的

356
00:23:10,924 --> 00:23:13,093
最大值位置的索引

357
00:23:13,126 --> 00:23:15,729
您可以在梯度通道中使用索引

358
00:23:15,762 --> 00:23:19,433
其中梯度必须传播到

359
00:23:19,466 --> 00:23:23,170
已提取出最大值的位置

360
00:23:23,203 --> 00:23:26,573
新的 API 也适用于训练

361
00:23:26,607 --> 00:23:30,844
对于 PyTorch 和 TensorFlow
在训练期间重复使用索引的速度

362
00:23:30,878 --> 00:23:33,380
可以提高六倍

363
00:23:34,515 --> 00:23:40,254
要在代码中对此进行设置
首先需要创建 GraphPooling 描述符

364
00:23:40,287 --> 00:23:42,723
您可以指定 returnIndicesMode

365
00:23:42,756 --> 00:23:46,593
例如 globalFlatten4D

366
00:23:46,627 --> 00:23:53,233
然后您可以使用 Return Indices API
来调用图上的池操作

367
00:23:53,267 --> 00:23:56,203
操作的结果是双重的

368
00:23:56,236 --> 00:24:01,475
第一个是 poolingTensor
第二个是 indicesTensor

369
00:24:01,508 --> 00:24:04,711
您可以缓存索引张量以备后用

370
00:24:04,745 --> 00:24:07,748
例如在训练管道上使用

371
00:24:09,316 --> 00:24:13,654
MPS Graph 现在公开了
一个新的并行随机数生成器

372
00:24:13,687 --> 00:24:15,722
举个例子 它可以用来

373
00:24:15,756 --> 00:24:19,226
初始化训练图的权重

374
00:24:19,259 --> 00:24:22,863
新的随机操作使用 Philox 算法

375
00:24:22,896 --> 00:24:28,135
并为给定的种子返回
与 TensorFlow 相同的结果

376
00:24:28,168 --> 00:24:31,772
新的运算以一个状态张量作为输入

377
00:24:31,805 --> 00:24:34,608
它返回一个随机张量作为输出

378
00:24:34,641 --> 00:24:38,078
而且该随机张量可以用作
新的状态张量 举个例子

379
00:24:38,111 --> 00:24:41,148
可以将其用作第二个随机操作的输入

380
00:24:41,181 --> 00:24:43,517
要使用新的随机运算

381
00:24:43,550 --> 00:24:46,787
请调用
randomPhiloxStateTensor 方法

382
00:24:46,820 --> 00:24:52,192
这个方法用给定的种子
初始化一个输入状态张量

383
00:24:52,226 --> 00:24:55,329
然后声明 RandomOp 描述符

384
00:24:55,362 --> 00:24:59,466
它将分布和数据类型作为输入

385
00:24:59,499 --> 00:25:02,102
在示例中 描述符指定了

386
00:25:02,135 --> 00:25:07,574
32 位浮点值的截断正态分布

387
00:25:07,608 --> 00:25:11,745
您也可以使用正态分布和均匀分布

388
00:25:12,846 --> 00:25:15,782
通过指定平均值

389
00:25:15,816 --> 00:25:18,719
标准差 最小值和最大值

390
00:25:18,752 --> 00:25:21,889
您可以进一步定义分布特征

391
00:25:21,922 --> 00:25:26,326
最后 您可以创建随机操作
提供刚刚创建的

392
00:25:26,360 --> 00:25:29,663
形状张量 描述符和状态张量

393
00:25:32,199 --> 00:25:34,067
除了 Random 之外

394
00:25:34,101 --> 00:25:37,905
MPS Graph 现在还支持
一种新的 GPU 加速操作

395
00:25:37,938 --> 00:25:42,109
来计算两个位向量之间的汉明距离

396
00:25:42,142 --> 00:25:45,279
汉明距离被定义为

397
00:25:45,312 --> 00:25:48,215
两个长度相同的输入之间不同的位数

398
00:25:48,248 --> 00:25:51,718
是两个序列之间编辑距离的度量

399
00:25:51,752 --> 00:25:58,192
它被用于从生物信息学
到密码学的若干应用

400
00:25:58,225 --> 00:26:01,728
要使用汉明距离
请在图形上调用 API

401
00:26:01,762 --> 00:26:06,867
提供 primaryTensor
secondaryTensor 和结果数据类型

402
00:26:06,900 --> 00:26:11,138
请注意 新内核支持在 GPU 上
通过批处理维度

403
00:26:11,171 --> 00:26:13,941
进行广播

404
00:26:13,974 --> 00:26:18,612
现在 我将向您展示新的张量操作

405
00:26:18,645 --> 00:26:20,347
这些操作非常容易使用

406
00:26:20,380 --> 00:26:24,084
您现在可以扩展张量的维度

407
00:26:24,117 --> 00:26:26,720
例如 从二维扩展到三维

408
00:26:26,753 --> 00:26:28,889
然后您可以把维度压缩回去

409
00:26:30,524 --> 00:26:36,129
您也可以平均分割一个张量
提供多个切片和一个轴

410
00:26:36,163 --> 00:26:39,233
或者沿着给定的轴堆叠张量

411
00:26:40,834 --> 00:26:44,638
您还可以为给定的输入形状生成
沿张量维度的

412
00:26:44,671 --> 00:26:46,740
坐标值

413
00:26:46,773 --> 00:26:51,111
例如 您可以用 0 轴上的坐标

414
00:26:51,144 --> 00:26:54,348
填充形状为 2 乘 4 的张量

415
00:26:54,381 --> 00:26:59,720
这也可用于实现 range1D 操作

416
00:26:59,753 --> 00:27:03,490
例如 假设您想要生成

417
00:27:03,524 --> 00:27:07,928
3 到 27 之间的数字范围 增量为 4

418
00:27:07,961 --> 00:27:10,731
要做到这一点 您可以先

419
00:27:10,764 --> 00:27:15,002
在维度 0 上的坐标创建
形状为 6 的张量

420
00:27:15,035 --> 00:27:21,008
然后您所要做的就是乘以增量
再加上偏移量

421
00:27:21,041 --> 00:27:25,179
这些都是今年新增的操作

422
00:27:25,212 --> 00:27:29,016
有了这些新的操作
您将能够使用 MPS Graph

423
00:27:29,049 --> 00:27:34,288
在整个 Apple 生态系统中
做更多的事情并获得更高的性能

424
00:27:34,321 --> 00:27:37,691
现在 我将向大家展示 Apple 芯片

425
00:27:37,724 --> 00:27:40,861
在 MPS 图表之外的性能提升

426
00:27:41,728 --> 00:27:45,766
Blackmagic 刚刚发布了
DaVinci Resolve 版本 18

427
00:27:45,799 --> 00:27:50,470
该版本使用 MPS Graph
来加速机器学习工作负载

428
00:27:50,504 --> 00:27:54,808
Magic Mask 是 Resolve 的一项功能
它使用机器学习

429
00:27:54,842 --> 00:28:00,814
来识别屏幕上的移动对象
并选择性地在对象上应用滤镜

430
00:28:00,848 --> 00:28:05,185
首先 我将演示这在以前版本的
Resolve 中是如何工作的

431
00:28:05,219 --> 00:28:08,889
然后将它与当前版本进行比较

432
00:28:08,922 --> 00:28:13,060
要创建遮罩 您只需选择目标对象

433
00:28:13,093 --> 00:28:16,730
您可以通过切换覆盖来查看遮罩

434
00:28:16,763 --> 00:28:19,399
遮罩由红色区域标识

435
00:28:19,433 --> 00:28:22,402
该区域正确标记了主体的形状

436
00:28:22,436 --> 00:28:28,709
现在 如果我播放视频 当物体
在屏幕上移动时 遮罩会跟踪它

437
00:28:28,742 --> 00:28:32,212
这看起来很棒
但它在以相当低的帧速率运行

438
00:28:32,246 --> 00:28:35,916
因为机器学习管道在引擎盖下运行

439
00:28:35,949 --> 00:28:39,419
现在我将切换到最新版本的 Resolve

440
00:28:39,453 --> 00:28:44,424
它使用 MPS Graph
来加速 Magic Mask 网络

441
00:28:44,458 --> 00:28:49,763
再次运行相同的时间线
帧速率比以前快了很多

442
00:28:49,796 --> 00:28:54,334
这在 Apple 芯片上
带来了更好的编辑体验

443
00:28:55,402 --> 00:29:00,073
这些是您仅仅通过
采用 MPS Graph 就能得到的加速

444
00:29:00,107 --> 00:29:04,645
我鼓励您去探索它能给您的 App
带来什么样的性能

445
00:29:04,678 --> 00:29:07,981
总而言之 您现在能够

446
00:29:08,015 --> 00:29:10,184
使用 PyTorch 的 GPU 加速

447
00:29:10,217 --> 00:29:13,420
该项目现在是开源的

448
00:29:13,453 --> 00:29:16,523
您将发现用 TensorFlow Metal 插件

449
00:29:16,557 --> 00:29:19,126
加速训练工作量的新方法

450
00:29:19,159 --> 00:29:23,463
例如 使用自定义操作和分布式训练

451
00:29:23,497 --> 00:29:28,202
最后 您还能够利用 MPS Graph 框架

452
00:29:28,235 --> 00:29:29,903
优化最苛刻的机器学习任务

453
00:29:29,937 --> 00:29:32,206
利用共享事件和新操作

454
00:29:32,239 --> 00:29:34,842
充分使用 Apple 芯片

455
00:29:34,875 --> 00:29:38,345
Dhruva 和我迫不及待地想知道
您将如何在您的 App 中

456
00:29:38,378 --> 00:29:39,880
使用这些新功能

457
00:29:39,913 --> 00:29:43,851
感谢您观看本期讲座
祝您的 WWDC 之旅一切顺利

