1
00:00:00,167 --> 00:00:03,003
♪ 柔和乐器演奏的嘻哈音乐 ♪

2
00:00:03,003 --> 00:00:09,977
♪

3
00:00:09,977 --> 00:00:13,981
Namaskar 您好
欢迎来到 WWDC 22

4
00:00:13,981 --> 00:00:17,651
我叫 Vrushali Mundhe
是 Create ML 团队的工程师

5
00:00:17,651 --> 00:00:22,456
很高兴在这里与您分享
Create ML 的新功能

6
00:00:22,456 --> 00:00:24,525
Create ML 可以让您
轻松地用收集到的数据

7
00:00:24,525 --> 00:00:27,628
训练强大的机器学习模型

8
00:00:27,628 --> 00:00:32,566
提供独特的体验并优化您的 App

9
00:00:32,566 --> 00:00:36,003
Create ML 作为与
Xcode 捆绑的 App 发布

10
00:00:36,003 --> 00:00:38,906
让您无需代码直接在 Mac 上

11
00:00:38,906 --> 00:00:41,808
创建和训练 Core ML 模型

12
00:00:41,808 --> 00:00:44,978
Create ML 也可作为

13
00:00:44,978 --> 00:00:47,147
SDK 中的 Swift 框架

14
00:00:47,147 --> 00:00:51,251
使用它的 API
您可以直接在您的 App 内

15
00:00:51,251 --> 00:00:54,588
轻松地自动创建模型

16
00:00:54,588 --> 00:00:57,758
或通过训练创造动态体验

17
00:00:57,758 --> 00:01:00,427
要详细了解
Create ML 的核心功能

18
00:01:00,427 --> 00:01:04,031
您可以查看这些往期讲座

19
00:01:04,031 --> 00:01:08,135
在本次讲座中 我们将讨论
Create ML 中的新增功能

20
00:01:08,135 --> 00:01:10,704
我们将从 Create ML
App 中的新功能开始

21
00:01:10,704 --> 00:01:12,806
这些功能可以帮助评估

22
00:01:12,806 --> 00:01:14,942
您的模型的准确性和实用性

23
00:01:14,942 --> 00:01:18,579
接着我会介绍
Create ML 框架

24
00:01:18,579 --> 00:01:20,681
它的扩展能力

25
00:01:20,681 --> 00:01:23,550
以及现在为您的 App

26
00:01:23,550 --> 00:01:26,119
高度定制模型的能力

27
00:01:26,119 --> 00:01:28,188
让我们从回顾一个典型的

28
00:01:28,188 --> 00:01:30,157
创建模型工流程开始

29
00:01:30,157 --> 00:01:33,160
给定一个确定的任务

30
00:01:33,160 --> 00:01:35,629
首先要开始收集和注释数据

31
00:01:35,629 --> 00:01:40,033
举个例子 想要直观地识别杂货

32
00:01:40,033 --> 00:01:42,002
对于这个图像分类任务

33
00:01:42,002 --> 00:01:45,839
您的出发点是收集和标记图像

34
00:01:45,839 --> 00:01:47,941
在这里 有一些水果和蔬菜

35
00:01:50,410 --> 00:01:53,780
Create ML
将帮助您根据这些数据训练模型

36
00:01:53,780 --> 00:01:56,283
模型可在您的 App 中使用

37
00:01:56,283 --> 00:01:58,719
但是 在使用这个模型之前

38
00:01:58,719 --> 00:02:02,756
一个重要的步骤是评估它的表现如何

39
00:02:02,756 --> 00:02:05,826
在这里
查看该模型在图像上的准确度

40
00:02:05,826 --> 00:02:09,263
并不是训练集的一部分

41
00:02:09,263 --> 00:02:11,431
根据评估

42
00:02:11,431 --> 00:02:14,735
您可以使用其他数据对模型进行迭代

43
00:02:14,735 --> 00:02:17,171
并修改训练设置

44
00:02:17,171 --> 00:02:19,773
或者 如果模型表现得足够好

45
00:02:19,773 --> 00:02:22,976
您可以准备将其集成到 App 中

46
00:02:22,976 --> 00:02:26,947
我们来进一步关注这个评估步骤

47
00:02:26,947 --> 00:02:29,550
在进行评估时 我们经常会

48
00:02:29,550 --> 00:02:33,053
通过在训练中保留的新数据上

49
00:02:33,053 --> 00:02:35,923
测试您的模型来衡量一组指标

50
00:02:35,923 --> 00:02:39,293
您可以
从查看最高级别的准确率指标开始

51
00:02:39,293 --> 00:02:41,695
或深入了解每类统计数据

52
00:02:41,695 --> 00:02:44,264
大致了解模型的行为

53
00:02:44,264 --> 00:02:48,769
以及超出其训练范围的整体能力

54
00:02:48,769 --> 00:02:51,972
最终 该模型将在您的 App 中

55
00:02:51,972 --> 00:02:54,141
赋予数据驱动体验

56
00:02:54,141 --> 00:02:55,742
在评估过程中

57
00:02:55,742 --> 00:03:00,314
您想确定该模型在输入或

58
00:03:00,314 --> 00:03:03,283
场景类别方面的主要优势和劣势

59
00:03:03,283 --> 00:03:07,754
它运作良好或可能达不到预期

60
00:03:07,754 --> 00:03:10,657
Create ML App
中有一些新功能

61
00:03:10,657 --> 00:03:13,260
可以在模型创建之旅的这部分帮助您

62
00:03:13,260 --> 00:03:16,296
让我向您展示一个我正在从事的项目

63
00:03:16,296 --> 00:03:18,699
在这里 我设置了一个项目

64
00:03:18,699 --> 00:03:20,767
来创建模型识别杂货

65
00:03:20,767 --> 00:03:23,070
我开始收集各种水果

66
00:03:23,070 --> 00:03:25,839
和蔬菜图像作为我的训练数据

67
00:03:25,839 --> 00:03:30,143
并给它们标上合适的标签

68
00:03:30,143 --> 00:03:32,446
这是我的不同类别

69
00:03:32,446 --> 00:03:34,281
和每个类别的图像数量

70
00:03:38,285 --> 00:03:43,557
我已经对我的图像分类器
进行了 25 次迭代训练

71
00:03:43,557 --> 00:03:46,260
接下来 当我点击“评估”选项卡时

72
00:03:46,260 --> 00:03:49,463
除了我为测试留出的训练数据

73
00:03:49,463 --> 00:03:53,433
我还可以添加
新的测试数据 一组图像

74
00:03:58,372 --> 00:04:03,510
接下来我将单击“评估”开始测试

75
00:04:03,510 --> 00:04:05,579
完成评估后

76
00:04:05,579 --> 00:04:08,615
UI 提供了结果的详细信息

77
00:04:08,615 --> 00:04:11,318
在顶部 有高级别摘要部分

78
00:04:11,318 --> 00:04:14,721
在这可以快速了解测试的准确性

79
00:04:14,721 --> 00:04:19,293
在这里
该测试数据的准确率为 89%

80
00:04:19,293 --> 00:04:21,061
在此“指标”选项卡下方

81
00:04:21,061 --> 00:04:24,798
这张表为每个类别提供了丰富的指标

82
00:04:24,798 --> 00:04:28,669
您可以使用这些下拉菜单
来调整此处显示的内容

83
00:04:28,669 --> 00:04:31,138
并添加额外的指标 如误报

84
00:04:31,138 --> 00:04:32,606
和漏报

85
00:04:32,606 --> 00:04:34,675
让我们来看看其中的一个类别

86
00:04:34,675 --> 00:04:36,276
“番茄”怎么样？

87
00:04:36,276 --> 00:04:40,080
该模型正确分类了
32 幅番茄图像中的 29 幅

88
00:04:40,080 --> 00:04:45,586
它还显示该类的准确率为 91%

89
00:04:45,586 --> 00:04:47,154
这意味着
该模型说某个东西是番茄时

90
00:04:47,154 --> 00:04:50,624
有 9% 是不正确的

91
00:04:50,624 --> 00:04:53,227
虽然这些数字和统计数据非常有用

92
00:04:53,227 --> 00:04:56,096
但有时

93
00:04:56,096 --> 00:04:58,465
在数据本身的背景下看它们更重要

94
00:04:58,465 --> 00:05:02,236
当我点击准确度时

95
00:05:02,236 --> 00:05:05,372
它会跳转到被错误归类为番茄的图像

96
00:05:05,372 --> 00:05:08,876
以下是测试数据中的三种情况

97
00:05:08,876 --> 00:05:12,145
对于每张图像
App 都会显示其缩略图

98
00:05:12,145 --> 00:05:14,448
模型预测的类别

99
00:05:14,448 --> 00:05:16,550
以及它下面的真实标签

100
00:05:16,550 --> 00:05:19,052
在第一个示例中
虽然模型将其分类为

101
00:05:19,052 --> 00:05:22,589
“番茄” 但它被标记为“马铃薯”

102
00:05:22,589 --> 00:05:25,058
在我看来这肯定是番茄

103
00:05:25,058 --> 00:05:27,694
这似乎
是一个错误标记测试数据的情况

104
00:05:27,694 --> 00:05:31,632
事实上
所有这三个示例似乎都被标记错误

105
00:05:31,632 --> 00:05:33,567
这应该很容易解决

106
00:05:33,567 --> 00:05:35,135
我会做一个笔记来再次检查

107
00:05:35,135 --> 00:05:37,738
并重新审视我的测试集标签

108
00:05:37,738 --> 00:05:40,007
这显然是我的失误

109
00:05:40,007 --> 00:05:42,943
但它是错误的唯一来源吗

110
00:05:42,943 --> 00:05:44,845
我通过研究
我选择的一个随机类上的指标

111
00:05:44,845 --> 00:05:47,281
到达这里

112
00:05:47,281 --> 00:05:50,317
您可能想知道
“我应该从哪里开始？”

113
00:05:50,317 --> 00:05:53,787
或者 “接下来我应该研究什么？”

114
00:05:53,787 --> 00:05:58,225
顶层摘要部分可以帮助您解决疑惑

115
00:05:58,225 --> 00:05:59,293
该 App 已选择

116
00:05:59,293 --> 00:06:01,795
一些最重要的评估细节

117
00:06:01,795 --> 00:06:05,766
可以从此处开始研究

118
00:06:05,766 --> 00:06:10,604
让我从头开始 回顾成功案例

119
00:06:10,604 --> 00:06:15,742
点击这里 这个正确的计数...

120
00:06:15,742 --> 00:06:19,413
在这里
我们可以快速浏览模型正确分类的

121
00:06:19,413 --> 00:06:23,550
所有 162 张图片

122
00:06:23,550 --> 00:06:27,187
接下来 我通过点击不正确

123
00:06:27,187 --> 00:06:31,258
将其与所有错误分类进行对比

124
00:06:31,258 --> 00:06:33,660
总共有 21 次错误

125
00:06:35,963 --> 00:06:38,765
又是那个被标记错误的番茄

126
00:06:38,765 --> 00:06:40,934
让我检查一下
是否还有其他类型的错误

127
00:06:40,934 --> 00:06:43,036
可以突出显示

128
00:06:43,036 --> 00:06:46,139
这个怎么样？

129
00:06:46,139 --> 00:06:50,344
这张图片被标记为“胡萝卜”

130
00:06:50,344 --> 00:06:53,780
但模型预测为“马铃薯”

131
00:06:53,780 --> 00:06:56,483
在这个小缩略图中很难分辨

132
00:06:56,483 --> 00:07:01,154
让我们单击此图像
以获得更清楚的视图

133
00:07:01,154 --> 00:07:03,557
嗯 这对我来说就像一只脚

134
00:07:03,557 --> 00:07:06,894
这显然不是
我认知里又长又瘦的胡萝卜形状

135
00:07:06,894 --> 00:07:09,563
但很容易被混淆为马铃薯

136
00:07:09,563 --> 00:07:12,199
也许我应该考虑添加更多的形状变化

137
00:07:12,199 --> 00:07:14,501
到我的胡萝卜训练数据

138
00:07:14,501 --> 00:07:16,603
让我也记下这一点

139
00:07:16,603 --> 00:07:20,274
这一次 我将点击文件名旁边的箭头

140
00:07:20,274 --> 00:07:23,243
带我跳转到“访达”中的这张图像

141
00:07:25,679 --> 00:07:30,651
我将右键单击并将其标记为红色

142
00:07:30,651 --> 00:07:33,520
以此在我的下一轮数据收集中

143
00:07:33,520 --> 00:07:36,456
提醒我这是要重新查看的东西

144
00:07:36,456 --> 00:07:40,594
让我从这个扩展的视图中
继续我的研究

145
00:07:40,594 --> 00:07:44,298
请注意
此视图也显示了完整的预测结果

146
00:07:44,298 --> 00:07:46,934
列出模型对每个类别的预测比例

147
00:07:46,934 --> 00:07:49,670
使用这些左右箭头

148
00:07:49,670 --> 00:07:53,473
还可以浏览示例

149
00:07:53,473 --> 00:07:57,244
我将从这里转到另一个示例

150
00:07:57,244 --> 00:07:58,912
这是一个有趣的示例

151
00:07:58,912 --> 00:08:02,883
这个图像中有多种蔬菜

152
00:08:02,883 --> 00:08:07,120
它说这是茄子 确实是的

153
00:08:07,120 --> 00:08:11,091
这里有茄子 但也有其他东西

154
00:08:11,091 --> 00:08:13,961
我需要想想
这是否是我的 App 中

155
00:08:13,961 --> 00:08:16,830
需要考虑的一个重要使用案例

156
00:08:16,830 --> 00:08:19,600
也许 UI 可以引导我的用户

157
00:08:19,600 --> 00:08:22,769
确保他们一次只指向一种类型的杂货

158
00:08:22,769 --> 00:08:24,972
或者如果我想支持多种类型

159
00:08:24,972 --> 00:08:28,141
我可能要考虑使用一个对象检测器

160
00:08:28,141 --> 00:08:29,776
App 中的另一个模板

161
00:08:29,776 --> 00:08:32,679
而不是整个图像分类器

162
00:08:32,679 --> 00:08:34,481
回到概要部分

163
00:08:34,481 --> 00:08:37,885
让我看看这条最高层级混乱

164
00:08:37,885 --> 00:08:40,621
在这里它说
将“辣椒”归类为“豆子”

165
00:08:40,621 --> 00:08:44,258
让我们点击来看看这个案例

166
00:08:44,258 --> 00:08:46,260
四个标记为辣椒的图像

167
00:08:46,260 --> 00:08:49,730
被错误地归类为豆类

168
00:08:49,730 --> 00:08:51,598
这些在我看来像很辣的辣椒

169
00:08:51,598 --> 00:08:55,068
但我猜它们也像豆子一样绿
所以才被错误归类

170
00:08:55,068 --> 00:08:58,805
我想知道这个模型是否在一般情况下
识别辣椒有问题

171
00:08:58,805 --> 00:09:05,812
让我将此查询选项从“不正确”
切换到“正确”...

172
00:09:05,812 --> 00:09:09,583
将这些错误与正确分类的辣椒
进行对比

173
00:09:09,583 --> 00:09:13,020
它正确分类了 32 张图像

174
00:09:13,020 --> 00:09:17,024
但是
我确实注意到其中大部分都是甜椒

175
00:09:17,024 --> 00:09:19,426
我应该检查我的训练数据以确保

176
00:09:19,426 --> 00:09:24,731
它有涵盖多种辣椒类型

177
00:09:24,731 --> 00:09:26,934
这次快速研究很好地提醒了我们

178
00:09:26,934 --> 00:09:29,436
训练和测试数据的数量、质量和种类

179
00:09:29,436 --> 00:09:34,174
对于机器学习是多么重要

180
00:09:34,174 --> 00:09:36,543
在短短的几分钟内

181
00:09:36,543 --> 00:09:38,779
该 App 帮助我直观地发现了

182
00:09:38,779 --> 00:09:40,848
一些标签和表述方面的问题

183
00:09:40,848 --> 00:09:43,517
我需要对我的训练数据进行一些调整

184
00:09:43,517 --> 00:09:46,019
看看调整后
它能否解决我们发现的问题

185
00:09:46,019 --> 00:09:49,623
它还提醒了一些
我以前没有考虑过的事情：

186
00:09:49,623 --> 00:09:52,759
如果用户在一张图像中

187
00:09:52,759 --> 00:09:54,494
看到多个蔬菜会发生什么

188
00:09:54,494 --> 00:09:58,732
我需要再考虑我的 App 设计

189
00:09:58,732 --> 00:10:00,834
所有这些探索都是可能的

190
00:10:00,834 --> 00:10:04,638
因为我有一系列的标签数据来评估

191
00:10:04,638 --> 00:10:08,942
但如果我想快速测试
未标记的示例该怎么办？

192
00:10:08,942 --> 00:10:11,278
或者考虑是否应该探索

193
00:10:11,278 --> 00:10:15,182
更多的摄像机角度或照明条件呢？

194
00:10:15,182 --> 00:10:18,151
在“预览”里就可以解决上述问题

195
00:10:18,151 --> 00:10:21,021
我可以拖拽一些我同事
刚刚发给我的示例进这里

196
00:10:21,021 --> 00:10:22,856
看看效果如何

197
00:10:36,603 --> 00:10:38,338
或者我甚至可以现场测试

198
00:10:38,338 --> 00:10:41,375
用我的 iPhone
作为“连续互通”相机

199
00:10:43,610 --> 00:10:45,746
当我将镜头对着这些蔬菜时

200
00:10:45,746 --> 00:10:49,516
该模型能够正确地
实时对它们进行分类

201
00:10:49,516 --> 00:10:54,488
这里 这是一个辣椒和一个番茄

202
00:10:54,488 --> 00:10:56,690
回顾一下 您现在可以更深入地了解

203
00:10:56,690 --> 00:11:01,061
一个训练有素的模型
在任何标记数据集上的行为

204
00:11:01,061 --> 00:11:04,198
“评估”窗格提供了详细的指标汇总

205
00:11:04,198 --> 00:11:06,400
及其扩展选项

206
00:11:06,400 --> 00:11:09,503
新的“探索”选项卡提供了一些选项

207
00:11:09,503 --> 00:11:12,172
让您可以在新交互式 UI 中筛选

208
00:11:12,172 --> 00:11:16,543
和可视化测试评估结果以及相关数据

209
00:11:16,543 --> 00:11:18,946
目前可用于图像分类器

210
00:11:18,946 --> 00:11:24,017
手部姿势分类器和物体检测模板

211
00:11:24,017 --> 00:11:26,987
实时预览可实现即时反馈

212
00:11:26,987 --> 00:11:29,456
它已扩展至图像分类器

213
00:11:29,456 --> 00:11:34,561
手部动作分类器
和身体动作分类器模板

214
00:11:34,561 --> 00:11:36,763
我们还扩展了该功能以允许您

215
00:11:36,763 --> 00:11:39,333
从任何附加的网络摄像头中选择

216
00:11:39,333 --> 00:11:42,069
我们还支持 macOS

217
00:11:42,069 --> 00:11:45,305
Ventura 上的“连续互通”相机

218
00:11:45,305 --> 00:11:48,675
这是对 Create ML
App 新功能的快速回顾总结

219
00:11:48,675 --> 00:11:50,577
我们接着来讨论
Create ML 框架中的

220
00:11:50,577 --> 00:11:52,446
新功能

221
00:11:54,915 --> 00:11:57,518
Create ML 框架适用于

222
00:11:57,518 --> 00:11:59,820
macOS、iOS
和 iPadOS

223
00:11:59,820 --> 00:12:04,525
今年 我们正将其部分支持
扩展到 tvOS 16

224
00:12:04,525 --> 00:12:07,127
程序化界面不仅让您

225
00:12:07,127 --> 00:12:09,830
在开发时自动创建模型

226
00:12:09,830 --> 00:12:12,866
而且还开辟了许多机会
来构建动态功能

227
00:12:12,866 --> 00:12:17,070
直接从用户的输入
或设备上的行为中学习

228
00:12:17,070 --> 00:12:20,073
提供个性化和自适应的体验

229
00:12:20,073 --> 00:12:24,444
同时保护用户隐私

230
00:12:24,444 --> 00:12:27,781
请注意 任务支持因平台而异

231
00:12:27,781 --> 00:12:31,151
例如 表格分类器和回归器

232
00:12:31,151 --> 00:12:34,588
在几乎所有平台可用
但一些对数据和计算要求较大的任务

233
00:12:34,588 --> 00:12:38,325
如涉及视频的任务

234
00:12:38,325 --> 00:12:41,061
则需要 macOS

235
00:12:41,061 --> 00:12:43,096
您可能有一个常见的问题是

236
00:12:43,096 --> 00:12:44,998
“如果我不能把我的想法映射到这些

237
00:12:44,998 --> 00:12:48,802
Create ML 的
预定义任务中怎么办？”

238
00:12:48,802 --> 00:12:52,239
为了帮助回答这个问题
我们要向您介绍

239
00:12:52,239 --> 00:12:54,441
一位 Create ML 系列的
新成员：

240
00:12:54,441 --> 00:12:56,610
Create ML 组件

241
00:12:56,610 --> 00:12:59,980
Create ML 组件展露了

242
00:12:59,980 --> 00:13:02,482
Create ML 的基本模块

243
00:13:02,482 --> 00:13:05,586
它允许您将它们组合在一起

244
00:13:05,586 --> 00:13:09,556
创建为您的用例定制的管道和模型

245
00:13:09,556 --> 00:13:11,458
强烈建议您查看这些讲座

246
00:13:11,458 --> 00:13:12,926
以了解更多信息

247
00:13:12,926 --> 00:13:14,895
在“了解
Create ML 组件”中

248
00:13:14,895 --> 00:13:16,964
您将了解构建基块

249
00:13:16,964 --> 00:13:19,600
以及它们如何组合在一起

250
00:13:19,600 --> 00:13:22,636
在“使用 Create ML
组件构建高级模型”中

251
00:13:22,636 --> 00:13:26,240
您将深入了解使用异步时间组件

252
00:13:26,240 --> 00:13:28,609
和自定义训练

253
00:13:28,609 --> 00:13:31,712
功能十分丰富 让我演示一个

254
00:13:31,712 --> 00:13:33,680
我很喜欢的功能：

255
00:13:33,680 --> 00:13:35,849
动作重复计数

256
00:13:35,849 --> 00:13:40,087
当我休息时 我会去跳舞

257
00:13:40,087 --> 00:13:41,355
我是受过专业训练的

258
00:13:41,355 --> 00:13:44,691
印度古典舞卡达克艺术家

259
00:13:44,691 --> 00:13:45,826
我经常依靠反复练习我的常规动作

260
00:13:45,826 --> 00:13:49,563
来优化我的舞蹈

261
00:13:49,563 --> 00:13:53,000
作为一名编舞者或教师
我希望我的表演者

262
00:13:53,000 --> 00:13:56,236
能够练习某些舞步并提交给我

263
00:13:56,236 --> 00:13:59,006
Create ML 中的
重复计数功能

264
00:13:59,006 --> 00:14:01,475
就可以帮我实现这个要求

265
00:14:01,475 --> 00:14:04,378
这是卡达克舞中的一个重要动作

266
00:14:04,378 --> 00:14:06,713
chakkar 平转

267
00:14:09,249 --> 00:14:11,952
我想每天练习一定的次数

268
00:14:11,952 --> 00:14:14,588
以优化我的动作形态和耐力

269
00:14:14,588 --> 00:14:18,625
我有一个使用 Create ML
构建的 iOS App 可以

270
00:14:18,625 --> 00:14:20,360
计算我的动作 让我来试一下

271
00:14:27,868 --> 00:14:30,304
当我开始做 chakkars 时

272
00:14:30,304 --> 00:14:31,972
与之对应的计数也在增加

273
00:14:31,972 --> 00:14:33,807
我刚才做了五个 chakkars 动作

274
00:14:33,807 --> 00:14:36,743
计数也正好是五

275
00:14:36,743 --> 00:14:39,146
接下来 我来尝试一些不同的小动作

276
00:14:39,146 --> 00:14:41,982
包括右侧和左侧的动作

277
00:14:41,982 --> 00:14:44,017
计数器会右侧和左侧动作
一齐算作一个动作

278
00:14:57,030 --> 00:14:59,566
在这里 计数显示三个

279
00:14:59,566 --> 00:15:02,903
让我再试试快速的单侧手臂运动

280
00:15:17,284 --> 00:15:18,685
这被计为四个

281
00:15:18,685 --> 00:15:20,821
当与动作分类结合使用时

282
00:15:20,821 --> 00:15:24,558
这将允许您同时对重复动作

283
00:15:24,558 --> 00:15:26,360
进行计数和分类

284
00:15:26,360 --> 00:15:30,430
重复计数
可作为运行时 API 使用

285
00:15:30,430 --> 00:15:33,800
它不需要训练数据

286
00:15:33,800 --> 00:15:37,237
在您的 App 中添加这一功能
只需几行代码即可

287
00:15:37,237 --> 00:15:40,507
它的实现
是基于一个预先训练好的模型

288
00:15:40,507 --> 00:15:42,643
该模型被设计成与类别无关

289
00:15:42,643 --> 00:15:46,180
意思是
虽然它适用于健身或舞蹈动作

290
00:15:46,180 --> 00:15:49,950
如跳远、深蹲、旋转
旋转、chakkars 等

291
00:15:49,950 --> 00:15:52,553
但也适用于

292
00:15:52,553 --> 00:15:56,089
各种全身性的重复动作

293
00:15:56,089 --> 00:15:57,858
您可以通过查看示例代码

294
00:15:57,858 --> 00:16:00,827
和与本次讲座相关的文章

295
00:16:00,827 --> 00:16:04,531
来了解这个模型
和潜在用例的更多信息

296
00:16:04,531 --> 00:16:08,335
以上就是对 Create ML
中新增功能的简要介绍

297
00:16:08,335 --> 00:16:11,104
Create ML App 中的
互动评估和实时预览

298
00:16:11,104 --> 00:16:13,574
可以让您更深入地了解

299
00:16:13,574 --> 00:16:16,476
您训练的模型

300
00:16:16,476 --> 00:16:20,080
Create ML 框架
增加了 tvOS 支持

301
00:16:20,080 --> 00:16:23,116
重复计数

302
00:16:23,116 --> 00:16:27,020
并扩展了对丰富的基础组件的访问

303
00:16:27,020 --> 00:16:29,890
以帮助您建立高度自定义的模型

304
00:16:29,890 --> 00:16:32,059
满足您的 App 需求

305
00:16:32,059 --> 00:16:33,093
谢谢

306
00:16:33,093 --> 00:16:35,929
希望您喜欢这些新功能

307
00:16:35,929 --> 00:16:38,465
我们迫不及待想看到您如何使用它们

308
00:16:38,465 --> 00:16:42,903
♪

