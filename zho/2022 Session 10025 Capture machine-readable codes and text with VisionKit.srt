1
00:00:00,334 --> 00:00:06,340
[欢快的音乐]

2
00:00:09,309 --> 00:00:13,313
Ron Santos: 嗨 大家好 我是 Ron Santos
一名输入工程师

3
00:00:13,347 --> 00:00:16,550
今天我和大家一起聊下
如何捕捉机读编码

4
00:00:16,583 --> 00:00:18,285
以及从视频流中解析文本

5
00:00:18,318 --> 00:00:21,722
或者 如我们常说的 数据扫描

6
00:00:21,755 --> 00:00:24,124
什么是数据扫描呢

7
00:00:24,157 --> 00:00:28,662
其实就是使用某种感应器
比如说相机，来读取数据的方法

8
00:00:29,763 --> 00:00:32,199
通常是文本形式的数据

9
00:00:32,232 --> 00:00:35,035
例如 收据的一些有趣资讯

10
00:00:35,068 --> 00:00:38,338
如电话号码 日期和价格

11
00:00:39,706 --> 00:00:42,709
或者是机器可读的编码数据

12
00:00:42,743 --> 00:00:45,612
如常见的二维码

13
00:00:45,646 --> 00:00:48,282
您之前可能使用过数据扫描

14
00:00:48,315 --> 00:00:51,218
如在相机 App 中
或 iOS 15 中推出的

15
00:00:51,251 --> 00:00:53,720
实况文本功能

16
00:00:53,754 --> 00:00:56,323
我相信您在日常生活中

17
00:00:56,356 --> 00:00:59,760
也用过 App 自带的扫描功能

18
00:00:59,793 --> 00:01:02,596
但如果要搭建自己的
数据扫描器呢

19
00:01:02,629 --> 00:01:04,198
应该怎么做呢

20
00:01:04,231 --> 00:01:07,034
iOS SDK 视您的需要

21
00:01:07,067 --> 00:01:08,602
提供了多种场景

22
00:01:09,303 --> 00:01:12,472
选项之一就是
使用 AVFoundation 框架

23
00:01:12,506 --> 00:01:14,241
建立拍摄图形

24
00:01:14,274 --> 00:01:17,945
将输入和输出连接到
同一个 session 进行配置

25
00:01:17,978 --> 00:01:22,549
生成如机器可读
代码的 AVMetadataObjects

26
00:01:22,583 --> 00:01:25,752
如果您还想捕获文本
还有另一个选项

27
00:01:25,786 --> 00:01:29,990
就是将 AVFoundation
与 Vision 框架相结合

28
00:01:30,023 --> 00:01:32,693
在这个图表中
您创建的是视频数据的输出

29
00:01:32,726 --> 00:01:35,662
而非元数据输出

30
00:01:35,696 --> 00:01:40,200
视频数据输出
带来了 sample buffers

31
00:01:40,234 --> 00:01:43,170
可以与文本一起输入到 Vision 框架

32
00:01:43,203 --> 00:01:47,774
也可以和条码识别请求共同使用
进行 Vision的物体观察功能

33
00:01:47,808 --> 00:01:49,843
关于使用 Vision
进行数据扫描的更多内容

34
00:01:49,877 --> 00:01:54,581
可以查看 WWDC21 中“Extract
document data using Vision”的内容

35
00:01:54,615 --> 00:01:58,519
好 以上是使用AVFoundation
和 Vision 进行数据扫描的内容

36
00:01:58,552 --> 00:02:03,724
在 iOS 16中 我们有一个新的选项
将这些工作都浓缩到了一起

37
00:02:03,757 --> 00:02:07,494
VisionKit 框架中的
DataScannerViewController 正式推出

38
00:02:07,528 --> 00:02:10,964
结合了 AVFoundation
和 Vision 的功能

39
00:02:10,998 --> 00:02:13,934
专门用于数据扫描目的

40
00:02:13,967 --> 00:02:17,671
DataScannerViewController 用户
可使用如

41
00:02:17,704 --> 00:02:22,176
实时摄影机预览 实用的指引标签

42
00:02:22,209 --> 00:02:24,411
物品高光显示功能

43
00:02:24,444 --> 00:02:29,049
tap-to-focus (轻点对焦)
也是可选功能之一

44
00:02:29,082 --> 00:02:32,920
最后 还可通过 pinch-to-zoom (手势缩放)
功能来放大图像

45
00:02:34,221 --> 00:02:37,090
我们再来聊聊其他的
对开发者来说实用的功能

46
00:02:37,124 --> 00:02:40,561
DataScannerViewController 是
UIViewController 的子类

47
00:02:40,594 --> 00:02:42,896
您可以选择自己喜欢的展示方式

48
00:02:42,930 --> 00:02:46,466
所识别物体的坐标
总是显示在观察坐标系中

49
00:02:46,500 --> 00:02:48,702
您无需费时将图像空间

50
00:02:48,735 --> 00:02:51,572
转换到 Vision 坐标
再到观察坐标

51
00:02:51,605 --> 00:02:54,241
您也可以通过指定
观察坐标系中的感兴趣区域

52
00:02:54,274 --> 00:02:58,979
限制观察的活动区间

53
00:02:59,012 --> 00:03:01,815
文本识别方面 您可以指定内容类型

54
00:03:01,849 --> 00:03:04,918
限制所查找的文本类型

55
00:03:04,952 --> 00:03:06,486
在机器可读代码方面

56
00:03:06,520 --> 00:03:10,290
您可以指定具体查找哪种符号

57
00:03:10,324 --> 00:03:12,359
我明白 使用您的 App

58
00:03:12,392 --> 00:03:15,929
我知道数据扫描只是
其众多功能之一

59
00:03:15,963 --> 00:03:18,365
但是需要很多代码

60
00:03:18,398 --> 00:03:20,067
通过 DataScannerViewController

61
00:03:20,100 --> 00:03:22,369
我们的目标是为您完成常规工作

62
00:03:22,402 --> 00:03:24,638
从而您可以将时间
聚焦在其它功能上

63
00:03:24,671 --> 00:03:28,008
接下来 我给您介绍下
如何将其添加到 App 中

64
00:03:28,041 --> 00:03:31,011
首先是隐私使用说明

65
00:03:31,044 --> 00:03:34,448
App 尝试捕捉视频时
iOS 会询问用户

66
00:03:34,481 --> 00:03:38,085
提供访问相机的明确权限

67
00:03:38,118 --> 00:03:42,256
您要提供一段描述性信息
用于说明需求

68
00:03:42,289 --> 00:03:45,759
那就需要在 App 的
Info.plist 文件中

69
00:03:45,792 --> 00:03:48,095
添加
“privacy - camera usage description”

70
00:03:48,128 --> 00:03:52,966
记得要尽可能详尽
这样用户知道他们提供权限的内容

71
00:03:53,000 --> 00:03:55,102
接下来是代码实现

72
00:03:55,135 --> 00:03:57,504
不管您要在哪里显示
数据扫描器

73
00:03:57,538 --> 00:03:59,773
首先要导入 VisionKit

74
00:04:01,008 --> 00:04:05,012
接下来 由于并不是所有型号的
设备都支持数据扫描

75
00:04:05,045 --> 00:04:08,549
使用 isSupported 类属性
隐藏实现功能的

76
00:04:08,582 --> 00:04:10,217
按钮或菜单

77
00:04:10,250 --> 00:04:13,620
这样使用不到这一功能的用户
就不需要看到这个界面了

78
00:04:14,888 --> 00:04:19,259
如果您想知道的话 可以告诉您
任何搭载 Apple Neural Engine 的

79
00:04:19,293 --> 00:04:22,396
2018 及以上版本的 iPhone 和 iPad 设备
都支持数据扫描

80
00:04:22,429 --> 00:04:24,932
您还要检查下可用性

81
00:04:24,965 --> 00:04:27,801
还记得隐私使用说明吗

82
00:04:27,835 --> 00:04:31,572
如果用户允许了相机权限
以及设备没有其它限制条件

83
00:04:31,605 --> 00:04:34,374
则扫描功能可用

84
00:04:34,408 --> 00:04:37,110
如 Screen Time 的
内容和隐私限制中

85
00:04:37,144 --> 00:04:41,081
限制了 相机 App 的
访问权限

86
00:04:41,114 --> 00:04:43,584
现在 您可以配置实例了

87
00:04:43,617 --> 00:04:47,254
首先 指定您感兴趣的数据类别

88
00:04:47,287 --> 00:04:51,458
例如 您可以扫描二维码和文本

89
00:04:52,559 --> 00:04:55,829
您可以视需要发送
语言列表到文本识别器

90
00:04:55,863 --> 00:04:59,099
作为不同处理方面的提示

91
00:04:59,132 --> 00:05:01,201
如拼写纠错

92
00:05:01,235 --> 00:05:04,805
如果您知道要查找什么语言
列出来

93
00:05:04,838 --> 00:05:08,308
在两种语言脚本外观相似的情况下
这是很有用的

94
00:05:08,342 --> 00:05:10,244
如果不提供指定语言

95
00:05:10,277 --> 00:05:13,947
则默认为用户的语言偏好

96
00:05:13,981 --> 00:05:17,050
您也可以请求具体的文本内容类型

97
00:05:17,084 --> 00:05:20,554
在这一例子中
我想让扫描装置查找 URLs

98
00:05:20,587 --> 00:05:23,056
既然您已经指明了
要识别的数据类型

99
00:05:23,090 --> 00:05:26,193
就可以创建 DataScanner 实例了

100
00:05:26,226 --> 00:05:29,630
在前面的案例中
我解释了条形码符号

101
00:05:29,663 --> 00:05:33,267
识别语言和文本内容类型

102
00:05:33,300 --> 00:05:37,471
容我花几分钟解释下
它们的其它可选选项

103
00:05:37,504 --> 00:05:41,108
条形码符号方面
我们和 Vision 条码检测器

104
00:05:41,141 --> 00:05:43,877
支持的符号一样

105
00:05:43,911 --> 00:05:46,980
在语言方面
作为实况文本功能的一部分

106
00:05:47,014 --> 00:05:50,150
DataScannerViewController 支持
同样的语言

107
00:05:50,184 --> 00:05:55,455
我很高兴地说 在 iOS 16 中
我们新增支持日语和韩语

108
00:05:55,489 --> 00:05:58,325
当然 未来这也可能有
进一步的变动

109
00:05:58,358 --> 00:06:00,694
所以使用
supportedTextRecognitionLanguages

110
00:06:00,727 --> 00:06:04,498
这一类属性获得更多最新列表

111
00:06:04,531 --> 00:06:07,868
最后 当扫描有具体语义的文本时

112
00:06:07,901 --> 00:06:10,971
DataScannerViewController 可以
查找这其中类型

113
00:06:11,905 --> 00:06:14,908
我们的数据扫描器已准备好
展示给用户了

114
00:06:14,942 --> 00:06:18,846
和其它 view controller 的
展示一样 全屏

115
00:06:18,879 --> 00:06:22,883
使用表格 或将其添加到
另一个视图层级中

116
00:06:22,916 --> 00:06:24,184
您可以自行决定

117
00:06:24,218 --> 00:06:26,520
随后 展示完成后

118
00:06:26,553 --> 00:06:29,890
调出 startScanning()
开始查找数据

119
00:06:29,923 --> 00:06:32,626
所以现在 我想要倒退一步
用一点时间

120
00:06:32,659 --> 00:06:35,729
再看下数据扫描器的初始化参数

121
00:06:35,762 --> 00:06:38,365
我在这
用了 recognizedDataTypes

122
00:06:38,398 --> 00:06:42,169
但还有其它可以多样化
您的体验

123
00:06:43,136 --> 00:06:44,805
我们逐一看下

124
00:06:44,838 --> 00:06:49,243
recognizedDataTypes 可以让您
指定需要识别的数据类型

125
00:06:49,276 --> 00:06:52,946
文本 机器可读代码
以及各是什么类型

126
00:06:52,980 --> 00:06:56,183
qualityLevel 可以设置为
平衡 快或准确

127
00:06:56,216 --> 00:06:59,353
设置为快这一质量级别 则会在
识别大尺寸 清晰度高的物体时

128
00:06:59,386 --> 00:07:02,222
为确保速度牺牲分辨率

129
00:07:02,256 --> 00:07:04,024
如标志上的文本

130
00:07:04,057 --> 00:07:05,959
准确这一质量级别可以
带来高精确性

131
00:07:05,993 --> 00:07:10,998
即使是扫描微型二维码或
微小序列号

132
00:07:11,031 --> 00:07:15,636
我推荐最开始使用平衡这一级别
这在大部分场景都适用

133
00:07:15,669 --> 00:07:18,572
recognizesMultipleItems 可供您

134
00:07:18,605 --> 00:07:20,774
在一个框架内识别一个或多个物体

135
00:07:20,807 --> 00:07:23,877
比如如果您想一次识别多个条码

136
00:07:23,911 --> 00:07:26,580
当出现错误时
用户没有点击别处的情况下

137
00:07:26,613 --> 00:07:29,950
默认识别最中心的物体

138
00:07:29,983 --> 00:07:33,153
绘制高光时开启高帧率跟踪

139
00:07:33,187 --> 00:07:36,190
在相机移动或场景改变时

140
00:07:36,223 --> 00:07:39,927
高光可尽可能跟随物体

141
00:07:39,960 --> 00:07:43,130
开启或禁用
pinch-to-zoom (手势缩放)

142
00:07:43,163 --> 00:07:47,434
我们还有一些方法
让您可以自行调整缩放范围

143
00:07:47,467 --> 00:07:49,870
开启指引时 屏幕顶部
会显示对应的标签

144
00:07:49,903 --> 00:07:52,806
帮助引导用户

145
00:07:52,840 --> 00:07:56,877
最后 如果需要的话
您可以启用系统高光

146
00:07:56,910 --> 00:07:59,546
或者也可以禁用
自行绘制高光

147
00:08:00,447 --> 00:08:02,349
现在您知道如何展示
数据扫描器了

148
00:08:02,382 --> 00:08:04,985
我们来聊聊如何摄取识别物体

149
00:08:05,018 --> 00:08:07,888
以及如何绘制自定义高光

150
00:08:08,922 --> 00:08:12,326
首先 为数据扫描器提供一个代理

151
00:08:12,359 --> 00:08:13,994
有了代理后

152
00:08:14,027 --> 00:08:17,097
可以执行
dataScanner didTapOn 方法

153
00:08:17,130 --> 00:08:20,133
用户点击一个物体时
可调用此功能

154
00:08:20,167 --> 00:08:24,538
通过这一方法 您可以看到这种
全新 RecognizeItem 的实例

155
00:08:24,571 --> 00:08:29,776
RecognizedItem 是将文本或条形码
作为关联值的枚举类型

156
00:08:29,810 --> 00:08:33,647
在文本方面 转录属性
保留识别字符串

157
00:08:33,680 --> 00:08:36,383
在条形码方面 如果负载包含字符串

158
00:08:36,416 --> 00:08:39,720
您可以使用
payloadStringValue 来获取

159
00:08:39,753 --> 00:08:42,556
关于 RecognizedItem
还有两点需要知道的

160
00:08:42,589 --> 00:08:46,560
首先 每个识别物体都有一个
独特的标识符

161
00:08:46,593 --> 00:08:48,896
在它整个生命周期中
都可用其进行追踪

162
00:08:48,929 --> 00:08:51,498
这一生命周期始于
物体首次识别之时

163
00:08:51,532 --> 00:08:54,001
离开视野后则周期结束

164
00:08:54,034 --> 00:08:57,204
第二 每个 RecognizedItem
都有一个性能界限

165
00:08:57,237 --> 00:08:59,907
这一界限不是矩形
但包含有四个点

166
00:08:59,940 --> 00:09:01,441
每个角落各一个点

167
00:09:01,475 --> 00:09:04,645
接下来 我们来聊聊
场景改变时 识别物体需调用的

168
00:09:04,678 --> 00:09:07,548
三种相关代理方法

169
00:09:07,581 --> 00:09:09,516
第一种是 didAdd

170
00:09:09,550 --> 00:09:12,753
在场景中识别新物体时调用

171
00:09:12,786 --> 00:09:15,255
如果要自行绘制高光

172
00:09:15,289 --> 00:09:18,292
可以在这里为每个新物体绘制一个

173
00:09:18,325 --> 00:09:23,030
您可以根据关联值的 ID
跟踪高光

174
00:09:23,063 --> 00:09:25,866
在新的视图中加入视图层级时

175
00:09:25,899 --> 00:09:28,836
添加到 DataScanner 的
overlayContainerView 中

176
00:09:28,869 --> 00:09:33,941
这样它们可以出现在相机预览的
上层 但在其它补充浏览器下层

177
00:09:35,142 --> 00:09:37,477
下一个代理方法是 didUpdate

178
00:09:37,511 --> 00:09:40,614
在物体移动或相机移动时调用

179
00:09:40,647 --> 00:09:44,551
也可以在识别文本改变
需要转录时调用

180
00:09:44,585 --> 00:09:47,554
扫描器扫描文本时间越久

181
00:09:47,588 --> 00:09:50,791
转录越精准 因此会发生变化

182
00:09:50,824 --> 00:09:54,027
使用更新物体的 ID
从您刚创建的词典中

183
00:09:54,061 --> 00:09:56,530
获取高光

184
00:09:56,563 --> 00:10:00,767
然后将视图绘制成更新的界限

185
00:10:00,801 --> 00:10:03,437
最后是 didRemove 代理方法

186
00:10:03,470 --> 00:10:07,040
在物体从场景中消失时调用

187
00:10:07,074 --> 00:10:09,977
在这个方法中
您可以忽略所有高光视图

188
00:10:10,010 --> 00:10:12,479
与移动视图相关联

189
00:10:12,513 --> 00:10:15,282
从视图层级中移除物体

190
00:10:15,315 --> 00:10:18,218
总而言之 如果您在物体上
自行绘制高光

191
00:10:18,252 --> 00:10:20,320
这三种代理方法
在控制场景中的高光动画时

192
00:10:20,354 --> 00:10:23,323
是非常重要的

193
00:10:23,357 --> 00:10:26,927
将动作变成动画
将物体变成动画

194
00:10:26,960 --> 00:10:29,096
通过三种代理方法

195
00:10:29,129 --> 00:10:33,333
都会展示当前识别的所有物体数组

196
00:10:33,367 --> 00:10:35,702
文本识别就比较简单了

197
00:10:35,736 --> 00:10:38,705
因为物体都用自然阅读顺序排列

198
00:10:38,739 --> 00:10:41,775
意味着用户在数值 0 时就可以
阅读到物体

199
00:10:41,808 --> 00:10:45,846
在物体到达数值 1 时就可以
阅读到等等

200
00:10:45,879 --> 00:10:48,515
这是如何使用
DataScannerViewController的概述

201
00:10:48,549 --> 00:10:53,287
在结束前 我快速说下其它功能

202
00:10:53,320 --> 00:10:55,189
如捕捉照片

203
00:10:55,222 --> 00:10:57,024
您可以调用 capturePhoto 方法

204
00:10:57,057 --> 00:11:01,428
从而异步返回一个
高质量的 UIImage

205
00:11:02,462 --> 00:11:04,431
如果您没有自行绘制高光

206
00:11:04,464 --> 00:11:07,234
可能不需要这三种代理方法

207
00:11:07,267 --> 00:11:10,704
相反 您可以使用
recognizedItem 属性

208
00:11:10,737 --> 00:11:15,742
这是一种 AsyncStream
在场景改变时会持续更新

209
00:11:17,845 --> 00:11:19,379
感谢大家的观看

210
00:11:19,413 --> 00:11:21,882
记住 iOS SDK 为您提供了

211
00:11:21,915 --> 00:11:23,684
用 AVFoundation
和 Vision 框架

212
00:11:23,717 --> 00:11:26,854
搭建计算机视觉工作流的选择

213
00:11:26,887 --> 00:11:29,122
但可能您要构建一个
可从视频内容文本中

214
00:11:29,156 --> 00:11:32,025
扫描文本
或机器可读代码的 App

215
00:11:32,059 --> 00:11:33,527
如拣配和包装 App

216
00:11:33,560 --> 00:11:36,697
后台仓库 App
或销售时点情报系统 App

217
00:11:36,730 --> 00:11:38,932
如果是这样的话
那就看下 VisionKit 中的

218
00:11:38,966 --> 00:11:40,434
DataScannerViewController 吧

219
00:11:40,467 --> 00:11:42,302
如我今天所说
它有许多初始化参数

220
00:11:42,336 --> 00:11:45,706
和代理方法可供选择

221
00:11:45,739 --> 00:11:49,943
提供多样化的体验
以匹配您 App 的风格和需求

222
00:11:50,944 --> 00:11:53,113
最后 强烈推荐大家看下

223
00:11:53,146 --> 00:11:55,849
“Add Live Text interaction
to your app” 这一讲座

224
00:11:55,883 --> 00:12:00,487
您可以学习到关于
VisionKit 静态图像实况文本的功能

225
00:12:01,555 --> 00:12:03,357
下次见 祝大家平安

226
00:12:03,390 --> 00:12:08,662
[欢快的音乐]

