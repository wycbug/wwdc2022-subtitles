1
00:00:00,000 --> 00:00:03,003
♪ 柔和乐器演奏的嘻哈音乐 ♪

2
00:00:03,003 --> 00:00:10,143
♪

3
00:00:10,143 --> 00:00:14,348
嗨 我是 Vidhi Goel
在这个视频中

4
00:00:14,348 --> 00:00:19,052
我将为您介绍降低
App 网络延迟的方法

5
00:00:19,052 --> 00:00:21,722
使其更快做出响应

6
00:00:21,722 --> 00:00:25,959
首先 我会解释为什么降低延迟

7
00:00:25,959 --> 00:00:29,563
对 App 的快速响应至关重要

8
00:00:29,563 --> 00:00:31,832
其次 我将介绍

9
00:00:31,832 --> 00:00:34,902
您在 App 和服务器中

10
00:00:34,902 --> 00:00:40,240
为消除不必要的延迟
可以做的一系列工作

11
00:00:40,240 --> 00:00:44,178
最后 我将向您展示为降低延迟

12
00:00:44,178 --> 00:00:47,948
可在网络上执行的操作

13
00:00:47,948 --> 00:00:51,451
网络延迟是数据从一个端点到达

14
00:00:51,451 --> 00:00:55,055
另一个端点所需的时间

15
00:00:55,055 --> 00:00:58,725
它决定了内容传递到

16
00:00:58,725 --> 00:01:01,028
您 App 的速度

17
00:01:01,028 --> 00:01:04,531
所有使用网络的 App
都可能受到

18
00:01:04,531 --> 00:01:06,767
缓慢网络事务的影响

19
00:01:06,767 --> 00:01:11,138
从而导致 App 体验不佳

20
00:01:11,138 --> 00:01:15,676
例如 视频通话有时会卡顿

21
00:01:15,676 --> 00:01:20,380
或反应迟钝 导致会议中断

22
00:01:20,380 --> 00:01:23,550
为解决该问题 人们经常致电

23
00:01:23,550 --> 00:01:27,421
服务供应商要求升级带宽

24
00:01:27,421 --> 00:01:31,792
但问题依然存在

25
00:01:31,792 --> 00:01:34,595
为找出问题的根本

26
00:01:34,595 --> 00:01:38,265
您需了解 App 中的数据包

27
00:01:38,265 --> 00:01:40,767
在网络中的传输方式

28
00:01:40,767 --> 00:01:44,805
当您的 App 或框架
从服务器请求数据时

29
00:01:44,805 --> 00:01:48,675
数据包由网络栈发出

30
00:01:48,675 --> 00:01:52,079
通常认为数据包直接发送至

31
00:01:52,079 --> 00:01:56,216
服务器 在网络中没有延迟

32
00:01:56,216 --> 00:01:59,920
但实际上 网络中最慢的链路

33
00:01:59,920 --> 00:02:05,592
通常有很长的数据包队列需要处理

34
00:02:05,592 --> 00:02:07,561
因此 来自您 App 的数据包

35
00:02:07,561 --> 00:02:10,864
实际上也排在这个长队列后面

36
00:02:10,864 --> 00:02:16,036
要等到前面的数据包处理完毕

37
00:02:16,036 --> 00:02:19,840
在最慢链路上排队增加了数据包在

38
00:02:19,840 --> 00:02:24,745
您的 App 和服务器之间
每次往返的时间

39
00:02:24,745 --> 00:02:29,917
当需要多次往返才能首次响应

40
00:02:29,917 --> 00:02:34,855
您 App 发出的请求时
该问题会更加严重

41
00:02:34,855 --> 00:02:39,159
例如 在 TCP 上
使用 TLS 1.2 时

42
00:02:39,159 --> 00:02:43,830
得到第一个响应包的时间

43
00:02:43,830 --> 00:02:46,400
是每次往返时间

44
00:02:46,400 --> 00:02:50,871
乘以四

45
00:02:50,871 --> 00:02:54,541
由于在网络中排队

46
00:02:54,541 --> 00:02:56,810
单次往返时间已经增加

47
00:02:56,810 --> 00:03:02,216
最终总耗时只能更长

48
00:03:02,216 --> 00:03:05,152
有两个因素共同决定了

49
00:03:05,152 --> 00:03:09,156
您 App 的响应能力

50
00:03:09,156 --> 00:03:15,128
即每次往返的时间和往返次数

51
00:03:15,128 --> 00:03:18,866
减少这两个因素
可降低您 App 的延迟

52
00:03:18,866 --> 00:03:24,071
提高其响应能力

53
00:03:24,071 --> 00:03:26,607
有一项研究测试了

54
00:03:26,607 --> 00:03:30,677
增加带宽速度与降低延迟

55
00:03:30,677 --> 00:03:33,680
对页面加载时间的影响

56
00:03:33,680 --> 00:03:37,484
在第一个测试中 延迟固定不变

57
00:03:37,484 --> 00:03:44,224
带宽速度从 1
增加到 10Mb/s

58
00:03:44,224 --> 00:03:49,129
首先 将带宽速度
从 1 增加到 2Mb/s

59
00:03:49,129 --> 00:03:53,767
页面加载时间减少近 40%

60
00:03:53,767 --> 00:03:56,036
效果显著

61
00:03:56,036 --> 00:04:01,441
但宽带速度增至 4Mb/s 后
每次增速

62
00:04:01,441 --> 00:04:07,181
对页面加载时间的影响几乎为零

63
00:04:07,181 --> 00:04:11,618
这就是为什么即使升级到千兆互联网

64
00:04:11,618 --> 00:04:14,188
App 运行仍然会慢

65
00:04:14,188 --> 00:04:19,226
第二个延迟测试的结果显示

66
00:04:19,226 --> 00:04:24,097
延迟每减少 20 毫秒

67
00:04:24,097 --> 00:04:28,869
页面加载时间随之线性递减

68
00:04:28,869 --> 00:04:33,473
以上结果适用于您 App 中的

69
00:04:33,473 --> 00:04:35,642
所有网络活动

70
00:04:35,642 --> 00:04:40,414
现在 我来为您介绍
可采取哪些简单操作

71
00:04:40,414 --> 00:04:45,285
来减少延迟
使您的 App 更快响应

72
00:04:45,285 --> 00:04:48,222
您可采用新版协议显著降低

73
00:04:48,222 --> 00:04:50,624
App 的延迟

74
00:04:50,624 --> 00:04:57,097
例如 IPv6 TLS 1.3
和 HTTP/3

75
00:04:57,097 --> 00:05:01,068
您只需在 App 中的使用

76
00:05:01,068 --> 00:05:04,371
URLSession和
Network.framework API

77
00:05:04,371 --> 00:05:07,741
一旦上述协议在您的服务器上被启用

78
00:05:07,741 --> 00:05:12,880
就能自动被使用

79
00:05:12,880 --> 00:05:17,351
自协议推出以来
我们看到 HTTP/3 的使用量

80
00:05:17,351 --> 00:05:22,356
不断增加 短短一年

81
00:05:22,356 --> 00:05:28,262
20% 的网络流量
都在使用 HTTP/3 协议

82
00:05:28,262 --> 00:05:32,499
且数据仍在增长

83
00:05:32,499 --> 00:05:37,604
对比不同 HTTP 版本的
Safari 浏览器流量

84
00:05:37,604 --> 00:05:42,876
HTTP/3 的速度最快

85
00:05:42,876 --> 00:05:47,848
在将请求完成时间的中位数看做是

86
00:05:47,848 --> 00:05:50,551
往返时间的倍数时

87
00:05:50,551 --> 00:05:53,720
HTTP/3 请求所花费的
时间只有 HTTP/1 的

88
00:05:53,720 --> 00:05:57,558
一半多一点

89
00:05:57,558 --> 00:06:03,664
这意味着您 App
发送的请求会更快得到响应

90
00:06:03,664 --> 00:06:07,100
当设备从 Wi-Fi
移动到蜂窝网络时

91
00:06:07,100 --> 00:06:11,071
需要花时间重新建立新连接

92
00:06:11,071 --> 00:06:15,275
这可能会
使您的 App 处于卡顿状态

93
00:06:15,275 --> 00:06:20,614
使用连接迁移可消除卡顿

94
00:06:20,614 --> 00:06:24,685
要选择接入
请在您的 URLSession 或

95
00:06:24,685 --> 00:06:28,889
NWParameters 上
将 multipathServiceType 属性

96
00:06:28,889 --> 00:06:32,326
设置为 .handover

97
00:06:32,326 --> 00:06:39,233
启用此选项
并确保其适用您的 App

98
00:06:39,233 --> 00:06:44,338
如果您直接
用 UDP 设计自己的协议

99
00:06:44,338 --> 00:06:49,810
iOS 16 和 macOS Ventura
引进了更好的方法

100
00:06:49,810 --> 00:06:52,446
来发送数据报文

101
00:06:52,446 --> 00:06:57,584
QUIC 数据报文
比普通 UDP 优点更多

102
00:06:57,584 --> 00:07:00,787
最重要的是 QUIC 数据报文

103
00:07:00,787 --> 00:07:03,023
可对网络拥堵做出反应

104
00:07:03,023 --> 00:07:07,895
进而维持较低往返时间
并减少数据包损失

105
00:07:07,895 --> 00:07:10,030
要选择接入客户端

106
00:07:10,030 --> 00:07:13,734
需在您的 QUIC 选项上
将 isDatagram 设置为 true

107
00:07:13,734 --> 00:07:19,606
并设置您要使用的
maxDatagramFrameSize

108
00:07:19,606 --> 00:07:22,409
创建数据报文流后

109
00:07:22,409 --> 00:07:27,714
您可像任何其它 QUIC 流
一样在上面发送和接收

110
00:07:27,714 --> 00:07:30,217
现在您知道了在 App 中

111
00:07:30,217 --> 00:07:32,519
降低延迟的方法

112
00:07:32,519 --> 00:07:36,156
接下来我将解释服务器如何影响

113
00:07:36,156 --> 00:07:39,393
您 App 的响应能力

114
00:07:39,393 --> 00:07:42,763
尽管常在顶级硬件上运行

115
00:07:42,763 --> 00:07:46,667
您的服务器仍然可能

116
00:07:46,667 --> 00:07:49,303
拖慢您的 App

117
00:07:49,303 --> 00:07:54,308
我们在 macOS Monterey 中
引进了网络质量工具

118
00:07:54,308 --> 00:07:56,443
您可利用该工具

119
00:07:56,443 --> 00:08:00,480
在您的服务供应商网络以及服务器上

120
00:08:00,480 --> 00:08:03,183
测试缓冲区膨胀情况

121
00:08:03,183 --> 00:08:06,887
您需配置您的服务器为

122
00:08:06,887 --> 00:08:09,623
网络质量工具的目标

123
00:08:09,623 --> 00:08:14,394
配置完成后
运行 networkQuality 工具

124
00:08:14,394 --> 00:08:17,598
首先针对
Apple 的默认服务器

125
00:08:17,598 --> 00:08:22,569
然后针对您自己配置的服务器

126
00:08:22,569 --> 00:08:26,406
如果该工具在默认服务器上得分良好

127
00:08:26,406 --> 00:08:30,544
但在您自己的服务器上得分较差

128
00:08:30,544 --> 00:08:33,580
那可能您的服务器响应能力

129
00:08:33,580 --> 00:08:35,949
有待提高

130
00:08:35,949 --> 00:08:40,888
现在 我来向您展示
我们如何利用该技术

131
00:08:40,888 --> 00:08:45,792
改进现在大家都在做的事情

132
00:08:45,792 --> 00:08:48,695
流媒体视频

133
00:08:50,397 --> 00:08:52,399
您可能有过这样的经历

134
00:08:52,399 --> 00:08:55,869
您想将视频向前跳到某一位置

135
00:08:55,869 --> 00:09:01,808
却要花很长时间等待缓冲

136
00:09:01,808 --> 00:09:05,512
于是 我们在随机访问中调查了

137
00:09:05,512 --> 00:09:08,282
缓冲较慢的原因

138
00:09:08,282 --> 00:09:10,584
我们利用网络质量工具

139
00:09:10,584 --> 00:09:13,820
测试流媒体服务器

140
00:09:13,820 --> 00:09:18,759
发现其响应能力得分很差

141
00:09:18,759 --> 00:09:23,897
我在右侧
播放了一个 WWDC 视频

142
00:09:23,897 --> 00:09:26,900
然后 前跳该视频

143
00:09:26,900 --> 00:09:28,836
视频在缓冲时

144
00:09:28,836 --> 00:09:32,206
屏幕未显示任何画面

145
00:09:32,206 --> 00:09:36,310
几秒钟后 画面才出现

146
00:09:36,310 --> 00:09:38,679
借助 macOS 上

147
00:09:38,679 --> 00:09:41,949
网络质量工具的输出详解

148
00:09:41,949 --> 00:09:46,920
我们发现服务器上的队列很长

149
00:09:46,920 --> 00:09:52,226
所以我们看了一下服务器配置

150
00:09:52,226 --> 00:09:58,866
具体来说 我们查看了
TCP TLS 和 HTTP 缓冲区大小

151
00:09:58,866 --> 00:10:09,142
配置分别为
4MB 256K 和 4MB

152
00:10:09,142 --> 00:10:14,014
因为 RAM 充足
所以缓冲区很大

153
00:10:14,014 --> 00:10:17,451
但缓冲有用

154
00:10:17,451 --> 00:10:22,155
并不代表缓冲越多越好

155
00:10:22,155 --> 00:10:27,427
响应能力测试突出了实际的问题

156
00:10:27,427 --> 00:10:32,065
即在较大的缓冲区中
新生成的数据包

157
00:10:32,065 --> 00:10:34,168
会排在旧数据后面

158
00:10:34,168 --> 00:10:37,237
导致在传输最新数据包时

159
00:10:37,237 --> 00:10:41,241
造成了很多额外延迟

160
00:10:41,241 --> 00:10:47,981
因此 我们将
HTTP 缓冲区大小减至 256K

161
00:10:47,981 --> 00:10:54,855
TLS 减至 16K
TCP 减至 128K

162
00:10:57,691 --> 00:11:01,328
这是 Apache Traffic Server 的配置文件

163
00:11:01,328 --> 00:11:05,399
显示的是已配置的选项

164
00:11:05,399 --> 00:11:10,871
TCP 未发送低水位标记
设置为 128K

165
00:11:10,871 --> 00:11:16,977
同时启用其他选项以降低缓冲

166
00:11:16,977 --> 00:11:21,748
对于 TLS
我们启用了动态记录大小

167
00:11:21,748 --> 00:11:26,753
对于 HTTP/2
我们降低了低水位标记

168
00:11:26,753 --> 00:11:28,789
和缓冲区块大小

169
00:11:28,789 --> 00:11:31,725
我们建议
您的 Apache Traffic Server

170
00:11:31,725 --> 00:11:34,628
也使用相同配置

171
00:11:34,628 --> 00:11:38,031
如果您使用的是其他网络服务器

172
00:11:38,031 --> 00:11:41,301
请寻找等效选项

173
00:11:41,301 --> 00:11:43,737
配置完成后

174
00:11:43,737 --> 00:11:47,541
再次运行网络质量工具

175
00:11:47,541 --> 00:11:52,646
这次获得了较高的 RPM 分数！

176
00:11:52,646 --> 00:11:56,250
我在右侧播放相同视频

177
00:11:56,250 --> 00:11:58,919
但这次前跳视频时

178
00:11:58,919 --> 00:12:03,590
视频立即开始继续播放

179
00:12:03,590 --> 00:12:07,594
消除了服务器上不必要的排队

180
00:12:07,594 --> 00:12:11,698
随机访问响应就更快

181
00:12:11,698 --> 00:12:15,869
无论您的 App 如何使用网络

182
00:12:15,869 --> 00:12:20,841
在服务器上更改上述配置
都可让您的 App 更快响应

183
00:12:20,841 --> 00:12:24,878
提供更好的用户体验

184
00:12:24,878 --> 00:12:29,917
以上就是改进您的 App
并更新服务器的方法

185
00:12:29,917 --> 00:12:34,855
还有第三个因素会极大影响响应能力

186
00:12:34,855 --> 00:12:37,224
即网络本身

187
00:12:37,224 --> 00:12:41,528
Apple 在 iOS 15
和 macOS Monterey 中

188
00:12:41,528 --> 00:12:44,364
引进网络质量工具后

189
00:12:44,364 --> 00:12:48,402
也有其他使用相同的方法

190
00:12:48,402 --> 00:12:52,973
开展网络质量测试的

191
00:12:52,973 --> 00:12:56,977
Waveform 发布了
Bufferbloat 测试

192
00:12:56,977 --> 00:12:59,246
Go 编写了开源的

193
00:12:59,246 --> 00:13:03,984
响应能力测试

194
00:13:03,984 --> 00:13:07,855
Ookla 也在
其 Speedtest App 中

195
00:13:07,855 --> 00:13:11,525
添加了响应测试

196
00:13:11,525 --> 00:13:15,395
Ookla 的 App
以毫秒为单位显示往返时间

197
00:13:15,395 --> 00:13:18,966
如果用 60000 除以往返时间

198
00:13:18,966 --> 00:13:24,104
就会得到
每分钟的往返次数 或 RPM

199
00:13:24,104 --> 00:13:26,673
您可以利用以上工具来测试

200
00:13:26,673 --> 00:13:30,944
自己的网络性能

201
00:13:30,944 --> 00:13:34,114
了解网络延迟的最佳方法

202
00:13:34,114 --> 00:13:37,751
就是使用延迟敏感的 App

203
00:13:37,751 --> 00:13:41,054
所以 我将向您展示
在远程计算机上的

204
00:13:41,054 --> 00:13:43,824
屏幕共享的体验

205
00:13:43,824 --> 00:13:45,559
我设置了网络条件

206
00:13:45,559 --> 00:13:48,829
用于模仿一个有代表性的接入网络

207
00:13:48,829 --> 00:13:54,234
并有来自其他设备的流量共享该网络

208
00:13:54,234 --> 00:13:59,106
在此 我使用屏幕共享
登录到我的远程计算机

209
00:14:01,175 --> 00:14:04,378
我点击了不同的访达菜单

210
00:14:04,378 --> 00:14:09,149
但每个菜单显示得都比较迟钝

211
00:14:09,149 --> 00:14:12,553
为了检查这种
互动行为的网络延迟情况

212
00:14:12,553 --> 00:14:16,823
我在本地计算
启动了一个显示时间的 App

213
00:14:16,823 --> 00:14:21,361
并在远程计算机上
启动了相同的 App

214
00:14:21,361 --> 00:14:25,832
即便两台计算机的时间同步

215
00:14:25,832 --> 00:14:29,703
但远程屏幕并未按时更新

216
00:14:29,703 --> 00:14:34,908
显示的时间延迟了几秒钟

217
00:14:34,908 --> 00:14:37,344
延迟更新的原因

218
00:14:37,344 --> 00:14:39,980
是在网络最慢的链路上

219
00:14:39,980 --> 00:14:42,783
有一个较长的队列

220
00:14:42,783 --> 00:14:45,485
来自屏幕共享 App 的数据包

221
00:14:45,485 --> 00:14:48,822
卡在了该队列中

222
00:14:50,824 --> 00:14:53,260
为解决该队列问题

223
00:14:53,260 --> 00:14:56,029
Apple 正与网络社区合作

224
00:14:56,029 --> 00:14:59,900
共同开发
一项名为 L4S 的新技术

225
00:14:59,900 --> 00:15:06,773
该技术将在 iOS 16
和 macOS Ventura 中以 Beta 版提供

226
00:15:06,773 --> 00:15:10,110
L4S 可显著降低排队延迟

227
00:15:10,110 --> 00:15:14,748
还可实现零拥堵损失

228
00:15:14,748 --> 00:15:17,551
为维持较短排队时间

229
00:15:17,551 --> 00:15:20,420
网络会明确发出拥堵信号

230
00:15:20,420 --> 00:15:22,623
而不是丢弃数据包

231
00:15:22,623 --> 00:15:25,492
发送器会根据网络拥堵反馈

232
00:15:25,492 --> 00:15:29,530
调整发送速率

233
00:15:29,530 --> 00:15:34,134
这就可以在网络中
维持非常短的排队时间

234
00:15:34,134 --> 00:15:37,070
而不丢失数据包

235
00:15:37,070 --> 00:15:41,875
进而让您的 App 快速响应

236
00:15:41,875 --> 00:15:48,282
现在 我们来看看
L4S 如何改进屏幕共享

237
00:15:48,282 --> 00:15:52,586
这里我用了相同的计算机和网络

238
00:15:52,586 --> 00:15:57,558
不同的是 我启用了 L4S

239
00:15:57,558 --> 00:16:00,360
我在点击各个访达菜单时

240
00:16:00,360 --> 00:16:02,896
都可立即打开

241
00:16:02,896 --> 00:16:06,900
我在两台计算机上
都启动了 Time App

242
00:16:06,900 --> 00:16:09,770
现在 远程屏幕上的时间

243
00:16:09,770 --> 00:16:16,944
和本地计算机上的几乎完全同步

244
00:16:16,944 --> 00:16:21,381
L4S 技术不仅改进了屏幕共享

245
00:16:21,381 --> 00:16:25,485
还改进了现今所有的 App

246
00:16:25,485 --> 00:16:28,121
并为未来更加先进的 App

247
00:16:28,121 --> 00:16:31,959
开放了大门

248
00:16:31,959 --> 00:16:36,230
这张表绘制的是监控下

249
00:16:36,230 --> 00:16:39,166
屏幕共享 App 数据包的
平均往返时间

250
00:16:39,166 --> 00:16:41,535
该 App 与同一网络下的

251
00:16:41,535 --> 00:16:46,006
其他设备同时消耗流量

252
00:16:46,006 --> 00:16:49,510
对比常规排队与 L4S 排队

253
00:16:49,510 --> 00:16:52,713
可看出启用 L4S 后

254
00:16:52,713 --> 00:16:56,416
往返时间大大减少

255
00:16:56,416 --> 00:17:00,387
这是屏幕共享体验显著改善的

256
00:17:00,387 --> 00:17:05,158
主要原因

257
00:17:05,158 --> 00:17:11,131
要用您的 App 在 HTTP/3 或 QUIC
上测试 L4S

258
00:17:11,131 --> 00:17:16,970
您可在 iOS 16 中的
开发者设置中启用 L4S

259
00:17:16,970 --> 00:17:22,809
或在 macOS Ventura 上
通过 defaults write 来启用 L4S

260
00:17:22,809 --> 00:17:25,612
要用 Linux 服务器进行测试

261
00:17:25,612 --> 00:17:30,083
您的 QUIC 实现
需要支持 Accurate ECN

262
00:17:30,083 --> 00:17:34,521
和可扩展的拥堵控制算法

263
00:17:34,521 --> 00:17:36,623
在部署支持 L4S 的网络时

264
00:17:36,623 --> 00:17:40,227
要确保您已做好准备

265
00:17:40,227 --> 00:17:44,264
测试您的 App 与 L4S 的兼容性

266
00:17:44,264 --> 00:17:50,504
并就可能遇到的任何问题提供反馈

267
00:17:50,504 --> 00:17:54,441
您已了解了降低延迟是

268
00:17:54,441 --> 00:17:58,045
提高您 App 响应能力的关键

269
00:17:58,045 --> 00:18:02,382
因此 采用 HTTP/3 和 QUIC

270
00:18:02,382 --> 00:18:04,718
来减少往返次数

271
00:18:04,718 --> 00:18:09,823
并将内容更快速地
传输到您的 App

272
00:18:09,823 --> 00:18:13,460
消除服务器上不必要的排队

273
00:18:13,460 --> 00:18:17,364
可提高交互时的响应能力

274
00:18:17,364 --> 00:18:21,702
通过在开发者设置中启用 L4S

275
00:18:21,702 --> 00:18:25,939
可测试您的 App 与
L4S 的兼容性并提供反馈

276
00:18:25,939 --> 00:18:29,042
最后 再和您的
服务器供应商谈论一下

277
00:18:29,042 --> 00:18:32,880
启用 L4S 的支持问题即可

278
00:18:32,880 --> 00:18:34,748
感谢收看！

279
00:18:34,748 --> 00:18:39,119
♪

