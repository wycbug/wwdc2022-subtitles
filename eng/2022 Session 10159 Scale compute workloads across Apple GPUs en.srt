1
00:00:00,434 --> 00:00:06,440
[upbeat music]

2
00:00:09,309 --> 00:00:11,478
- Hello and welcome.

3
00:00:11,512 --> 00:00:13,413
My name is Marco Giordano,

4
00:00:13,447 --> 00:00:17,050
and I'm with the GPU Software
Engineering team here at Apple.

5
00:00:17,084 --> 00:00:19,620
In this session I'll talk to you about

6
00:00:19,653 --> 00:00:23,357
how to scale workloads
across Apple M1 GPUs.

7
00:00:23,390 --> 00:00:26,727
If you work on complex compute
workloads and want to know how to

8
00:00:26,760 --> 00:00:31,031
take full advantage of Apple silicon
hardware and achieve great scaling,

9
00:00:31,064 --> 00:00:33,433
this talk is the one for you.

10
00:00:33,467 --> 00:00:36,837
I will start by discussing
compute scalability concepts

11
00:00:36,870 --> 00:00:42,276
and how applications can naturally scale
performance across the M1 GPU family.

12
00:00:42,309 --> 00:00:45,846
And then, I'll share
step-by-step "how-tos"

13
00:00:45,879 --> 00:00:48,782
and talk about what tools are available

14
00:00:48,815 --> 00:00:52,252
to maximize compute scaling
for your workloads.

15
00:00:52,286 --> 00:00:55,122
Let's start by understanding
what scalability is

16
00:00:55,155 --> 00:00:57,991
and why it is important
for your workload.

17
00:00:59,293 --> 00:01:02,829
The Apple M1 GPU was designed
from the ground up to scale

18
00:01:02,863 --> 00:01:08,535
and to let your workload achieve excellent
performance across the entire SOC family.

19
00:01:08,569 --> 00:01:13,407
The same GPU supporting all Metal 3
features scales from your 8-core iPad

20
00:01:13,440 --> 00:01:16,476
all the way to your 64-core Mac Studio.

21
00:01:17,544 --> 00:01:20,214
To take advantage
of the high level of scaling,

22
00:01:20,247 --> 00:01:24,551
having an app optimized for M1
is a great starting point.

23
00:01:24,585 --> 00:01:29,089
Many prominent pro apps have already
been optimized for Apple M1

24
00:01:29,122 --> 00:01:33,260
and have been experiencing
excellent scaling across all devices.

25
00:01:34,962 --> 00:01:39,933
For example, here we have
Affinity Photo and DaVinci Resolve--

26
00:01:39,967 --> 00:01:43,971
photo and video editors from
the post-production industry.

27
00:01:44,004 --> 00:01:47,608
These apps are achieving great scaling.

28
00:01:47,641 --> 00:01:53,447
Let's define what scalability really means
and how you can achieve "ideal" scaling.

29
00:01:53,480 --> 00:01:58,385
GPU workload scalability
is the capacity to improve performance

30
00:01:58,418 --> 00:02:01,555
with an increased number of GPU cores.

31
00:02:01,588 --> 00:02:04,658
The chart on the right
shows application speed-up

32
00:02:04,691 --> 00:02:07,194
with an increasing GPU cores count.

33
00:02:07,227 --> 00:02:10,964
Linear proportion improvement
is considered ideal.

34
00:02:12,232 --> 00:02:16,403
However, while working on your app,
you might notice a type of scaling

35
00:02:16,436 --> 00:02:20,307
which hits a plateau and scales with
diminishing returns,

36
00:02:20,340 --> 00:02:24,945
or doesn't scale at all
due to gaps in the GPU timeline.

37
00:02:25,579 --> 00:02:29,983
Or you might see another type scaling
where the performance improves

38
00:02:30,017 --> 00:02:32,819
but not uniformly across the stack

39
00:02:32,853 --> 00:02:37,157
where the workload
is hitting some GPU limiters,

40
00:02:37,191 --> 00:02:42,930
like here, between 24 to 32
or 48 to 64 cores.

41
00:02:44,431 --> 00:02:48,569
Your goal is to get as close as
possible to linear scaling,

42
00:02:48,602 --> 00:02:51,338
and I will show you
the tools and techniques

43
00:02:51,371 --> 00:02:55,108
to identify bottlenecks and
achieve the result you want.

44
00:02:56,276 --> 00:03:01,682
In the next section I will discuss the
approaches to maximize GPU scaling.

45
00:03:01,715 --> 00:03:06,954
For every workload, you should
first identify where the bottleneck is.

46
00:03:06,987 --> 00:03:11,225
Workloads can be limited either by
computation or bandwidth.

47
00:03:11,258 --> 00:03:14,027
During the optimization process,

48
00:03:14,061 --> 00:03:16,930
you might end up
bouncing between one and the other.

49
00:03:16,964 --> 00:03:21,635
If you are computational-bound,
you might try to shift some of the load

50
00:03:21,668 --> 00:03:26,039
to leverage memory
to reduce computation, or vice versa.

51
00:03:26,073 --> 00:03:29,576
Bottlenecks can shift when you scale up.

52
00:03:29,610 --> 00:03:32,379
One good solution could be
using Apple frameworks

53
00:03:32,412 --> 00:03:34,982
like MPS or MPSGraph.

54
00:03:35,015 --> 00:03:37,184
if you can leverage their primitives,

55
00:03:37,217 --> 00:03:41,522
we made sure every compute kernel
runs best on all the hardware.

56
00:03:41,555 --> 00:03:44,725
However, you
can't replace everything with MPS,

57
00:03:44,758 --> 00:03:48,529
so it is critical to profile
and understand your workload.

58
00:03:50,297 --> 00:03:51,164
I will first cover three items
that can help minimize GPU gaps:

59
00:03:54,868 --> 00:03:58,839
Improve your work distribution,
eliminate GPU timeline gaps,

60
00:03:58,872 --> 00:04:01,508
and atomics operation considerations.

61
00:04:02,476 --> 00:04:06,613
Then I will explain
how to optimize for GPU limiters

62
00:04:06,647 --> 00:04:10,951
by first investigating the effect of
compute grid shapes

63
00:04:10,984 --> 00:04:13,387
and memory layouts of your workload

64
00:04:13,420 --> 00:04:18,892
and finally by looking
at a specific example in Blender Cycles.

65
00:04:18,926 --> 00:04:22,362
Start by focusing on minimizing GPU gaps.

66
00:04:22,396 --> 00:04:26,967
This kind of scaling can be the result
of the GPU not being fully utilized,

67
00:04:27,000 --> 00:04:30,070
with gaps in the GPU timeline
where the hardware is idle.

68
00:04:32,139 --> 00:04:35,976
Let's see if we can improve scaling by
investigating work distribution.

69
00:04:37,544 --> 00:04:41,715
Small workloads
usually do not saturate the whole GPU,

70
00:04:41,748 --> 00:04:44,418
and kernel synchronization has its cost,

71
00:04:44,451 --> 00:04:47,955
so both can prevent proper scaling.

72
00:04:47,988 --> 00:04:53,093
It is very important to understand how
the workload gets mapped to the hardware,

73
00:04:53,126 --> 00:04:54,928
so let's talk about it.

74
00:04:55,696 --> 00:05:00,267
A workload is dispatched in the form
of a 3D grid of threadgroups.

75
00:05:00,300 --> 00:05:04,137
Threadgroups are uniformly
distributed to the GPU cores

76
00:05:04,171 --> 00:05:08,976
and have access to threadgroup memory,
which is limited in size,

77
00:05:09,009 --> 00:05:11,945
but very fast, local to the GPU core.

78
00:05:12,913 --> 00:05:16,783
A single threadgroup is further
broken down into SIMD-groups,

79
00:05:16,817 --> 00:05:21,088
which are also known as waves or warps
in other compute dialects.

80
00:05:21,989 --> 00:05:26,059
Checking the "threadExecutionWidth"
on the compute pipeline state object

81
00:05:26,093 --> 00:05:28,161
will return the SIMD width,

82
00:05:28,195 --> 00:05:31,765
and on all Apple GPUs,
it is equal to 32.

83
00:05:33,033 --> 00:05:37,337
Threadgroups can have up to
1024 threads per threadgroup

84
00:05:37,371 --> 00:05:41,575
and threads can share up to
32K of threadgroup memory.

85
00:05:42,876 --> 00:05:45,679
To keep the GPU busy,
there should be enough work to do

86
00:05:45,712 --> 00:05:47,347
on all the GPU cores.

87
00:05:48,749 --> 00:05:51,618
Here is an example of a grid to dispatch.

88
00:05:51,652 --> 00:05:54,555
Threadgroups are dispatched
to GPU Clusters

89
00:05:54,588 --> 00:05:58,091
and distributed among GPU cores.

90
00:05:59,159 --> 00:06:01,228
If there are too few threadgroups,

91
00:06:01,261 --> 00:06:04,565
the workload
won't fully saturate the machine.

92
00:06:04,598 --> 00:06:06,033
Here's how to fix this.

93
00:06:08,101 --> 00:06:11,438
Start by computing
how many threads the workload produces

94
00:06:11,471 --> 00:06:15,475
and roughly see if the dispatch
will saturate the whole machine.

95
00:06:16,410 --> 00:06:22,082
For relatively complex kernels, 1K to 2K
concurrent threads per shader core

96
00:06:22,115 --> 00:06:24,651
is considered a very good occupancy,

97
00:06:24,685 --> 00:06:30,591
so take 1 to 2K threads per GPU core as
a rule of thumb.

98
00:06:30,624 --> 00:06:35,596
Now you can compute if you have enough
work to fully saturate the hardware.

99
00:06:35,629 --> 00:06:39,032
The table here shows the lowest
recommended number of threads

100
00:06:39,066 --> 00:06:41,301
to saturate different SOCs.

101
00:06:43,670 --> 00:06:45,739
Another thing to consider
would be avoiding

102
00:06:45,772 --> 00:06:48,909
using unnecessarily large
threadgroup sizes.

103
00:06:48,942 --> 00:06:54,481
Making threadgroups smaller will map
the load to the hardware more uniformly.

104
00:06:54,515 --> 00:06:58,752
Using larger threadgroups might prevent
a more uniform distribution,

105
00:06:58,785 --> 00:07:01,588
leading to imbalance in the GPU cores.

106
00:07:02,890 --> 00:07:05,926
It's best to use
the smallest multiple of the SIMD width

107
00:07:05,959 --> 00:07:07,995
that maps well to your workload.

108
00:07:08,629 --> 00:07:12,165
By using smaller threadgroups,
the GPU has more opportunities

109
00:07:12,199 --> 00:07:14,668
to better balance its workload.

110
00:07:16,170 --> 00:07:19,039
Please always check your
kernel runtime performance

111
00:07:19,072 --> 00:07:21,942
with Xcode or Instruments GPU Tools.

112
00:07:23,443 --> 00:07:28,882
In this GPU capture, for example, there is
a kernel performing some computation.

113
00:07:28,916 --> 00:07:32,653
Occupancy is pretty low,
which is unexpected.

114
00:07:32,686 --> 00:07:36,089
The compiler statistics show
that max theoretical occupancy,

115
00:07:36,123 --> 00:07:40,060
which is new in Xcode 14, is 100%.

116
00:07:40,093 --> 00:07:43,997
This indicates there might not
be enough threads--and indeed,

117
00:07:44,031 --> 00:07:48,569
we can see the algorithms starts
to dispatch fewer and fewer threads,

118
00:07:48,602 --> 00:07:50,604
not saturating the machine anymore.

119
00:07:51,805 --> 00:07:54,975
Low occupancy
might have several other causes.

120
00:07:55,008 --> 00:08:01,014
To get all the details, check the
Metal Compute on MacBook Pro Tech talk.

121
00:08:01,849 --> 00:08:05,152
OK, now that workload
is correctly distributed,

122
00:08:05,185 --> 00:08:08,655
it's time to make sure the GPU
is always busy.

123
00:08:09,957 --> 00:08:13,393
Under-utilizing the GPU
never leads to ideal scaling,

124
00:08:13,427 --> 00:08:18,131
and the worst case
of under-utilizing is keeping it idle.

125
00:08:18,165 --> 00:08:21,768
The GPU can be idle
because of GPU timeline gaps.

126
00:08:23,971 --> 00:08:26,807
Consider this example.

127
00:08:26,840 --> 00:08:30,110
Here is a workload
using only 50% of the GPU

128
00:08:30,143 --> 00:08:34,248
due to work serialization
between CPU and GPU.

129
00:08:34,281 --> 00:08:39,152
In this case, overall task duration
is the sum of CPU and GPU work

130
00:08:39,186 --> 00:08:41,455
with no overlaps.

131
00:08:42,489 --> 00:08:46,727
Doubling the GPU cores makes
the GPU track complete faster,

132
00:08:46,760 --> 00:08:49,796
but the CPU track is not affected.

133
00:08:49,830 --> 00:08:56,103
Overall performance increases only by 33%,
far from ideal scaling.

134
00:08:57,237 --> 00:09:02,676
If the GPU cores are doubled again,
the workload is even faster on the GPU,

135
00:09:02,709 --> 00:09:08,315
but overall latency is reduced by
only 60% compared to the original time!

136
00:09:08,348 --> 00:09:13,053
So GPU cores scaling brings
diminishing returns in such cases.

137
00:09:13,086 --> 00:09:16,089
This is far from ideal.
Let's fix it!

138
00:09:17,858 --> 00:09:23,397
This Instrument trace from a M1 pro
shows big GPU timeline gaps,

139
00:09:23,430 --> 00:09:26,667
and this will clearly prevent
proper scaling.

140
00:09:28,035 --> 00:09:31,738
On M1 Ultra the same workload
is indeed a bit faster,

141
00:09:31,772 --> 00:09:34,441
but the GPU idle time became higher

142
00:09:34,474 --> 00:09:38,278
and the workload is not scaling well.

143
00:09:38,312 --> 00:09:41,348
The big gaps are caused by
CPU synchronization

144
00:09:41,381 --> 00:09:44,651
using the waitUntilCompleted
on the command buffer.

145
00:09:45,552 --> 00:09:49,189
After changing the waiting logic
and removing serialization,

146
00:09:49,223 --> 00:09:53,327
the GPU became fully utilized,
which is great.

147
00:09:54,661 --> 00:09:56,029
Comparing the workload scaling

148
00:09:56,063 --> 00:09:57,030
before and after,

149
00:09:57,064 --> 00:09:58,765
we can state that the scaling

150
00:09:58,799 --> 00:10:01,635
became much closer to the ideal scaling.

151
00:10:03,403 --> 00:10:06,773
In the previous example,
it was possible to remove

152
00:10:06,807 --> 00:10:09,810
CPU/GPU synchronization altogether,

153
00:10:09,843 --> 00:10:15,482
however this is not always the case,
due to your application nature.

154
00:10:15,516 --> 00:10:20,587
There are other approaches you can take
to reduce idle time.

155
00:10:20,621 --> 00:10:23,724
Use MTLSharedEvents to signal the CPU,

156
00:10:23,757 --> 00:10:27,961
pipeline more work,
consider using GPU-driven encoding,

157
00:10:27,995 --> 00:10:30,497
and using concurrent dispatches.

158
00:10:30,531 --> 00:10:35,335
So let's discuss those approaches
to minimize GPU timeline gaps.

159
00:10:35,369 --> 00:10:37,905
Some of them might fit your workflow.

160
00:10:39,139 --> 00:10:44,378
Waiting on the CPU for GPU completion
leads to not ideal scaling.

161
00:10:44,411 --> 00:10:46,947
If your application
is using WaitUntilCompleted,

162
00:10:46,980 --> 00:10:50,584
you might want to try to use
MTLSharedEvents instead.

163
00:10:51,919 --> 00:10:54,555
MTLSharedEvents have lower overhead

164
00:10:54,588 --> 00:10:57,724
and can help you reduce the timeline gaps.

165
00:10:57,758 --> 00:10:58,959
The next thing to consider

166
00:10:58,992 --> 00:11:01,228
is pipelining the workload.

167
00:11:02,329 --> 00:11:04,498
If the algorithm has the data necessary

168
00:11:04,531 --> 00:11:06,633
for the next batch to work on,

169
00:11:06,667 --> 00:11:09,937
it's possible to encode one or
more batches in advance

170
00:11:09,970 --> 00:11:12,973
before waiting on the MTLSharedEvents.

171
00:11:13,006 --> 00:11:15,843
By doing so,
the GPU will not become drained

172
00:11:15,876 --> 00:11:18,312
and will always have work to process.

173
00:11:19,713 --> 00:11:23,116
If work can't be encoded
in advance on the same queue,

174
00:11:23,150 --> 00:11:26,787
consider using a second queue
to overlap work.

175
00:11:26,820 --> 00:11:30,424
Using multiple queues allows you
to submit independent work,

176
00:11:30,457 --> 00:11:33,026
and they do not stall
the other submission thread

177
00:11:33,060 --> 00:11:35,462
when waiting on an event.

178
00:11:35,495 --> 00:11:40,067
This way, the GPU has the chance
to keep receiving and processing work.

179
00:11:41,602 --> 00:11:46,807
In some cases, an algorithm
can encode work directly from the GPU.

180
00:11:47,841 --> 00:11:49,576
Using indirect command buffer,

181
00:11:49,610 --> 00:11:53,380
you can move the encoding of the
next batch directly on the GPU,

182
00:11:53,413 --> 00:11:56,416
avoiding any need for synchronization.

183
00:11:56,450 --> 00:12:00,153
For more details about indirect
command buffers, please check

184
00:12:00,187 --> 00:12:02,456
"Modern Rendering with Metal."

185
00:12:02,489 --> 00:12:06,527
The workload now removes
or minimizes expensive synchronizations

186
00:12:06,560 --> 00:12:09,763
between CPU and GPU as much as possible.

187
00:12:09,796 --> 00:12:15,035
But even with a busy GPU timeline,
scaling challenges may still exist.

188
00:12:15,068 --> 00:12:17,137
Let's investigate.

189
00:12:17,171 --> 00:12:19,973
This graph
is from an image processing workload

190
00:12:20,007 --> 00:12:23,744
where images are processed
1 frame at a time.

191
00:12:23,777 --> 00:12:28,982
A lot of back-to-back compute serial
dispatches can also limit scaling.

192
00:12:29,016 --> 00:12:31,718
The GPU is busy,
but kernel synchronization

193
00:12:31,752 --> 00:12:36,223
has a cost and additionally,
every dispatch has a small ramp up

194
00:12:36,256 --> 00:12:38,392
where the threadgroups
are being distributed

195
00:12:38,425 --> 00:12:41,361
and not yet saturating the cores.

196
00:12:41,395 --> 00:12:45,032
Likewise, when threadgroups
finish and retire,

197
00:12:45,065 --> 00:12:49,303
there might not be enough work
to fully saturate the cores anymore.

198
00:12:49,336 --> 00:12:54,174
In this situation, the advice is to
overlap independent work when possible.

199
00:12:54,208 --> 00:12:56,810
Let's see a visual example.

200
00:12:56,844 --> 00:13:00,747
Here we have a workload processing
two images, one after the other.

201
00:13:00,781 --> 00:13:04,017
Normally, kernels need to
synchronize between each other.

202
00:13:04,051 --> 00:13:07,688
However, this is not the only
way to schedule work.

203
00:13:07,721 --> 00:13:13,327
You can interleave independent work of
two images using concurrent dispatches.

204
00:13:13,360 --> 00:13:16,730
Here the driver is able to
interleave different work,

205
00:13:16,763 --> 00:13:19,299
thanks to concurrent dispatches.

206
00:13:19,333 --> 00:13:22,402
We can see that the two kernels
that previously were back-to-back

207
00:13:22,436 --> 00:13:27,140
are now separated
by some independent work.

208
00:13:27,174 --> 00:13:30,644
However,
when you use MTLDispatchTypeConcurrent,

209
00:13:30,677 --> 00:13:33,780
barriers must be put in manually.

210
00:13:33,814 --> 00:13:38,118
Concurrent dispatches enable the
driver to pack the work more tightly,

211
00:13:38,151 --> 00:13:42,222
hiding most of the synchronization cost
between dependent kernels,

212
00:13:42,256 --> 00:13:47,427
as well as fill the ramp up
and tail end of the various kernels.

213
00:13:47,461 --> 00:13:50,764
This optimization greatly improved
the workload performance

214
00:13:50,797 --> 00:13:55,402
and scaling when
moving from M1 Max to M1 Ultra.

215
00:13:55,435 --> 00:13:59,506
The workload runs 30% faster
with two images interleaved,

216
00:13:59,540 --> 00:14:04,811
70% faster with 3 images in parallel,
compared to the previous scaling.

217
00:14:07,014 --> 00:14:11,652
It's important to carefully consider
atomic operations that kernels are doing.

218
00:14:11,685 --> 00:14:15,422
Let's make sure it is made in
the most efficient way.

219
00:14:15,455 --> 00:14:19,126
Atomic operation
allows reading and writing data

220
00:14:19,159 --> 00:14:22,229
from multiple threads in a safe manner.

221
00:14:22,262 --> 00:14:26,333
Global atomics
are coherent across the whole GPU.

222
00:14:26,366 --> 00:14:29,937
When many threads attempt to
read and write the same global value,

223
00:14:29,970 --> 00:14:32,472
this leads to contention.

224
00:14:32,506 --> 00:14:38,445
Increasing numbers of GPU cores doesn't
help and in fact leads to more contention.

225
00:14:38,478 --> 00:14:41,682
Let's investigate how you can
improve atomics behavior

226
00:14:41,715 --> 00:14:44,051
in an algorithm with an example.

227
00:14:45,719 --> 00:14:49,356
Here is a reduction algorithm,
where all of the values in a buffer

228
00:14:49,389 --> 00:14:51,792
will be summed up together.

229
00:14:51,825 --> 00:14:54,928
The simplest approach is to perform
an atomic add operation

230
00:14:54,962 --> 00:14:57,464
per thread in main memory.

231
00:14:57,497 --> 00:15:02,603
However, this is not ideal because
that puts a great level of pressure

232
00:15:02,636 --> 00:15:08,008
on a single value in main memory,
effectively serializing each memory write.

233
00:15:09,376 --> 00:15:11,945
There are two things that the
hardware offers to help with

234
00:15:11,979 --> 00:15:14,381
atomic memory contention:

235
00:15:14,414 --> 00:15:16,950
Simd-group instruction
and threadgroup atomics.

236
00:15:18,585 --> 00:15:24,291
SIMD instructions like prefix_exlusive sum
and simd_min and many more

237
00:15:24,324 --> 00:15:28,161
allow to do operations and
exchange memory between registers

238
00:15:28,195 --> 00:15:31,932
in a SIMD-group
without round trip to memory.

239
00:15:31,965 --> 00:15:35,769
Threadgroup atomics are fulfilled by
the threadgroup memory.

240
00:15:35,802 --> 00:15:38,839
Each GPU core
has its own threadgroup memory

241
00:15:38,872 --> 00:15:42,476
allowing to scale
with the number of GPU cores.

242
00:15:42,509 --> 00:15:46,847
Let's see how these two features
can help you improve your workload.

243
00:15:48,549 --> 00:15:50,617
Here we have
the same reduction problem,

244
00:15:50,651 --> 00:15:54,321
but this time it start using
a SIMD-group instruction,

245
00:15:54,354 --> 00:15:56,390
an inclusive memory sum.

246
00:15:56,423 --> 00:16:01,094
Such operation will leave the sum
of all the numbers in the SIMD-group

247
00:16:01,128 --> 00:16:03,664
in the last thread.

248
00:16:03,697 --> 00:16:08,001
The last thread from each SIMD-group
can then perform a single atomic add

249
00:16:08,035 --> 00:16:12,739
in threadgroup memory to reduce
all SIMD-groups to a single value

250
00:16:12,773 --> 00:16:14,908
in threadgroup memory.

251
00:16:14,942 --> 00:16:19,246
In this way, using SIMD-group
instruction and threadgroup memory,

252
00:16:19,279 --> 00:16:24,484
a whole threadgroup was reduced
without touching main memory at all.

253
00:16:24,518 --> 00:16:28,488
Each group will be able to reduce
independently and in parallel.

254
00:16:29,823 --> 00:16:32,926
Now that each threadgroup has
been reduced to a single value,

255
00:16:32,960 --> 00:16:35,229
one thread per threadgroup can perform

256
00:16:35,262 --> 00:16:37,898
a single atomic in main memory.

257
00:16:37,931 --> 00:16:39,666
Not only this requires only

258
00:16:39,700 --> 00:16:41,201
one atomic per threadgroup,

259
00:16:41,235 --> 00:16:43,136
but since threadgroups complete

260
00:16:43,170 --> 00:16:44,771
at different times,

261
00:16:44,805 --> 00:16:47,107
it scatters atomics over time,

262
00:16:47,140 --> 00:16:50,677
reducing memory contention even further.

263
00:16:50,711 --> 00:16:54,114
To recap,
to maximize atomics effectiveness,

264
00:16:54,147 --> 00:16:59,119
try to leverage memory locality,
try to use SIMD-group operation,

265
00:16:59,152 --> 00:17:02,756
as well as to leverage
threadgroup memory atomics.

266
00:17:02,789 --> 00:17:07,628
All this should greatly help reduce atomic
operation pressure that prevents scaling.

267
00:17:08,829 --> 00:17:15,035
Now that GPU gaps are fixed, it's time
to see if the scaling is closer to ideal.

268
00:17:15,068 --> 00:17:19,706
GPU Limiters in Xcode and
Metal System Trace help to optimize

269
00:17:19,740 --> 00:17:25,179
any bottlenecks and inefficiencies in GPU
cores execution pipeline.

270
00:17:25,212 --> 00:17:28,382
For example,
inefficient memory access patterns

271
00:17:28,415 --> 00:17:33,020
always cause high Last Level Cache
or Memory Management Unit,

272
00:17:33,053 --> 00:17:36,723
or MMU limiters,
and pretty low utilizations.

273
00:17:36,757 --> 00:17:43,497
The first thing to address is the way
to tune threadgroups and memory layout.

274
00:17:43,530 --> 00:17:46,200
The key in reducing memory span
and divergence

275
00:17:46,233 --> 00:17:50,537
is to have a clear understanding
of the workload memory access pattern,

276
00:17:50,571 --> 00:17:54,007
both spatially and temporally.

277
00:17:54,041 --> 00:17:58,312
Once that's understood,
there are two possible tuning directions:

278
00:17:58,345 --> 00:18:01,915
Re-organize the data layout to improve
data access locality,

279
00:18:01,949 --> 00:18:05,953
or tune the access pattern
to better match the data layout

280
00:18:05,986 --> 00:18:09,056
and improve memory and cache locality.

281
00:18:09,089 --> 00:18:10,490
Let's see an example.

282
00:18:12,659 --> 00:18:16,663
Here it is a memory buffer
where the data is laid out horizontally,

283
00:18:16,697 --> 00:18:18,732
one row after the other.

284
00:18:18,765 --> 00:18:21,802
However, when the compute kernel
is dispatched,

285
00:18:21,835 --> 00:18:24,404
it is common to have a 2D like pattern

286
00:18:24,438 --> 00:18:27,374
with square threadgroups
being distributed,

287
00:18:27,407 --> 00:18:29,843
which is quite spatially localized.

288
00:18:29,877 --> 00:18:34,414
This access pattern and data layout
is not great for data locality.

289
00:18:36,216 --> 00:18:39,653
For example, when the first
SIMD-group access the data,

290
00:18:39,686 --> 00:18:42,322
the requests are packed in a cache lines.

291
00:18:42,356 --> 00:18:44,992
Most of the cache line won't be used,

292
00:18:45,025 --> 00:18:50,063
however still
occupying space in the cache.

293
00:18:50,097 --> 00:18:53,100
Re-arrange the data to fit
the access pattern better,

294
00:18:53,133 --> 00:18:56,837
where, for example,
instead of spanning the whole row,

295
00:18:56,870 --> 00:18:59,940
it is localized into stripes.

296
00:19:01,008 --> 00:19:04,144
With this new memory layout,
a threadgroup will be able

297
00:19:04,178 --> 00:19:07,080
to utilize
most of the data that will be requested

298
00:19:07,114 --> 00:19:11,585
in a cache line, reducing divergence
and improving cache efficiency.

299
00:19:12,586 --> 00:19:16,089
The other option is to change
how the 3D grid is dispatched

300
00:19:16,123 --> 00:19:19,126
to better fit the current data layout.

301
00:19:19,159 --> 00:19:23,664
Try to play with the threadgroup
size to create groups that map better

302
00:19:23,697 --> 00:19:27,768
to your memory layout,
like a more rectangular shape,

303
00:19:27,801 --> 00:19:29,670
for example.

304
00:19:29,703 --> 00:19:33,440
In this case, the access pattern
is aligned with the memory layout,

305
00:19:33,473 --> 00:19:36,977
giving a much higher cache efficiency.

306
00:19:37,010 --> 00:19:41,415
You might need to experiment
to find the best fit for your workload.

307
00:19:41,448 --> 00:19:44,418
Sometimes
you might need to make trade-offs,

308
00:19:44,451 --> 00:19:49,756
sacrifice thread divergence
for memory locality, or vice versa,

309
00:19:49,790 --> 00:19:54,661
change your data layout, grid dispatch,
or a combination of them all.

310
00:19:54,695 --> 00:19:57,631
Every workload and access pattern
is different.

311
00:20:00,100 --> 00:20:03,270
Now that you're aware of ways
to improve memory locality,

312
00:20:03,303 --> 00:20:06,273
let's see a more concrete example
in Blender Cycles.

313
00:20:08,408 --> 00:20:13,680
Cycles is Blender's physically-based
path tracer for production rendering.

314
00:20:13,714 --> 00:20:17,885
It is designed to provide physically
based results out-of-the-box,

315
00:20:17,918 --> 00:20:22,422
with artistic control and flexible
shading nodes for production needs.

316
00:20:24,258 --> 00:20:30,230
This Instrument trace clearly shows low
Read Bandwidth, high Top GPU Limiter,

317
00:20:30,264 --> 00:20:34,368
high Cache Limiter
and low Last Level Cache Utilization.

318
00:20:36,170 --> 00:20:41,975
Keeping bandwidth and MMU limiters
in control is important for scaling.

319
00:20:42,009 --> 00:20:45,679
If your Top limiter is the Last
Level Cache or MMU,

320
00:20:45,712 --> 00:20:50,551
you need to reduce your memory span
and maximize data locality.

321
00:20:50,584 --> 00:20:52,152
Let's see an example.

322
00:20:53,887 --> 00:20:57,958
Cycles use sorting of data
to try to reduce divergence.

323
00:20:57,991 --> 00:21:01,762
It does that by sorting
the ray hits by material type.

324
00:21:01,795 --> 00:21:04,131
This is great to reduce thread divergence,

325
00:21:04,164 --> 00:21:07,401
but it increases
spatial memory divergence,

326
00:21:07,434 --> 00:21:11,004
resulting in a high MMU Limiter.

327
00:21:11,038 --> 00:21:14,641
To help with this, we experimented with
partitioning the memory range

328
00:21:14,675 --> 00:21:17,711
before sorting to increase data locality.

329
00:21:17,744 --> 00:21:18,579
Let's visualize it.

330
00:21:18,612 --> 00:21:24,051
When rays are shot into the scene
to simulate light traveling,

331
00:21:24,084 --> 00:21:28,055
they hit objects and data is
collected into buffers.

332
00:21:28,088 --> 00:21:30,958
At the point of intersection
we know many things--

333
00:21:30,991 --> 00:21:34,728
the material type that was
hit, like glass, metal and so on,

334
00:21:34,761 --> 00:21:39,099
the intersection position,
the ray, and more.

335
00:21:39,132 --> 00:21:43,303
For simplicity,
let's focus on the material type only.

336
00:21:43,337 --> 00:21:45,906
Here are the materials
in a buffer in memory.

337
00:21:47,341 --> 00:21:49,910
Since a lot of data
is gathered per ray hit,

338
00:21:49,943 --> 00:21:53,380
the memory buffer can become quite large.

339
00:21:53,413 --> 00:21:55,616
To avoid moving a lot of memory around,

340
00:21:55,649 --> 00:22:00,521
populate a list of indices
and sort those instead.

341
00:22:00,554 --> 00:22:03,957
After the sort,
the indices for the same material type

342
00:22:03,991 --> 00:22:06,560
are now packed closed together.

343
00:22:06,593 --> 00:22:11,932
SIMD-groups can start loading
the indices and process the materials.

344
00:22:11,965 --> 00:22:15,269
The SIMD-group will use the index
to load the corresponding data

345
00:22:15,302 --> 00:22:16,837
in the original buffer.

346
00:22:18,472 --> 00:22:22,576
However, the SIMD-group would be
reading across the whole memory span,

347
00:22:22,609 --> 00:22:25,279
putting pressure on the MMU.

348
00:22:25,312 --> 00:22:27,981
Let's investigate the new approach.

349
00:22:28,015 --> 00:22:31,985
The memory range is partitioned
in an idealized partition

350
00:22:32,019 --> 00:22:36,390
that simply won't
let indices from different partition mix.

351
00:22:36,423 --> 00:22:41,962
When sorting, it is apparent that
the range of data accessed is contained

352
00:22:41,995 --> 00:22:46,733
inside the partition instead of spanning
the full memory range like before.

353
00:22:46,767 --> 00:22:52,739
It is a trade-off and balance between
thread divergence and memory divergence.

354
00:22:52,773 --> 00:22:55,609
The number of partitions
and size that is ideal

355
00:22:55,642 --> 00:22:58,078
is highly dependent on the workload.

356
00:22:58,111 --> 00:23:02,216
You might have to experiment
to see which one works best.

357
00:23:02,249 --> 00:23:07,421
Let's take another Metal System Trace
and let see if the workload improved.

358
00:23:07,454 --> 00:23:11,124
Here we see the limiters and
utilizations for the optimized version.

359
00:23:11,158 --> 00:23:17,364
The Top Performance limiter went down,
as well as Last Level Cache limiter.

360
00:23:17,397 --> 00:23:22,436
As a result, bandwidth and shader runtime
substantially improved.

361
00:23:22,469 --> 00:23:24,137
Let's see how much.

362
00:23:24,171 --> 00:23:28,976
Top limiter and LLC limiter
reduced by around 20%.

363
00:23:29,009 --> 00:23:32,145
That means data flow is more efficient.

364
00:23:32,179 --> 00:23:35,215
GPU Read bandwidth increased
significantly,

365
00:23:35,249 --> 00:23:38,652
allowing to push more data
to the GPU cores.

366
00:23:39,987 --> 00:23:43,557
Overall, increasing
memory locality with this experiment

367
00:23:43,590 --> 00:23:48,896
improved performance between
10 to 30%, depending on the scene.

368
00:23:48,929 --> 00:23:54,034
This was just an example of many ways you
can try to improve memory access pattern.

369
00:23:54,067 --> 00:23:58,472
Keep experimenting and optimizing
for the Top Performance Limiter.

370
00:23:58,505 --> 00:24:02,476
The GPU tools have more useful
counters to tune for.

371
00:24:03,677 --> 00:24:08,916
Xcode has a new theoretical occupancy
in the compiler statistic window.

372
00:24:08,949 --> 00:24:15,556
Both Xcode and Instruments now have
several MMU related limiters and counters,

373
00:24:15,589 --> 00:24:20,060
specifically a new MMU Limiter,
MMU Utilization Counter,

374
00:24:20,093 --> 00:24:23,130
and MMU TLB Miss Rate Counter.

375
00:24:24,431 --> 00:24:27,301
I have covered a lot of ground today.

376
00:24:27,334 --> 00:24:31,972
I discussed GPU scalability and how
bottlenecks can shift when scaling up,

377
00:24:32,005 --> 00:24:36,009
and how the tools can help
you find and fix scalability issues.

378
00:24:36,043 --> 00:24:40,147
I also discussed how you might
need to experiment and make trade-offs

379
00:24:40,180 --> 00:24:43,417
to get the best result
for your application.

380
00:24:43,450 --> 00:24:47,855
I am looking forward to seeing all
your great apps scale amazingly well

381
00:24:47,888 --> 00:24:48,956
on Apple silicon.

382
00:24:48,989 --> 00:24:50,624
Thank you for watching.

