1
00:00:00,000 --> 00:00:03,003
♪ Mellow instrumental
hip-hop music ♪

2
00:00:03,003 --> 00:00:09,810
♪

3
00:00:09,810 --> 00:00:11,879
Hao Tang: Hi, my name is Hao.

4
00:00:11,879 --> 00:00:15,115
I'm an engineer
on the Object Capture team.

5
00:00:15,115 --> 00:00:18,986
Today, my colleague Risa and I
will be showing you how to use

6
00:00:18,986 --> 00:00:21,989
the Object Capture API
and RealityKit

7
00:00:21,989 --> 00:00:25,325
to create 3D models
of real-world objects

8
00:00:25,325 --> 00:00:27,628
and bring them into AR.

9
00:00:27,628 --> 00:00:29,396
Let's get started.

10
00:00:29,396 --> 00:00:32,633
First, I'll give you a recap
of Object Capture,

11
00:00:32,633 --> 00:00:35,502
which we launched
as a RealityKit API

12
00:00:35,502 --> 00:00:38,238
on macOS last year.

13
00:00:38,238 --> 00:00:40,307
Then, I'll introduce you

14
00:00:40,307 --> 00:00:43,310
to a couple of camera
enhancements in ARKit,

15
00:00:43,310 --> 00:00:47,047
which allow you to capture
high-res photos of your object

16
00:00:47,047 --> 00:00:48,582
and can help you
better integrate

17
00:00:48,582 --> 00:00:52,753
Object Capture
into your AR applications.

18
00:00:52,753 --> 00:00:56,223
After that, I will go through
the best practice guidelines

19
00:00:56,223 --> 00:00:58,792
of Object Capture
so you can continue

20
00:00:58,792 --> 00:01:02,362
to make the best
out of this technology.

21
00:01:02,362 --> 00:01:05,265
In the last section,
Risa will take you through

22
00:01:05,265 --> 00:01:09,436
an end-to-end workflow with
Object Capture in RealityKit

23
00:01:09,436 --> 00:01:12,506
and demonstrate how
you can bring real-world objects

24
00:01:12,506 --> 00:01:15,609
into an AR experience.

25
00:01:15,609 --> 00:01:19,246
Let's start with a quick recap
of Object Capture.

26
00:01:19,246 --> 00:01:22,316
Object Capture
is a computer vision technology

27
00:01:22,316 --> 00:01:25,018
that you can leverage
to easily turn images

28
00:01:25,018 --> 00:01:29,523
of real-world objects
into detailed 3D models.

29
00:01:29,523 --> 00:01:32,059
You begin by taking photos
of your object

30
00:01:32,059 --> 00:01:37,030
from various angles
with an iPhone, iPad, or DSLR.

31
00:01:37,030 --> 00:01:39,633
Then, you copy
those photos to a Mac

32
00:01:39,633 --> 00:01:42,836
which supports Object Capture.

33
00:01:42,836 --> 00:01:45,138
Using the Photogrammetry API,

34
00:01:45,138 --> 00:01:49,142
RealityKit can transform
your photos into a 3D model

35
00:01:49,142 --> 00:01:51,878
in just a few minutes.

36
00:01:51,878 --> 00:01:55,182
The output model includes both
a geometric mesh

37
00:01:55,182 --> 00:01:58,585
as well as various material
maps, including textures,

38
00:01:58,585 --> 00:02:02,522
that are automatically applied
to your model.

39
00:02:02,522 --> 00:02:05,492
For more details
of the Object Capture API,

40
00:02:05,492 --> 00:02:07,561
I would highly recommend
that you watch

41
00:02:07,561 --> 00:02:12,499
last year's WWDC session
on Object Capture.

42
00:02:12,499 --> 00:02:16,269
Many developers have created
amazing 3D capture apps

43
00:02:16,269 --> 00:02:21,241
using Object Capture:
Unity, Cinema4D, Qlone,

44
00:02:21,241 --> 00:02:25,078
PolyCam, PhotoCatch,
just to name a few.

45
00:02:25,078 --> 00:02:28,382
In addition to this,
we have beautiful-looking models

46
00:02:28,382 --> 00:02:31,351
that were created
using this API.

47
00:02:31,351 --> 00:02:34,688
Here's a few models that
were created by Ethan Saadia

48
00:02:34,688 --> 00:02:36,957
using the power
of Object Capture

49
00:02:36,957 --> 00:02:39,626
within the PhotoCatch app.

50
00:02:39,626 --> 00:02:43,597
And our friend Mikko Haapoja
from Shopify also generated

51
00:02:43,597 --> 00:02:48,068
a bunch of great-looking
3D models using this API.

52
00:02:48,068 --> 00:02:50,704
The detailed quality
of the output 3D models

53
00:02:50,704 --> 00:02:56,143
you get with Object Capture is
highly beneficial in e-commerce.

54
00:02:56,143 --> 00:02:58,412
Here's the GOAT app,
for example,

55
00:02:58,412 --> 00:03:02,115
that lets you try on a variety
of shoes on your feet.

56
00:03:02,115 --> 00:03:04,351
All of these shoe models
have been created

57
00:03:04,351 --> 00:03:07,921
with the Object Capture API
which has been designed

58
00:03:07,921 --> 00:03:12,392
to capture the finest level
of detail on them.

59
00:03:12,392 --> 00:03:15,195
This can go a long way
in helping you

60
00:03:15,195 --> 00:03:18,331
with your purchase decision
on a product,

61
00:03:18,331 --> 00:03:22,702
or even try out an accurate fit
for an object in your space.

62
00:03:22,702 --> 00:03:26,106
For example, the Plant Story app
lets you preview

63
00:03:26,106 --> 00:03:30,177
real-looking 3D models
of various plants in your space,

64
00:03:30,177 --> 00:03:34,147
all of which have been created
with Object Capture.

65
00:03:34,147 --> 00:03:36,650
This can help you get a sense
of how much space

66
00:03:36,650 --> 00:03:38,819
you may need for a plant,

67
00:03:38,819 --> 00:03:43,457
or simply see them in your space
in realistic detail.

68
00:03:43,457 --> 00:03:45,525
Speaking about realism,

69
00:03:45,525 --> 00:03:49,563
were you able to spot
the real plant in this video?

70
00:03:49,563 --> 00:03:52,299
Yes, it's the one
in the white planter

71
00:03:52,299 --> 00:03:55,769
on the left-most corner
of the table.

72
00:03:55,769 --> 00:03:58,305
We are very thrilled
to see such a stunning

73
00:03:58,305 --> 00:04:00,974
and widespread use
of the Object Capture API

74
00:04:00,974 --> 00:04:04,111
since its launch in 2021.

75
00:04:04,111 --> 00:04:08,381
Now, let's talk about some
camera enhancements in ARKit,

76
00:04:08,381 --> 00:04:11,651
which will greatly help
the quality of reconstruction

77
00:04:11,651 --> 00:04:14,087
with Object Capture.

78
00:04:14,087 --> 00:04:16,389
A great Object Capture
experience starts

79
00:04:16,389 --> 00:04:21,128
with taking good photos
of objects from all sides.

80
00:04:21,128 --> 00:04:24,764
To this end, you can use
any high-resolution camera,

81
00:04:24,764 --> 00:04:26,833
like the iPhone or iPad,

82
00:04:26,833 --> 00:04:31,071
or even a DSLR
or mirrorless camera.

83
00:04:31,071 --> 00:04:34,741
If you use the Camera app
on your iPhone or iPad,

84
00:04:34,741 --> 00:04:37,410
you can take high-quality
photos with depth

85
00:04:37,410 --> 00:04:41,081
and gravity information which
lets the Object Capture API

86
00:04:41,081 --> 00:04:43,717
automatically recover
the real-world scale

87
00:04:43,717 --> 00:04:47,254
and orientation of the object.

88
00:04:47,254 --> 00:04:51,124
In addition to that,
if you use an iPhone or iPad,

89
00:04:51,124 --> 00:04:54,461
you can take advantage
of ARKit's tracking capabilities

90
00:04:54,461 --> 00:04:58,598
to overlay a 3D guidance UI
on top of the model

91
00:04:58,598 --> 00:05:03,203
to get good coverage
of the object from all sides.

92
00:05:03,203 --> 00:05:05,038
Another important thing to note

93
00:05:05,038 --> 00:05:08,842
is that the higher the image
resolution from your capture,

94
00:05:08,842 --> 00:05:11,778
the better the quality
of the 3D model

95
00:05:11,778 --> 00:05:14,581
that Object Capture can produce.

96
00:05:14,581 --> 00:05:15,882
To that end,

97
00:05:15,882 --> 00:05:19,719
with this year's ARKit release
we are introducing a brand-new

98
00:05:19,719 --> 00:05:23,423
high-resolution
background photos API.

99
00:05:23,423 --> 00:05:28,061
This API lets you capture photos
at native camera resolution

100
00:05:28,061 --> 00:05:31,164
while you are still running
an ARSession.

101
00:05:31,164 --> 00:05:36,002
It allows you to use your 3D
UI overlays on top of the object

102
00:05:36,002 --> 00:05:40,240
while taking full advantage
of the camera sensor on device.

103
00:05:40,240 --> 00:05:44,044
On an iPhone 13, that means
the full 12 megapixels

104
00:05:44,044 --> 00:05:47,547
native resolution
of the Wide camera.

105
00:05:47,547 --> 00:05:50,250
This API is nonintrusive.

106
00:05:50,250 --> 00:05:52,852
It does not interrupt
the continuous video stream

107
00:05:52,852 --> 00:05:56,423
of the current ARSession,
so your app will continue

108
00:05:56,423 --> 00:06:01,061
to provide a smooth
AR experience for your users.

109
00:06:01,061 --> 00:06:05,165
In addition, ARKit makes
EXIF metadata available

110
00:06:05,165 --> 00:06:07,767
in the photos,
which allows your app

111
00:06:07,767 --> 00:06:12,038
to read useful information
about white balance, exposure,

112
00:06:12,038 --> 00:06:16,910
and other settings that can be
valuable for post-processing.

113
00:06:16,910 --> 00:06:22,882
ARKit makes it extremely easy
to use this new API in your app.

114
00:06:22,882 --> 00:06:25,318
You can simply query
a video format

115
00:06:25,318 --> 00:06:27,954
that supports high-resolution
frame capturing

116
00:06:27,954 --> 00:06:33,059
on ARWorldTrackingConfguration,
and if successful,

117
00:06:33,059 --> 00:06:37,897
set the new video format
and run the ARSession.

118
00:06:37,897 --> 00:06:41,668
When it comes to capturing
a high-res photo,

119
00:06:41,668 --> 00:06:44,137
simply call ARSession's new

120
00:06:44,137 --> 00:06:47,574
captureHighResolutionFrame API
function,

121
00:06:47,574 --> 00:06:50,310
which will return to you
a high-res photo

122
00:06:50,310 --> 00:06:53,480
via a completion handler
asynchronously.

123
00:06:53,480 --> 00:06:56,850
It is that simple.

124
00:06:56,850 --> 00:06:59,686
We have also recognized
that there are use cases

125
00:06:59,686 --> 00:07:03,657
where you may prefer manual
control over the camera settings

126
00:07:03,657 --> 00:07:07,661
such as focus, exposure,
or white balance.

127
00:07:07,661 --> 00:07:11,231
So we are providing you
with a convenient way

128
00:07:11,231 --> 00:07:14,934
to access the underlying
AVCaptureDevice directly

129
00:07:14,934 --> 00:07:19,139
and change its properties
for fine-grained camera control.

130
00:07:19,139 --> 00:07:22,776
As shown in this code example,
simply call

131
00:07:22,776 --> 00:07:25,645
configurableCaptureDevice
ForPrimaryCamera

132
00:07:25,645 --> 00:07:28,515
on your
ARWorldTrackingConfiguration

133
00:07:28,515 --> 00:07:33,553
to get access to the underlying
AVCaptureDevice.

134
00:07:33,553 --> 00:07:36,056
For more details
on these enhancements,

135
00:07:36,056 --> 00:07:38,224
I highly recommend
you to check out

136
00:07:38,224 --> 00:07:44,097
the "Discover ARKit 6 session"
from this year's WWDC.

137
00:07:44,097 --> 00:07:47,500
Now, let's go through
some best practice guidelines

138
00:07:47,500 --> 00:07:49,669
with Object Capture.

139
00:07:49,669 --> 00:07:52,806
First things first;
we need to choose an object

140
00:07:52,806 --> 00:07:56,810
with the right characteristics
for Object Capture.

141
00:07:56,810 --> 00:08:01,081
A good object has
adequate texture on its surface.

142
00:08:01,081 --> 00:08:04,951
If some regions of the object
are textureless or transparent,

143
00:08:04,951 --> 00:08:09,923
the details in those regions
may not be reconstructed well.

144
00:08:09,923 --> 00:08:14,127
A good object should also be
free of glare and reflections.

145
00:08:14,127 --> 00:08:16,896
If the object does not have
a matte surface,

146
00:08:16,896 --> 00:08:19,399
you can try to reduce
the specular on it

147
00:08:19,399 --> 00:08:21,901
using diffuse lighting.

148
00:08:21,901 --> 00:08:24,070
If you would like
to flip over the object

149
00:08:24,070 --> 00:08:25,872
to capture its bottom,

150
00:08:25,872 --> 00:08:29,242
please ensure
that your object stays rigid.

151
00:08:29,242 --> 00:08:33,947
In other words, it should not
change its shape when flipped.

152
00:08:33,947 --> 00:08:37,884
And lastly, a good object
can contain fine structure

153
00:08:37,884 --> 00:08:40,253
to some degree,
but you will need to use

154
00:08:40,253 --> 00:08:43,223
a high-resolution camera
and take close-up photos

155
00:08:43,223 --> 00:08:48,161
to recover the fine detail
of the object.

156
00:08:48,161 --> 00:08:49,529
The next important thing

157
00:08:49,529 --> 00:08:52,932
is setting up an ideal
capture environment.

158
00:08:52,932 --> 00:08:56,269
You will want to make sure
that your capture environment

159
00:08:56,269 --> 00:09:00,006
has good, even,
and diffuse lighting.

160
00:09:00,006 --> 00:09:03,176
It is important to ensure
a stable background

161
00:09:03,176 --> 00:09:06,413
and have sufficient space
around the object.

162
00:09:06,413 --> 00:09:08,014
If your room is dark,

163
00:09:08,014 --> 00:09:11,918
you can make use
of a well-lit turntable.

164
00:09:11,918 --> 00:09:14,487
Next, we'll look
at some guidelines

165
00:09:14,487 --> 00:09:18,691
for capturing good photos
of your object, which in turn,

166
00:09:18,691 --> 00:09:22,061
will ensure that you get
a good quality 3D model

167
00:09:22,061 --> 00:09:24,431
from Object Capture.

168
00:09:24,431 --> 00:09:28,067
As an example, I'll show you
how my colleague Maunesh

169
00:09:28,067 --> 00:09:30,370
used his iPhone
to capture the images

170
00:09:30,370 --> 00:09:32,939
of a beautiful pirate ship
that was created

171
00:09:32,939 --> 00:09:37,911
by our beloved ARKit engineer,
Christian Lipski.

172
00:09:37,911 --> 00:09:40,380
Maunesh begins
by placing the pirate ship

173
00:09:40,380 --> 00:09:43,516
in the middle of a clean table.

174
00:09:43,516 --> 00:09:47,921
This makes the ship
clearly stand out in the photos.

175
00:09:47,921 --> 00:09:51,491
He holds his iPhone steadily
with two hands.

176
00:09:51,491 --> 00:09:54,260
As he circles
around the ship slowly,

177
00:09:54,260 --> 00:09:57,997
he captures photos
at various heights.

178
00:09:57,997 --> 00:10:01,901
He makes sure that the ship
is large enough in the center

179
00:10:01,901 --> 00:10:03,903
of the camera's field of view

180
00:10:03,903 --> 00:10:07,874
so that he can capture
the maximum amount of detail.

181
00:10:07,874 --> 00:10:10,310
He also makes sure
that he always maintains

182
00:10:10,310 --> 00:10:15,882
a high degree of overlap
between any two adjacent photos.

183
00:10:15,882 --> 00:10:18,384
After he takes
a good number of photos --

184
00:10:18,384 --> 00:10:23,423
about 80 in this case --
he flips the ship on its side,

185
00:10:23,423 --> 00:10:27,227
so that he can also
reconstruct its bottom.

186
00:10:27,227 --> 00:10:31,097
He continues to capture
about 20 more photos of the ship

187
00:10:31,097 --> 00:10:34,334
in a flipped orientation.

188
00:10:34,334 --> 00:10:37,270
One thing to note is that
he is holding the iPhone

189
00:10:37,270 --> 00:10:39,172
in landscape mode.

190
00:10:39,172 --> 00:10:42,642
This is because
he is capturing a long object,

191
00:10:42,642 --> 00:10:45,278
and in this case,
the landscape mode helps him

192
00:10:45,278 --> 00:10:49,916
capture maximum amount of detail
of the object.

193
00:10:49,916 --> 00:10:53,286
However, he may need to use
the iPhone in portrait mode

194
00:10:53,286 --> 00:10:57,357
if he were to capture
a tall object instead.

195
00:10:59,359 --> 00:11:00,527
That's it!

196
00:11:00,527 --> 00:11:03,963
The final step in the process
is to copy those photos

197
00:11:03,963 --> 00:11:09,002
onto a Mac and process them
using the Object Capture API.

198
00:11:09,002 --> 00:11:11,771
You can choose from
four different detail levels,

199
00:11:11,771 --> 00:11:15,041
which are optimized
for different use cases.

200
00:11:15,041 --> 00:11:18,211
The reduced and medium detail
levels are optimized

201
00:11:18,211 --> 00:11:21,481
for use in web-based
and mobile experiences,

202
00:11:21,481 --> 00:11:25,218
such as viewing 3D content
in AR QuickLook.

203
00:11:25,218 --> 00:11:28,121
The reconstructed models
for those detail levels

204
00:11:28,121 --> 00:11:31,124
have fewer triangles
and material channels,

205
00:11:31,124 --> 00:11:34,294
thereby consuming
less memory.

206
00:11:34,294 --> 00:11:36,496
The full and raw detail levels

207
00:11:36,496 --> 00:11:39,432
are intended for high-end
interactive use cases,

208
00:11:39,432 --> 00:11:44,203
such as in computer games
or post-production workflows.

209
00:11:44,203 --> 00:11:47,140
These models contain
the highest geometric detail

210
00:11:47,140 --> 00:11:50,176
and give you the flexibility
to choose between baked

211
00:11:50,176 --> 00:11:52,412
and unbaked materials,

212
00:11:52,412 --> 00:11:55,882
but they require more memory
to reconstruct.

213
00:11:55,882 --> 00:11:58,585
It is important to select
the right output level

214
00:11:58,585 --> 00:12:00,954
depending on your use case.

215
00:12:00,954 --> 00:12:04,324
For our pirate ship, we chose
the medium detail level,

216
00:12:04,324 --> 00:12:09,896
which only took a few minutes
to process it on an M1 Mac.

217
00:12:09,896 --> 00:12:12,565
The output 3D model
looked so stunning

218
00:12:12,565 --> 00:12:15,268
that we actually put together
an animated clip

219
00:12:15,268 --> 00:12:18,905
of the pirate ship
sailing in high seas.

220
00:12:18,905 --> 00:12:22,208
And that's the power
of Object Capture for you!

221
00:12:22,208 --> 00:12:24,010
Ahoy!

222
00:12:24,010 --> 00:12:25,945
Now I'll hand it off to Risa,

223
00:12:25,945 --> 00:12:28,681
who will be walking you through
an end-to-end workflow

224
00:12:28,681 --> 00:12:31,517
with Object Capture
in RealityKit.

225
00:12:31,517 --> 00:12:33,186
Risa Yoneyama: Thanks, Hao.

226
00:12:33,186 --> 00:12:37,056
Now that we have gone over
the Object Capture API,

227
00:12:37,056 --> 00:12:41,194
I am excited to go over an
end-to-end developer workflow,

228
00:12:41,194 --> 00:12:46,399
to bring your real-life object
into AR using RealityKit.

229
00:12:46,399 --> 00:12:48,368
We'll walk through
each step in detail

230
00:12:48,368 --> 00:12:50,236
with an example workflow,

231
00:12:50,236 --> 00:12:54,007
so let's dive
straight into a demo.

232
00:12:54,007 --> 00:12:56,843
My colleague Zach
is an occasional woodworker

233
00:12:56,843 --> 00:13:00,780
and recently built six oversized
wooden chess pieces --

234
00:13:00,780 --> 00:13:02,949
one for each unique piece.

235
00:13:02,949 --> 00:13:04,517
Looking at these chess pieces,

236
00:13:04,517 --> 00:13:08,621
I'm inspired to create
an interactive AR chess game.

237
00:13:08,621 --> 00:13:10,790
Previously,
you'd need a 3D modeler

238
00:13:10,790 --> 00:13:13,993
and material specialist
to create high-quality 3D models

239
00:13:13,993 --> 00:13:15,862
of real-world objects.

240
00:13:15,862 --> 00:13:18,398
Now, with the
Object Capture API,

241
00:13:18,398 --> 00:13:21,367
we can simply capture
these chess pieces directly

242
00:13:21,367 --> 00:13:24,504
and bring them
into augmented reality.

243
00:13:24,504 --> 00:13:27,006
Let's start off
by capturing the rook.

244
00:13:27,006 --> 00:13:30,543
My colleague Bryan will be using
this professional setup,

245
00:13:30,543 --> 00:13:33,179
keeping in mind
the best practices we covered

246
00:13:33,179 --> 00:13:35,448
in the previous section.

247
00:13:35,448 --> 00:13:39,085
In this case, Bryan is placing
the rook on this turntable

248
00:13:39,085 --> 00:13:41,821
with some professional lighting
to help avoid harsh shadows

249
00:13:41,821 --> 00:13:44,123
in the final output.

250
00:13:44,123 --> 00:13:47,393
You can also use the iPhone
camera with a turntable,

251
00:13:47,393 --> 00:13:50,029
which provides you with
automatic scale estimation

252
00:13:50,029 --> 00:13:54,500
and gravity vector information
in your output USDZ.

253
00:13:54,500 --> 00:13:57,870
Please refer to the
Object Capture session from 2021

254
00:13:57,870 --> 00:14:00,306
for more details on this.

255
00:14:00,306 --> 00:14:03,142
Of course, if you do not have
an elaborate setup

256
00:14:03,142 --> 00:14:07,613
like Bryan does here, you can
also simply hold your iOS device

257
00:14:07,613 --> 00:14:12,218
and walk around your object
to capture the images.

258
00:14:12,218 --> 00:14:14,987
Now that we have all the photos
of our rook piece,

259
00:14:14,987 --> 00:14:17,924
I'm going to transfer these
over to the Mac.

260
00:14:17,924 --> 00:14:19,292
I'll process these photos

261
00:14:19,292 --> 00:14:21,427
using the
PhotogrammetrySession API

262
00:14:21,427 --> 00:14:24,597
that was introduced in 2021.

263
00:14:24,597 --> 00:14:26,632
Per the best practice
guidelines,

264
00:14:26,632 --> 00:14:29,469
I'll use the reduced detail
level to reconstruct,

265
00:14:29,469 --> 00:14:33,239
as we want to make sure
our AR app performs well.

266
00:14:33,239 --> 00:14:38,911
The final output of the API
will be a USDZ file type model.

267
00:14:38,911 --> 00:14:40,913
Here is our final output
of the rook chess piece

268
00:14:40,913 --> 00:14:43,616
I just reconstructed.

269
00:14:43,616 --> 00:14:46,319
To save us some time,
I've gone ahead and captured

270
00:14:46,319 --> 00:14:50,022
the other five pieces
ahead of time.

271
00:14:50,022 --> 00:14:52,825
You may be wondering
how we will create a chess game

272
00:14:52,825 --> 00:14:56,262
with only one color scheme
for the chess pieces.

273
00:14:56,262 --> 00:14:58,598
Let's duplicate
our six unique pieces

274
00:14:58,598 --> 00:15:01,667
and drag them
into Reality Converter.

275
00:15:01,667 --> 00:15:04,370
I have inverted the colors
in the original texture

276
00:15:04,370 --> 00:15:08,808
and replaced the duplicated set
with this new inverted texture.

277
00:15:08,808 --> 00:15:10,943
This way, we can have
a lighter version

278
00:15:10,943 --> 00:15:13,479
and a darker version
of the chess pieces,

279
00:15:13,479 --> 00:15:15,348
one for each player.

280
00:15:15,348 --> 00:15:16,783
I'll be exporting the models

281
00:15:16,783 --> 00:15:18,918
with the compressed textures
option turned on

282
00:15:18,918 --> 00:15:20,987
in the Export menu.

283
00:15:20,987 --> 00:15:22,822
This will help decrease
the memory footprint

284
00:15:22,822 --> 00:15:24,724
of the textures.

285
00:15:26,325 --> 00:15:28,795
Now that we have
our full set of chess pieces,

286
00:15:28,795 --> 00:15:33,566
we are ready to bring the models
into our Xcode project.

287
00:15:33,566 --> 00:15:35,802
I've created a chessboard
using RealityKit

288
00:15:35,802 --> 00:15:38,738
by scaling down
primitive cubes on the y-axis

289
00:15:38,738 --> 00:15:42,241
and alternating the colors
between black and white.

290
00:15:42,241 --> 00:15:45,077
Here are all the chess pieces
I reconstructed,

291
00:15:45,077 --> 00:15:47,246
laid out on the chessboard.

292
00:15:47,246 --> 00:15:48,881
This is already exciting to see

293
00:15:48,881 --> 00:15:51,751
our real-life objects
in our application,

294
00:15:51,751 --> 00:15:53,152
but let's start adding
some features

295
00:15:53,152 --> 00:15:56,455
to make it an actual
interactive game.

296
00:15:56,455 --> 00:15:58,090
Throughout
this part of the demo,

297
00:15:58,090 --> 00:16:01,160
I would like to showcase several
different existing technologies,

298
00:16:01,160 --> 00:16:03,429
so we can provide examples
of how you might want

299
00:16:03,429 --> 00:16:08,034
to combine the technologies to
accomplish your desired output.

300
00:16:08,034 --> 00:16:10,369
As we'll be going over
some practical use cases

301
00:16:10,369 --> 00:16:12,772
of advanced topics
in RealityKit,

302
00:16:12,772 --> 00:16:14,574
I would recommend checking out

303
00:16:14,574 --> 00:16:16,709
the RealityKit sessions
from 2021

304
00:16:16,709 --> 00:16:20,546
if you are not already
familiar with the APIs.

305
00:16:20,546 --> 00:16:23,349
I want to start by adding
a start-up animation

306
00:16:23,349 --> 00:16:26,352
when we first launch
the application.

307
00:16:26,352 --> 00:16:28,855
I am imagining an animation
where the checker tiles

308
00:16:28,855 --> 00:16:30,323
slowly fall into place

309
00:16:30,323 --> 00:16:32,792
from slightly above
its final position,

310
00:16:32,792 --> 00:16:36,429
all while the chess pieces
also translate in together.

311
00:16:36,429 --> 00:16:38,664
To replicate
this effect in code,

312
00:16:38,664 --> 00:16:41,400
all it takes is two steps.

313
00:16:41,400 --> 00:16:44,136
The first step is to translate
both our entities

314
00:16:44,136 --> 00:16:46,172
up along the y-axis,

315
00:16:46,172 --> 00:16:50,009
while also uniformly
scaling down the chess piece.

316
00:16:50,009 --> 00:16:53,145
The second step and final step
is to animate both entities

317
00:16:53,145 --> 00:16:56,315
back to its original transform.

318
00:16:56,315 --> 00:16:59,352
The code for this
is quite simple.

319
00:16:59,352 --> 00:17:03,289
I'll start by iterating through
the checker tile entities.

320
00:17:03,289 --> 00:17:04,390
For each entity,

321
00:17:04,390 --> 00:17:07,159
I'll save the current transform
of the checker tile

322
00:17:07,159 --> 00:17:10,763
as this will be the final
position it lands on.

323
00:17:10,763 --> 00:17:16,002
Then, I'll move each square up
10 cm on the y-axis.

324
00:17:16,002 --> 00:17:18,104
We can now take advantage
of the move function

325
00:17:18,104 --> 00:17:22,642
to animate this back
to our original transform.

326
00:17:22,642 --> 00:17:25,544
I also happen to know
that this border USDZ

327
00:17:25,544 --> 00:17:29,749
that outlines the checkerboard
has a built-in animation.

328
00:17:29,749 --> 00:17:31,817
We can use the playAnimation API

329
00:17:31,817 --> 00:17:35,454
to start the animation
simultaneously.

330
00:17:35,454 --> 00:17:38,357
I've added the exact same
animation to the chess pieces

331
00:17:38,357 --> 00:17:42,495
but also modifying the scale
as they translate.

332
00:17:42,495 --> 00:17:43,729
And here we have it:

333
00:17:43,729 --> 00:17:47,934
a simple startup animation
with just a few lines of code.

334
00:17:47,934 --> 00:17:50,970
However, we won't actually
be able to play chess

335
00:17:50,970 --> 00:17:53,539
without the ability
to move the chess pieces.

336
00:17:53,539 --> 00:17:55,708
Let's work on that next.

337
00:17:55,708 --> 00:17:58,210
Before we can start moving
the chess pieces,

338
00:17:58,210 --> 00:18:00,980
we'll need to be able
to select one.

339
00:18:00,980 --> 00:18:03,649
I've already added
a UITapGestureRecognizer

340
00:18:03,649 --> 00:18:05,651
to my ARView.

341
00:18:05,651 --> 00:18:08,220
When the users taps
a specific location,

342
00:18:08,220 --> 00:18:10,990
we will define a ray that starts
from the camera origin

343
00:18:10,990 --> 00:18:14,827
and goes through that 2D point.

344
00:18:14,827 --> 00:18:18,698
We can then perform a raycast
with that ray into the 3D scene

345
00:18:18,698 --> 00:18:21,167
to see if we hit any entities.

346
00:18:21,167 --> 00:18:24,403
I've specified my chess piece
collision group as a mask

347
00:18:24,403 --> 00:18:27,206
as I know I only want to be able
to select the chess pieces

348
00:18:27,206 --> 00:18:29,308
in my scene.

349
00:18:29,308 --> 00:18:31,077
Be mindful that
the raycast function

350
00:18:31,077 --> 00:18:33,212
will ignore all entities
that do not have

351
00:18:33,212 --> 00:18:35,047
a CollisionComponent.

352
00:18:35,047 --> 00:18:39,719
If we do find a chess piece,
we can finally select it.

353
00:18:39,719 --> 00:18:41,754
Now that we know
which piece is selected,

354
00:18:41,754 --> 00:18:43,122
I want to add an effect

355
00:18:43,122 --> 00:18:47,259
that will make the piece
look like it is glowing.

356
00:18:47,259 --> 00:18:50,062
We can leverage custom materials
to achieve this;

357
00:18:50,062 --> 00:18:52,999
more specifically,
surface shaders.

358
00:18:52,999 --> 00:18:55,001
Surface shaders allow you
to calculate

359
00:18:55,001 --> 00:18:58,170
or specify material parameters
through Metal,

360
00:18:58,170 --> 00:19:01,240
which then gets called by
RealityKit's fragment shader

361
00:19:01,240 --> 00:19:03,809
once per each pixel.

362
00:19:03,809 --> 00:19:05,177
We can write a surface shader

363
00:19:05,177 --> 00:19:08,014
that looks like
this fire effect in Metal.

364
00:19:08,014 --> 00:19:09,615
Then apply a custom material,

365
00:19:09,615 --> 00:19:12,184
with this surface shader
to our rectangular prism

366
00:19:12,184 --> 00:19:15,955
to have the shader affect
how our entity looks.

367
00:19:15,955 --> 00:19:19,859
Let's write some code
to achieve our desired effect.

368
00:19:19,859 --> 00:19:22,228
I've already added
a noise texture to the project

369
00:19:22,228 --> 00:19:24,530
to use in this surface shader.

370
00:19:24,530 --> 00:19:26,399
We'll sample the texture twice,

371
00:19:26,399 --> 00:19:28,534
once for the overall
shape of the effect

372
00:19:28,534 --> 00:19:30,603
and another for detail.

373
00:19:30,603 --> 00:19:33,606
We then take the RGB value
and remap it to look

374
00:19:33,606 --> 00:19:35,641
just the way we want.

375
00:19:35,641 --> 00:19:38,144
Then, with the processed value
we just extracted,

376
00:19:38,144 --> 00:19:40,946
we'll calculate the opacity
of the sample point

377
00:19:40,946 --> 00:19:45,418
by comparing its y-position
with the image value.

378
00:19:45,418 --> 00:19:47,053
To give the effect
some movement,

379
00:19:47,053 --> 00:19:49,188
we'll be moving through
the y-axis of the texture

380
00:19:49,188 --> 00:19:52,525
as a function of time.

381
00:19:52,525 --> 00:19:55,194
Additionally, we will also
use the facing angle

382
00:19:55,194 --> 00:19:57,296
of each sample point
in conjunction

383
00:19:57,296 --> 00:19:59,965
with the viewing direction
of the camera

384
00:19:59,965 --> 00:20:02,001
to fade the effect at the sides.

385
00:20:02,001 --> 00:20:04,503
This will soften the edges
and hide the regular nature

386
00:20:04,503 --> 00:20:07,973
of the underlying model.

387
00:20:07,973 --> 00:20:11,544
Finally, we'll set the color
and opacity we just calculated

388
00:20:11,544 --> 00:20:15,448
using the surface
parameter functions.

389
00:20:15,448 --> 00:20:16,615
And here are the chess pieces

390
00:20:16,615 --> 00:20:19,018
with the selection shader
applied to it.

391
00:20:19,018 --> 00:20:22,922
They really do look like they
are glowing from the inside.

392
00:20:22,922 --> 00:20:24,390
Now, if we combine that

393
00:20:24,390 --> 00:20:26,892
with three separate
translation animations,

394
00:20:26,892 --> 00:20:30,663
that will result in something
that looks like this.

395
00:20:30,663 --> 00:20:34,867
With the functionality to move
chess pieces implemented,

396
00:20:34,867 --> 00:20:38,704
we'll also be able to capture
the opponent's pieces.

397
00:20:38,704 --> 00:20:41,774
Just like surface shaders,
geometry modifiers

398
00:20:41,774 --> 00:20:45,511
can be implemented
using custom materials.

399
00:20:45,511 --> 00:20:48,981
They are a very powerful tool,
as you can change vertex data

400
00:20:48,981 --> 00:20:54,420
such as position, normals,
texture coordinates, and more.

401
00:20:54,420 --> 00:20:57,523
Each of these Metal functions
will be called once per vertex

402
00:20:57,523 --> 00:21:00,526
by RealityKit's vertex shader.

403
00:21:00,526 --> 00:21:03,295
These modifications
are purely transient

404
00:21:03,295 --> 00:21:05,598
and do not affect
the vertex information

405
00:21:05,598 --> 00:21:08,667
of the actual entity.

406
00:21:08,667 --> 00:21:11,137
I'm thinking we could add
a fun geometry modifier

407
00:21:11,137 --> 00:21:14,473
to squash the pieces
when they are captured.

408
00:21:14,473 --> 00:21:16,942
I have this property
on my chess piece

409
00:21:16,942 --> 00:21:19,812
called capturedProgress
to represent the progress

410
00:21:19,812 --> 00:21:24,350
of the capturing animation
from 0 to 1.

411
00:21:24,350 --> 00:21:27,486
Since capturing
is a user-initiated action,

412
00:21:27,486 --> 00:21:29,755
we somehow need to tell
the geometry modifier

413
00:21:29,755 --> 00:21:32,725
when to start its animation.

414
00:21:32,725 --> 00:21:34,593
The good thing is
you can do this

415
00:21:34,593 --> 00:21:38,097
by setting the custom property
on a customMaterial.

416
00:21:38,097 --> 00:21:42,735
This allows data to be shared
between the CPU and the GPU.

417
00:21:42,735 --> 00:21:45,704
We will specifically use
the custom value property here

418
00:21:45,704 --> 00:21:50,142
and pass the animation progress
to the geometry modifier.

419
00:21:50,142 --> 00:21:53,579
To extract the animation
progress from the Metal side,

420
00:21:53,579 --> 00:21:57,917
we can use the custom parameter
on uniforms.

421
00:21:57,917 --> 00:22:00,186
Since I want to scale
the object vertically,

422
00:22:00,186 --> 00:22:02,621
as if it is being squashed
by another piece,

423
00:22:02,621 --> 00:22:06,125
we will set the scale axis
as the y-direction.

424
00:22:06,125 --> 00:22:08,360
To add some complexity
to the animation,

425
00:22:08,360 --> 00:22:10,796
we will also change
the geometry in the x-axis

426
00:22:10,796 --> 00:22:13,265
to create a wave effect.

427
00:22:13,265 --> 00:22:15,601
The offset of the vertex
can be set using the

428
00:22:15,601 --> 00:22:19,271
set_model_position_ offset
function.

429
00:22:19,271 --> 00:22:23,142
Here is the final product
of our geometry modifier.

430
00:22:23,142 --> 00:22:26,278
You can see that it scales up
a bit before collapsing down,

431
00:22:26,278 --> 00:22:30,482
while being stretched vertically
along the x-axis.

432
00:22:30,482 --> 00:22:32,885
As a chess novice myself,

433
00:22:32,885 --> 00:22:34,987
I thought it might be helpful
to add a feature

434
00:22:34,987 --> 00:22:37,389
to indicate where
your selected piece can move to

435
00:22:37,389 --> 00:22:40,292
to help me learn the game.

436
00:22:40,292 --> 00:22:43,329
Since the checker pieces
are each individual entities

437
00:22:43,329 --> 00:22:45,297
with their own Model Component,

438
00:22:45,297 --> 00:22:48,634
I can apply a pulsing effect
using a surface shader

439
00:22:48,634 --> 00:22:52,171
to potential moves
to distinguish them from others.

440
00:22:52,171 --> 00:22:55,107
Next, I'll add a post-processing
effect called "bloom"

441
00:22:55,107 --> 00:22:58,344
to accentuate
the effect even more.

442
00:22:58,344 --> 00:23:00,713
Again, we're using
the custom parameter here

443
00:23:00,713 --> 00:23:04,283
we used in the surface shader
for the glow effect.

444
00:23:04,283 --> 00:23:07,853
In this case, we are passing in
a Boolean from the CPU side

445
00:23:07,853 --> 00:23:11,123
to our Metal surface shader.

446
00:23:11,123 --> 00:23:13,459
If this checker
is a possible move,

447
00:23:13,459 --> 00:23:16,629
I want to add a pulsing effect
by changing the color.

448
00:23:16,629 --> 00:23:21,100
We'll specifically add the pulse
to the emissive color here.

449
00:23:21,100 --> 00:23:25,571
Lastly, I'll add the bloom
effect to the entire view.

450
00:23:25,571 --> 00:23:28,440
Bloom is a post-processing
effect that produces

451
00:23:28,440 --> 00:23:32,344
feathers of light from
the borders of bright areas.

452
00:23:32,344 --> 00:23:35,147
We can accomplish this effect
by taking advantage

453
00:23:35,147 --> 00:23:39,451
of the render callbacks property
on ARView.

454
00:23:39,451 --> 00:23:42,154
We will write the bloom effect
using the already built-in

455
00:23:42,154 --> 00:23:45,758
Metal performance shader
functions.

456
00:23:45,758 --> 00:23:49,094
Next, we'll simply set the
renderCallbacks.postProcess

457
00:23:49,094 --> 00:23:52,498
closure as our bloom function
we just defined.

458
00:23:52,498 --> 00:23:55,601
When we pulse our checkers,
we are pulsing to a white color

459
00:23:55,601 --> 00:23:57,536
which will now be
further emphasized

460
00:23:57,536 --> 00:24:00,339
with the bloom effect.

461
00:24:00,339 --> 00:24:03,142
With the surface shader
and bloom effect together,

462
00:24:03,142 --> 00:24:08,480
we can see exactly where
we can move our pieces to.

463
00:24:08,480 --> 00:24:11,216
Finally, let's combine
everything we have together

464
00:24:11,216 --> 00:24:13,619
to see our real-life
chess pieces come to life

465
00:24:13,619 --> 00:24:16,422
in our AR app.

466
00:24:16,422 --> 00:24:18,490
We can see how
all the features we added

467
00:24:18,490 --> 00:24:21,126
look in our environment.

468
00:24:21,126 --> 00:24:22,761
For your convenience
we have linked

469
00:24:22,761 --> 00:24:26,732
the Capture Chess sample project
to the session resources.

470
00:24:26,732 --> 00:24:28,901
Please download it
and try it out for yourself

471
00:24:28,901 --> 00:24:31,236
to see it in your environment.

472
00:24:31,236 --> 00:24:32,604
And it's that simple.

473
00:24:32,604 --> 00:24:36,041
From capture to reconstruction
of the oversized chess pieces,

474
00:24:36,041 --> 00:24:40,112
then into
our augmented reality app.

475
00:24:40,112 --> 00:24:43,082
We've covered a lot
in this session today

476
00:24:43,082 --> 00:24:46,418
so let's summarize
some of the key points.

477
00:24:46,418 --> 00:24:50,255
We first started off by
recapping the Object Capture API

478
00:24:50,255 --> 00:24:53,459
that we announced in 2021.

479
00:24:53,459 --> 00:24:56,362
We then went over
a new API in ARKit

480
00:24:56,362 --> 00:24:58,997
that enables
capturing photos on-demand

481
00:24:58,997 --> 00:25:03,802
at native camera resolution
during an active ARSession.

482
00:25:03,802 --> 00:25:07,706
To help you get the most out of
the Object Capture technology,

483
00:25:07,706 --> 00:25:11,243
we listed types of objects that
are suited for reconstruction,

484
00:25:11,243 --> 00:25:14,747
ideal environments
to get high-quality images,

485
00:25:14,747 --> 00:25:16,648
and the recommended
flow to follow

486
00:25:16,648 --> 00:25:19,885
while capturing your object.

487
00:25:19,885 --> 00:25:21,787
For the latter part
of this session,

488
00:25:21,787 --> 00:25:25,591
we walked through an example
end-to-end developer workflow.

489
00:25:25,591 --> 00:25:28,494
We captured photos
of the oversized chess pieces

490
00:25:28,494 --> 00:25:32,431
and used the images as input
to the PhotogrammetrySession API

491
00:25:32,431 --> 00:25:35,167
to create 3D models of them.

492
00:25:35,167 --> 00:25:38,270
Then, we imported the models
into Reality Converter

493
00:25:38,270 --> 00:25:40,739
to replace some textures.

494
00:25:40,739 --> 00:25:43,575
And finally, we slowly
built up our chess game

495
00:25:43,575 --> 00:25:47,946
to see our chess pieces
in action in AR.

496
00:25:47,946 --> 00:25:50,015
And that's it
for our session today.

497
00:25:50,015 --> 00:25:51,817
Thank you so much for watching.

498
00:25:51,817 --> 00:25:53,285
Ahoy!

499
00:25:53,285 --> 00:25:57,556
♪

