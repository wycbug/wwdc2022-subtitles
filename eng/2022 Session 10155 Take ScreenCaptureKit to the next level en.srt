1
00:00:00,000 --> 00:00:03,003
♪ Mellow instrumental
hip-hop music ♪

2
00:00:03,003 --> 00:00:10,177
♪

3
00:00:10,177 --> 00:00:12,212
Meng Yang: Hi,
my name is Meng Yang,

4
00:00:12,212 --> 00:00:15,949
an engineer from GPU Software
here at Apple.

5
00:00:15,949 --> 00:00:19,119
Today I am going cover
a few advanced topics

6
00:00:19,119 --> 00:00:21,989
about ScreenCaptureKit
and how it can take

7
00:00:21,989 --> 00:00:26,226
your app's screen sharing
experience to the next level.

8
00:00:26,226 --> 00:00:28,929
Later, my colleague Drew
will demonstrate

9
00:00:28,929 --> 00:00:32,699
this exciting new API in action.

10
00:00:32,699 --> 00:00:37,137
Screen capture is at the heart
of screen sharing applications

11
00:00:37,137 --> 00:00:41,575
such as Zoom,
Google Meet, SharePlay

12
00:00:41,575 --> 00:00:46,346
and even popular game streaming
services like Twitch,

13
00:00:46,346 --> 00:00:50,851
which have become the new norm
of how we work, study,

14
00:00:50,851 --> 00:00:55,656
collaborate, and socialize
over the past few years.

15
00:00:55,656 --> 00:00:58,058
ScreenCaptureKit
is a brand-new,

16
00:00:58,058 --> 00:01:00,794
high-performance
screen capture framework

17
00:01:00,794 --> 00:01:05,565
built from ground up
with a powerful feature set.

18
00:01:05,565 --> 00:01:10,137
The rich set of features
includes highly customizable

19
00:01:10,137 --> 00:01:14,474
content control that allows you
to easily pick and then choose

20
00:01:14,474 --> 00:01:18,045
any combination
of windows, applications,

21
00:01:18,045 --> 00:01:21,515
and displays to capture.

22
00:01:21,515 --> 00:01:24,618
Ability to capture
up to the screen content's

23
00:01:24,618 --> 00:01:28,422
native resolution
and frame rate.

24
00:01:28,422 --> 00:01:32,092
Dynamic stream property controls
like resolution,

25
00:01:32,092 --> 00:01:34,628
frame rate, pixel format.

26
00:01:34,628 --> 00:01:37,497
And these controls
can be modified on the fly

27
00:01:37,497 --> 00:01:40,867
without recreating the stream.

28
00:01:40,867 --> 00:01:44,004
Capture buffers that are
GPU memory-backed

29
00:01:44,004 --> 00:01:47,307
to reduce memory copies.

30
00:01:47,307 --> 00:01:51,211
Hardware-accelerated
content capture, scaling,

31
00:01:51,211 --> 00:01:53,914
pixel and color
format conversion

32
00:01:53,914 --> 00:01:59,953
to achieve high-performance
capture with reduced CPU usage.

33
00:01:59,953 --> 00:02:07,060
Last but not least, support for
both video and audio capture.

34
00:02:07,060 --> 00:02:08,795
Before getting started,

35
00:02:08,795 --> 00:02:11,298
this talk assumes
you are already familiar

36
00:02:11,298 --> 00:02:14,267
with the basic concepts,
building blocks,

37
00:02:14,267 --> 00:02:17,504
and workflow of
how the framework works.

38
00:02:17,504 --> 00:02:21,508
Please visit the intro session
"Meet ScreenCaptureKit"

39
00:02:21,508 --> 00:02:23,510
to learn more.

40
00:02:23,510 --> 00:02:26,246
In this session,
I am going to talk about

41
00:02:26,246 --> 00:02:30,250
how to capture and display
a single window.

42
00:02:30,250 --> 00:02:36,857
Next, how to add screen content
to full display capture.

43
00:02:36,857 --> 00:02:40,961
How to remove content
from display capture.

44
00:02:40,961 --> 00:02:45,032
I will then show you a few ways
to configure the stream

45
00:02:45,032 --> 00:02:48,235
for different use cases.

46
00:02:48,235 --> 00:02:52,372
And last, you will see a demo
of how ScreenCaptureKit

47
00:02:52,372 --> 00:02:56,309
transformed the screen
and audio capture experience

48
00:02:56,309 --> 00:03:03,417
of OBS Studio, a popular
open source screen capture app.

49
00:03:03,417 --> 00:03:06,553
Now, let's start
with the first example,

50
00:03:06,553 --> 00:03:10,223
and probably
the most common use case:

51
00:03:10,223 --> 00:03:14,194
capture a single window.

52
00:03:14,194 --> 00:03:16,897
This example is going to cover

53
00:03:16,897 --> 00:03:20,300
how to set up
a single window filter;

54
00:03:20,300 --> 00:03:22,936
what to expect
from the stream output

55
00:03:22,936 --> 00:03:27,274
when the captured window
is being resized, occluded,

56
00:03:27,274 --> 00:03:30,677
moved off-screen, or minimized.

57
00:03:30,677 --> 00:03:34,347
You will also learn
how to use per-frame metadata

58
00:03:34,347 --> 00:03:38,318
and how to properly display
the captured window.

59
00:03:38,318 --> 00:03:40,287
Let's dive in.

60
00:03:40,287 --> 00:03:43,523
To capture a single window
that's independent

61
00:03:43,523 --> 00:03:45,926
of which display it's on,

62
00:03:45,926 --> 00:03:49,362
you can start by using
a single window filter

63
00:03:49,362 --> 00:03:54,201
and initialize the filter
with just one window.

64
00:03:54,201 --> 00:03:55,902
In the example here,

65
00:03:55,902 --> 00:04:01,341
the filter is configured to
include a single Safari window.

66
00:04:01,341 --> 00:04:06,346
The video output includes just
that window and nothing else.

67
00:04:06,346 --> 00:04:10,150
No child, pop-up,
or other windows from Safari

68
00:04:10,150 --> 00:04:13,186
will be included.

69
00:04:13,186 --> 00:04:17,157
ScreenCaptureKit's audio capture
policy on the other hand

70
00:04:17,157 --> 00:04:20,594
always works at the app level.

71
00:04:20,594 --> 00:04:23,730
When a single window filter
is used,

72
00:04:23,730 --> 00:04:26,800
all the audio content
from the application

73
00:04:26,800 --> 00:04:30,504
that contains the window
will be captured,

74
00:04:30,504 --> 00:04:36,877
even from those windows that are
not present in the video output.

75
00:04:36,877 --> 00:04:40,447
Now let's take a look
at the code sample.

76
00:04:40,447 --> 00:04:43,717
To create a stream
with a single window,

77
00:04:43,717 --> 00:04:47,154
start by getting
all available content to share

78
00:04:47,154 --> 00:04:50,457
via SCShareableContent.

79
00:04:50,457 --> 00:04:55,462
Next, get the window you want
to share from SCShareableContent

80
00:04:55,462 --> 00:04:58,865
by matching the windowID.

81
00:04:58,865 --> 00:05:03,170
Then, create a SCContentFilter
with the type

82
00:05:03,170 --> 00:05:08,575
desktopIndependentWindow
with the specified SCWindow.

83
00:05:08,575 --> 00:05:12,045
You can further configure
the stream to include audio

84
00:05:12,045 --> 00:05:15,382
as part of the stream output.

85
00:05:15,382 --> 00:05:18,051
Now you are ready
to create a stream

86
00:05:18,051 --> 00:05:21,755
with contentFilter
and streamConfig.

87
00:05:21,755 --> 00:05:27,227
You can then add a StreamOutput
and start the stream.

88
00:05:27,227 --> 00:05:31,965
Let's take a look
at the stream output next.

89
00:05:31,965 --> 00:05:36,536
In the example here, the source
display is on the left

90
00:05:36,536 --> 00:05:40,473
and the stream output
is on the right.

91
00:05:40,473 --> 00:05:45,579
The stream filter includes
a single Safari window.

92
00:05:45,579 --> 00:05:49,216
Now I am going to start
to scroll the Safari window

93
00:05:49,216 --> 00:05:52,118
that's being captured.

94
00:05:52,118 --> 00:05:55,055
The stream output includes
the live content

95
00:05:55,055 --> 00:05:57,257
from the single Safari window

96
00:05:57,257 --> 00:06:02,162
and is updating at the same
cadence as the source window,

97
00:06:02,162 --> 00:06:06,199
up to the source display's
native frame rate.

98
00:06:06,199 --> 00:06:10,437
For example, when the source
window is constantly updating

99
00:06:10,437 --> 00:06:14,574
on a 120Hz display,
the stream output

100
00:06:14,574 --> 00:06:20,347
can also achieve
up to 120 fps update.

101
00:06:20,347 --> 00:06:24,551
You might wonder what happens
when the window resizes.

102
00:06:24,551 --> 00:06:27,554
Please keep in mind
that frequently changing

103
00:06:27,554 --> 00:06:29,556
the stream's output dimension

104
00:06:29,556 --> 00:06:32,892
can lead to additional
memory allocation

105
00:06:32,892 --> 00:06:36,029
and therefore not recommended.

106
00:06:36,029 --> 00:06:40,333
The stream's output dimension
is mostly fixed

107
00:06:40,333 --> 00:06:44,337
and it does not resize
with the source window.

108
00:06:44,337 --> 00:06:47,440
Now let me start to resize
the source window

109
00:06:47,440 --> 00:06:51,778
and see what happens
to the stream's output.

110
00:06:51,778 --> 00:06:55,715
ScreenCaptureKit always
performs hardware scaling

111
00:06:55,715 --> 00:07:00,253
on the captured window so it
never exceeds the frame output

112
00:07:00,253 --> 00:07:03,490
as the source window resizes.

113
00:07:03,490 --> 00:07:07,861
How about windows that are
covered by other windows?

114
00:07:07,861 --> 00:07:12,799
When the source window is
occluded or partially occluded,

115
00:07:12,799 --> 00:07:15,302
the stream output
always includes

116
00:07:15,302 --> 00:07:19,105
the window's full content.

117
00:07:19,105 --> 00:07:21,508
And this also applies
to the case

118
00:07:21,508 --> 00:07:24,377
when the window
is completely off-screen

119
00:07:24,377 --> 00:07:28,515
or moved to other displays.

120
00:07:28,515 --> 00:07:33,119
And for minimized windows, when
the source window is minimized,

121
00:07:33,119 --> 00:07:36,623
the stream output is paused,

122
00:07:36,623 --> 00:07:41,828
and it resumes when the source
window is no longer minimized.

123
00:07:41,828 --> 00:07:45,365
Next, let's move
to audio output.

124
00:07:45,365 --> 00:07:47,233
In this example here,

125
00:07:47,233 --> 00:07:50,837
there are two Safari windows
with audio tracks,

126
00:07:50,837 --> 00:07:55,141
and the window on the left
is being captured.

127
00:07:55,141 --> 00:07:59,112
The video output includes
just the first window,

128
00:07:59,112 --> 00:08:01,948
and the audio tracks
from both Safari windows

129
00:08:01,948 --> 00:08:05,352
will be included
in the audio output.

130
00:08:05,352 --> 00:08:07,921
Let's take a look and listen.

131
00:08:07,921 --> 00:08:12,892
♪ Electronic dance music ♪

132
00:08:12,892 --> 00:08:16,429
Chef: And I wrote down
my favorite guacamole recipe.

133
00:08:16,429 --> 00:08:19,165
It calls for four avocados. 

134
00:08:19,165 --> 00:08:21,167
Meng: With the stream
up and running,

135
00:08:21,167 --> 00:08:23,870
your app receives a frame update

136
00:08:23,870 --> 00:08:27,774
whenever there's
a new frame available.

137
00:08:27,774 --> 00:08:30,910
The frame's output
includes IOSurface

138
00:08:30,910 --> 00:08:36,516
representing the captured frame
and the per-frame metadata.

139
00:08:36,516 --> 00:08:42,088
I'd like to spend some time
talking about metadata.

140
00:08:42,088 --> 00:08:45,024
I am going to show you
examples of metadata

141
00:08:45,024 --> 00:08:48,495
that can be quite useful
for your app.

142
00:08:48,495 --> 00:08:54,267
And these include dirty rects,
content rect,

143
00:08:54,267 --> 00:08:58,738
content scale, and scale factor.

144
00:08:58,738 --> 00:09:01,207
Let's start with dirty rects.

145
00:09:01,207 --> 00:09:04,477
Dirty rects indicate
where the new content is

146
00:09:04,477 --> 00:09:06,913
from the previous frame.

147
00:09:06,913 --> 00:09:11,017
In the example here, the dirty
rects are being highlighted

148
00:09:11,017 --> 00:09:15,655
to illustrate the regions
of frame updates.

149
00:09:15,655 --> 00:09:19,325
Instead of always
encoding the entire frame,

150
00:09:19,325 --> 00:09:23,663
or calculate the delta between
two frames in the encoder,

151
00:09:23,663 --> 00:09:27,534
you can simply use
dirty rects to only encode

152
00:09:27,534 --> 00:09:30,403
and transmit the regions
with new updates

153
00:09:30,403 --> 00:09:33,640
and copy the updates
onto the previous frame

154
00:09:33,640 --> 00:09:38,645
on the receiver side
to generate a new frame.

155
00:09:38,645 --> 00:09:43,082
Dirty rects can be retrieved
from the output CMSampleBuffer's

156
00:09:43,082 --> 00:09:49,589
metadata dictionary
using the matching key.

157
00:09:49,589 --> 00:09:54,928
Now let's move to content rect
and the content scale.

158
00:09:54,928 --> 00:09:58,932
The source window to be captured
is on the left

159
00:09:58,932 --> 00:10:02,735
and the stream output
is on the right.

160
00:10:02,735 --> 00:10:05,438
Since a window can be resized,

161
00:10:05,438 --> 00:10:08,775
the source window's
native backing surface size

162
00:10:08,775 --> 00:10:13,079
often doesn't match
the stream output's dimension.

163
00:10:13,079 --> 00:10:16,716
In the example here,
the captured window has

164
00:10:16,716 --> 00:10:22,655
different aspect ratio from the
frame's output and is bigger.

165
00:10:22,655 --> 00:10:29,195
The captured window is scaled
down to fit into the output.

166
00:10:29,195 --> 00:10:33,466
A content rect, which is
highlighted in green here,

167
00:10:33,466 --> 00:10:37,537
indicates the region of interest
of the captured content

168
00:10:37,537 --> 00:10:40,306
on the stream output.

169
00:10:40,306 --> 00:10:44,077
And the content scale
indicates how much the content

170
00:10:44,077 --> 00:10:46,746
is scaled to fit.

171
00:10:46,746 --> 00:10:50,517
Here the captured Safari window
is scaled down

172
00:10:50,517 --> 00:10:55,421
by 0.77 to fit inside the frame.

173
00:10:55,421 --> 00:10:58,491
Now you can use the metadata
just discussed

174
00:10:58,491 --> 00:11:01,294
to correctly display
the captured window

175
00:11:01,294 --> 00:11:06,032
as close to its native
appearance as possible.

176
00:11:06,032 --> 00:11:10,770
First, let's start by cropping
the content from its output

177
00:11:10,770 --> 00:11:13,940
using the content rect.

178
00:11:13,940 --> 00:11:20,613
Next, scale the content back up
by dividing the content scale.

179
00:11:20,613 --> 00:11:24,884
Now the captured content
is scaled to match one-to-one

180
00:11:24,884 --> 00:11:28,054
in pixel size
as the source window.

181
00:11:28,054 --> 00:11:30,623
But how is the captured window
going to look

182
00:11:30,623 --> 00:11:33,560
on the target display?

183
00:11:33,560 --> 00:11:36,696
To answer that question,
I would like to start

184
00:11:36,696 --> 00:11:40,466
by describing
how scale factor works.

185
00:11:40,466 --> 00:11:44,537
A display's scale factor
indicates the scale ratio

186
00:11:44,537 --> 00:11:48,274
between a display
or window's logical point size

187
00:11:48,274 --> 00:11:53,112
and its backing surface's
pixel size.

188
00:11:53,112 --> 00:11:59,152
A scale factor 2, or a 2x mode,
means every one point onscreen

189
00:11:59,152 --> 00:12:03,623
equals four pixels
on the backing surface.

190
00:12:03,623 --> 00:12:06,793
A window can be moved
from a Retina display

191
00:12:06,793 --> 00:12:11,397
with scale factor 2,
such as in the example here,

192
00:12:11,397 --> 00:12:14,701
to a non-Retina display
with scale factor 1

193
00:12:14,701 --> 00:12:17,403
while being captured.

194
00:12:17,403 --> 00:12:22,275
With scale factor 1,
each one logical point onscreen

195
00:12:22,275 --> 00:12:26,713
corresponds to one pixel
on the backing surface.

196
00:12:26,713 --> 00:12:29,649
In addition,
the source display might have

197
00:12:29,649 --> 00:12:33,219
mismatched scale factor
from the target display

198
00:12:33,219 --> 00:12:38,324
where the captured content
will be displayed.

199
00:12:38,324 --> 00:12:41,894
In this example,
a window is being captured

200
00:12:41,894 --> 00:12:47,033
from a Retina display on
the left with a scale factor 2

201
00:12:47,033 --> 00:12:52,238
and to be displayed on a
non-Retina display on the right.

202
00:12:52,238 --> 00:12:56,609
If the captured window is
displayed as-is without scaling

203
00:12:56,609 --> 00:12:58,878
on the target
non-Retina display

204
00:12:58,878 --> 00:13:01,848
with one point
to one pixel mapping,

205
00:13:01,848 --> 00:13:06,119
the window will look
four times as big.

206
00:13:06,119 --> 00:13:09,956
To fix this, you should
always check the scale factor

207
00:13:09,956 --> 00:13:13,826
from the frame's metadata
against the scale factor

208
00:13:13,826 --> 00:13:16,663
of the target display.

209
00:13:16,663 --> 00:13:21,067
When there's a mismatch, scale
the size of the captured content

210
00:13:21,067 --> 00:13:24,871
by the scale factor
before displaying it.

211
00:13:24,871 --> 00:13:29,242
After scaling, the captured
window on the target display

212
00:13:29,242 --> 00:13:34,914
now appears to be the same size
as its source window.

213
00:13:34,914 --> 00:13:37,350
Now let's take a look
at the code,

214
00:13:37,350 --> 00:13:39,686
and it's quite simple.

215
00:13:39,686 --> 00:13:44,490
Content rect, content scale,
and scale factor

216
00:13:44,490 --> 00:13:48,561
can also be retrieved from
the output CMSampleBuffer's

217
00:13:48,561 --> 00:13:51,097
metadata attachment.

218
00:13:51,097 --> 00:13:53,733
You can then use these metadata

219
00:13:53,733 --> 00:14:00,740
to crop and scale the captured
content to display it correctly.

220
00:14:00,740 --> 00:14:03,743
To recap, a single window filter

221
00:14:03,743 --> 00:14:06,713
always includes
full window content

222
00:14:06,713 --> 00:14:11,084
even when the source window
is off-screen or occluded.

223
00:14:11,084 --> 00:14:14,821
It's display
and space independent.

224
00:14:14,821 --> 00:14:20,293
The output is always offset
at the top-left corner.

225
00:14:20,293 --> 00:14:25,031
Pop-up or child windows
are not included.

226
00:14:25,031 --> 00:14:29,736
Consider using metadata
to best display the content.

227
00:14:29,736 --> 00:14:35,842
And the audio includes tracks
from the entire containing app.

228
00:14:35,842 --> 00:14:38,745
Now that you have just learned
about how to capture

229
00:14:38,745 --> 00:14:41,180
and display a single window,

230
00:14:41,180 --> 00:14:46,519
let me move to the next class of
display-based content filters.

231
00:14:46,519 --> 00:14:48,488
In this next example,

232
00:14:48,488 --> 00:14:51,290
you will learn to create
a display-based filter

233
00:14:51,290 --> 00:14:55,194
with windows or apps,
and I will demonstrate

234
00:14:55,194 --> 00:15:00,099
some differences between video-
and audio-filtering rules.

235
00:15:00,099 --> 00:15:04,670
A display-based inclusion filter
specifies which display

236
00:15:04,670 --> 00:15:07,406
you want to capture
content from.

237
00:15:07,406 --> 00:15:11,878
By default,
no windows are captured.

238
00:15:11,878 --> 00:15:15,882
You can choose the content
you want to capture by window.

239
00:15:15,882 --> 00:15:20,486
In the example here, a Safari
window and a Keynote window

240
00:15:20,486 --> 00:15:23,389
are added to the display filter.

241
00:15:23,389 --> 00:15:27,226
The video output includes
just these two windows

242
00:15:27,226 --> 00:15:29,295
placed in a display space

243
00:15:29,295 --> 00:15:32,865
and the audio output
includes all the soundtracks

244
00:15:32,865 --> 00:15:37,170
from Keynote and Safari apps.

245
00:15:37,170 --> 00:15:40,206
This code sample demonstrates
how to create

246
00:15:40,206 --> 00:15:44,443
display-based filters
with included windows.

247
00:15:44,443 --> 00:15:48,014
Start by creating a list
of SCWindows

248
00:15:48,014 --> 00:15:52,351
using SCShareableContent
and windowIDs.

249
00:15:52,351 --> 00:15:56,789
And then, create
a display-based SCContentFilter

250
00:15:56,789 --> 00:16:01,494
with a given display
and a list of included windows.

251
00:16:01,494 --> 00:16:03,729
You can then create a stream

252
00:16:03,729 --> 00:16:07,200
using the filter and
configuration in the same way

253
00:16:07,200 --> 00:16:13,172
as a desktop independent
window and start the stream.

254
00:16:13,172 --> 00:16:15,274
With the stream up and running,

255
00:16:15,274 --> 00:16:18,644
let's take a look
at the stream's output.

256
00:16:18,644 --> 00:16:22,849
The filter is configured
to include two Safari windows,

257
00:16:22,849 --> 00:16:26,185
menu bar, and wallpaper windows.

258
00:16:30,356 --> 00:16:32,959
If a window is moved off-screen,

259
00:16:32,959 --> 00:16:37,363
it will be removed
from the stream output.

260
00:16:37,363 --> 00:16:40,800
When a new Safari window
is created,

261
00:16:40,800 --> 00:16:44,170
the new window doesn't show up
in the stream output

262
00:16:44,170 --> 00:16:48,040
because the new window
is not in the filter.

263
00:16:48,040 --> 00:16:52,111
The same rule also applies
to child or pop-up windows,

264
00:16:52,111 --> 00:16:56,315
which do not show up
in the stream's output.

265
00:16:56,315 --> 00:16:59,018
If you want to ensure
that child windows

266
00:16:59,018 --> 00:17:02,889
are included automatically
in your stream output,

267
00:17:02,889 --> 00:17:07,960
you can use a display-based
filter with included apps.

268
00:17:07,960 --> 00:17:12,231
In this example, adding
the Safari and Keynote apps

269
00:17:12,231 --> 00:17:16,736
to the filter ensures that
the audio and video output

270
00:17:16,736 --> 00:17:20,506
from all the windows and
soundtracks from these two apps

271
00:17:20,506 --> 00:17:24,010
are included in the output

272
00:17:24,010 --> 00:17:27,446
Window exception filters
are a powerful way

273
00:17:27,446 --> 00:17:31,117
of excluding specific windows
from your output

274
00:17:31,117 --> 00:17:36,389
when the filter is specified
as a display with included apps.

275
00:17:36,389 --> 00:17:39,392
For example,
a single Safari window

276
00:17:39,392 --> 00:17:42,328
is removed from the output.

277
00:17:42,328 --> 00:17:47,533
ScreenCaptureKit enables
audio capture at the app level,

278
00:17:47,533 --> 00:17:51,570
so excluding audio
from a single Safari window

279
00:17:51,570 --> 00:17:54,740
is the equivalent
to removing audio tracks

280
00:17:54,740 --> 00:17:57,877
for all Safari apps.

281
00:17:57,877 --> 00:18:00,479
Although the stream's
video output

282
00:18:00,479 --> 00:18:03,916
still includes a Safari window,

283
00:18:03,916 --> 00:18:07,987
all the sound tracks
from Safari apps are removed

284
00:18:07,987 --> 00:18:11,490
and the audio output
includes just the soundtrack

285
00:18:11,490 --> 00:18:13,259
from Keynote.

286
00:18:13,259 --> 00:18:17,797
In the code example here,
we change the SCContentFilter

287
00:18:17,797 --> 00:18:21,067
to include a list of
SCRunningApplications

288
00:18:21,067 --> 00:18:23,636
instead of SCWindows.

289
00:18:23,636 --> 00:18:27,807
If there are individual windows
you want to further exclude,

290
00:18:27,807 --> 00:18:33,612
build a list of SCWindows and
then create an SCContentFilter

291
00:18:33,612 --> 00:18:36,615
using the list of SCApplications

292
00:18:36,615 --> 00:18:41,954
with the list of excepting
windows to exclude.

293
00:18:41,954 --> 00:18:45,725
Let's take a look at what the
stream output looks like now

294
00:18:45,725 --> 00:18:48,694
when new or child windows
are created

295
00:18:48,694 --> 00:18:51,964
by specifying included apps.

296
00:18:51,964 --> 00:18:58,070
This time, Safari app and system
windows are added to the filter.

297
00:18:58,070 --> 00:19:02,308
A new Safari window
is now automatically included

298
00:19:02,308 --> 00:19:05,711
in the stream output
and the same rule applies

299
00:19:05,711 --> 00:19:08,881
to child and pop-up windows.

300
00:19:08,881 --> 00:19:12,651
This can be quite useful
when you are doing a tutorial

301
00:19:12,651 --> 00:19:15,621
and want to demonstrate
the full action

302
00:19:15,621 --> 00:19:19,925
including invoking pop-up
or new windows.

303
00:19:19,925 --> 00:19:22,895
I have just demonstrated
how to add content

304
00:19:22,895 --> 00:19:26,632
to the stream output
through a few different ways.

305
00:19:26,632 --> 00:19:28,300
My next example will show you

306
00:19:28,300 --> 00:19:32,938
how to remove content
from the stream output.

307
00:19:32,938 --> 00:19:35,608
This example
includes a test app

308
00:19:35,608 --> 00:19:38,611
that emulates
a video conferencing app

309
00:19:38,611 --> 00:19:43,382
that contains a preview
of the display being shared.

310
00:19:43,382 --> 00:19:47,953
Because the test app recursively
shows itself in the preview,

311
00:19:47,953 --> 00:19:52,758
it's creating the so-called
mirror hall effect.

312
00:19:52,758 --> 00:19:56,595
Even during full display share,
it's common for screen sharing

313
00:19:56,595 --> 00:20:01,434
applications to remove its
own windows, capture preview,

314
00:20:01,434 --> 00:20:05,905
participant camera view
to avoid the mirror hall effect,

315
00:20:05,905 --> 00:20:10,910
or other system UIs
such as notification windows.

316
00:20:10,910 --> 00:20:13,079
ScreenCaptureKit provides you

317
00:20:13,079 --> 00:20:17,116
with a set of exclusion-based
filters that allow you

318
00:20:17,116 --> 00:20:21,153
to quickly remove content
from display capture.

319
00:20:21,153 --> 00:20:25,357
An exclusion-based display
filter captures all the windows

320
00:20:25,357 --> 00:20:28,427
from the given display
by default.

321
00:20:28,427 --> 00:20:32,431
You can then start to remove
individual windows or apps

322
00:20:32,431 --> 00:20:35,968
by adding them
to the exclusion filter.

323
00:20:35,968 --> 00:20:40,306
For example, you can add
the content capture test app

324
00:20:40,306 --> 00:20:46,846
and Notification Center to the
list of excluded applications.

325
00:20:46,846 --> 00:20:49,315
To create
a display-based filter

326
00:20:49,315 --> 00:20:52,384
excluding a list
of applications,

327
00:20:52,384 --> 00:20:56,489
start by retrieving
SCApplications to exclude

328
00:20:56,489 --> 00:20:59,058
by matching bundle ID.

329
00:20:59,058 --> 00:21:02,328
If there are individual windows
you'd like to cherry-pick

330
00:21:02,328 --> 00:21:05,831
back to the stream output,
you can also build

331
00:21:05,831 --> 00:21:10,302
an optional list of
excepting SCWindows.

332
00:21:10,302 --> 00:21:13,606
And then use a given display,

333
00:21:13,606 --> 00:21:16,742
the list of applications
to exclude,

334
00:21:16,742 --> 00:21:22,848
and a list of excepting windows
to create the content filter.

335
00:21:22,848 --> 00:21:26,285
Let's take a look at the result.

336
00:21:26,285 --> 00:21:28,954
The content capture
test app that's causing

337
00:21:28,954 --> 00:21:32,892
the mirror hall problem
and the notification windows

338
00:21:32,892 --> 00:21:36,295
are both removed
from the stream output.

339
00:21:36,295 --> 00:21:38,964
New or child windows
from these apps

340
00:21:38,964 --> 00:21:43,135
will be automatically
removed as well.

341
00:21:43,135 --> 00:21:46,639
If these removed apps
include any audio,

342
00:21:46,639 --> 00:21:50,876
their audio will be removed
from the audio output.

343
00:21:50,876 --> 00:21:54,246
We've just seen how
to capture a single window,

344
00:21:54,246 --> 00:21:58,417
how to add and remove windows
from a display filter.

345
00:21:58,417 --> 00:22:02,288
Let's move
to stream configuration next.

346
00:22:02,288 --> 00:22:05,558
In the next few examples,
you will learn about

347
00:22:05,558 --> 00:22:09,161
different stream properties
you can configure,

348
00:22:09,161 --> 00:22:13,465
how to set up the stream for
screen capture and streaming,

349
00:22:13,465 --> 00:22:18,204
and how to build a window picker
with live preview.

350
00:22:18,204 --> 00:22:22,241
Let's start with
configuration properties.

351
00:22:22,241 --> 00:22:25,211
These are some of
the common stream properties

352
00:22:25,211 --> 00:22:30,649
you can configure, such as
stream output dimensions,

353
00:22:30,649 --> 00:22:33,452
source and destination rects,

354
00:22:33,452 --> 00:22:38,557
color space, color matrix,
and pixel format,

355
00:22:38,557 --> 00:22:43,362
whether to include cursor,
and frame rate control.

356
00:22:43,362 --> 00:22:48,601
We will take a look at each
property in details next.

357
00:22:48,601 --> 00:22:51,237
Let's start
with output dimension,

358
00:22:51,237 --> 00:22:56,508
which can be specified
as width and height in pixels.

359
00:22:56,508 --> 00:22:59,845
The source display's dimension
and aspect ratio

360
00:22:59,845 --> 00:23:04,316
doesn't always match
the output dimension.

361
00:23:04,316 --> 00:23:08,554
And when this mismatch happens
while capturing a full display,

362
00:23:08,554 --> 00:23:13,659
there will be pillar or
letterbox in the stream output.

363
00:23:13,659 --> 00:23:17,830
You can also specify a source
rect that defines the region

364
00:23:17,830 --> 00:23:22,334
to capture from and the result
will be rendered and scaled

365
00:23:22,334 --> 00:23:26,472
to the destination rect
on the frame output.

366
00:23:26,472 --> 00:23:30,342
ScreenCaptureKit supports
hardware accelerated

367
00:23:30,342 --> 00:23:36,248
color space, color matrix,
and pixel format conversion.

368
00:23:36,248 --> 00:23:41,120
Common BGRA and YUV formats
are supported.

369
00:23:41,120 --> 00:23:46,458
Please visit our developer page
for the full list.

370
00:23:46,458 --> 00:23:50,829
When show cursor is enabled,
the stream output includes

371
00:23:50,829 --> 00:23:54,466
a cursor prerendered
into the frame.

372
00:23:54,466 --> 00:23:57,469
This applies
to all system cursors,

373
00:23:57,469 --> 00:24:02,374
even custom cursor like
the camera-shaped one here.

374
00:24:02,374 --> 00:24:04,943
You can use
minimum frame interval

375
00:24:04,943 --> 00:24:08,347
to control desired
output frame rate.

376
00:24:08,347 --> 00:24:12,685
For example,
when requesting 60 fps,

377
00:24:12,685 --> 00:24:16,655
set the minimal interval
to 1/60.

378
00:24:16,655 --> 00:24:21,393
You will receive frame update
no more than 60 fps,

379
00:24:21,393 --> 00:24:26,432
and no more than
the content's native frame rate.

380
00:24:26,432 --> 00:24:29,335
Queue depth can be specified
to determine

381
00:24:29,335 --> 00:24:34,340
the number of surfaces
in the server-side surface pool.

382
00:24:34,340 --> 00:24:38,444
More surfaces in the pool
can lead to better frame rate

383
00:24:38,444 --> 00:24:43,816
and performance, but it results
in higher system memory usage

384
00:24:43,816 --> 00:24:47,286
and potentially
a latency trade-off,

385
00:24:47,286 --> 00:24:50,956
which I will discuss
in more details later.

386
00:24:50,956 --> 00:24:54,293
ScreenCaptureKit accepts
queue depth range between

387
00:24:54,293 --> 00:24:59,531
three to eight with a default
queue depth of three.

388
00:24:59,531 --> 00:25:03,535
In this example here,
the surface pool is configured

389
00:25:03,535 --> 00:25:07,473
to include four surfaces
available for ScreenCaptureKit

390
00:25:07,473 --> 00:25:09,608
to render to.

391
00:25:09,608 --> 00:25:13,612
The current active surface
is surface 1

392
00:25:13,612 --> 00:25:19,118
and ScreenCaptureKit is
rendering the next frame to it.

393
00:25:19,118 --> 00:25:22,254
Once surface 1 is complete,

394
00:25:22,254 --> 00:25:26,825
ScreenCaptureKit sends
surface 1 to your app.

395
00:25:26,825 --> 00:25:30,529
Your app is processing
and holding surface 1,

396
00:25:30,529 --> 00:25:35,033
while ScreenCaptureKit
is rendering to surface 2.

397
00:25:35,033 --> 00:25:39,371
Surface 1 is now marked
as unavailable in the pool

398
00:25:39,371 --> 00:25:43,242
since your app
is still using it.

399
00:25:43,242 --> 00:25:47,479
When surface 2 is complete,
it's sent to your app

400
00:25:47,479 --> 00:25:51,884
and ScreenCaptureKit
now renders to surface 3.

401
00:25:51,884 --> 00:25:55,654
But if your app is still
processing surface 1,

402
00:25:55,654 --> 00:25:59,591
it will start to fall behind
as frames are now provided

403
00:25:59,591 --> 00:26:03,362
faster than they
can be processed.

404
00:26:03,362 --> 00:26:07,866
If the surface pool contains
a large number of surfaces,

405
00:26:07,866 --> 00:26:10,402
new surfaces
will start to pile up

406
00:26:10,402 --> 00:26:13,105
and you might need to consider
starting to drop frames

407
00:26:13,105 --> 00:26:15,541
in order to keep up.

408
00:26:15,541 --> 00:26:18,877
In this case,
more surfaces in the pool

409
00:26:18,877 --> 00:26:22,948
can potentially lead
to higher latency.

410
00:26:22,948 --> 00:26:25,784
The number of surfaces
left in the pool

411
00:26:25,784 --> 00:26:29,788
for ScreenCaptureKit to use,
equals the queue depth

412
00:26:29,788 --> 00:26:34,493
minus the number of surfaces
held by your app.

413
00:26:34,493 --> 00:26:36,061
In the example here,

414
00:26:36,061 --> 00:26:40,199
both surface 1 and 2
are still held by your app.

415
00:26:40,199 --> 00:26:45,037
There are 2 surfaces
left in the surface pool.

416
00:26:45,037 --> 00:26:49,041
After surface 3 is complete
and is sent to your app,

417
00:26:49,041 --> 00:26:54,146
the only available surface
left in the pool is surface 4.

418
00:26:54,146 --> 00:26:59,718
If your app continues to hold
on to surface 1, 2, and 3,

419
00:26:59,718 --> 00:27:04,089
ScreenCaptureKit will soon
run out of surfaces to render to

420
00:27:04,089 --> 00:27:07,659
and you will start to see
frame loss and glitch.

421
00:27:07,659 --> 00:27:11,296
Your app needs to finish
and release surface 1

422
00:27:11,296 --> 00:27:14,800
before ScreenCaptureKit starts
to render the next frame

423
00:27:14,800 --> 00:27:20,472
after surface 4
in order to avoid frame loss.

424
00:27:20,472 --> 00:27:24,109
Now your app releases
surface 1 and it's available

425
00:27:24,109 --> 00:27:27,679
for ScreenCaptureKit
to use again.

426
00:27:27,679 --> 00:27:31,116
To recap: there are two rules
your app needs to follow

427
00:27:31,116 --> 00:27:35,420
in order avoid frame latency
and frame loss.

428
00:27:35,420 --> 00:27:38,690
To avoid delayed frame,
you need to be able to process

429
00:27:38,690 --> 00:27:42,528
a frame within
the MinimumFrameInterval.

430
00:27:42,528 --> 00:27:45,864
To avoid frame loss,
the time it takes your app

431
00:27:45,864 --> 00:27:50,202
to release the surfaces back
to the pool must be less than

432
00:27:50,202 --> 00:27:55,107
MinimumFrameInterval
times QueueDepth minus 1,

433
00:27:55,107 --> 00:28:00,212
after which ScreenCaptureKit
runs out of surfaces to use,

434
00:28:00,212 --> 00:28:04,716
enters a stall, and will
start to miss new frames.

435
00:28:04,716 --> 00:28:07,052
Now that you've seen
the various properties

436
00:28:07,052 --> 00:28:10,989
you can configure,
let's dive into some examples

437
00:28:10,989 --> 00:28:15,727
to configure the stream for
screen capture and streaming.

438
00:28:15,727 --> 00:28:19,598
Some screen content
includes videos, games,

439
00:28:19,598 --> 00:28:22,768
or animations that
are constantly updating

440
00:28:22,768 --> 00:28:26,204
and that requires
higher frame rate.

441
00:28:26,204 --> 00:28:30,108
While others include
mostly static text

442
00:28:30,108 --> 00:28:32,110
like the keynote window,

443
00:28:32,110 --> 00:28:36,815
which prioritize higher
resolution over frame rate,

444
00:28:36,815 --> 00:28:40,786
you can live-adjust the
stream's configuration based on

445
00:28:40,786 --> 00:28:45,857
the content being shared
and the networking condition.

446
00:28:45,857 --> 00:28:48,694
In this code example,
you are going to see

447
00:28:48,694 --> 00:28:55,300
how to configure the capture
to stream 4K, 60-fps game.

448
00:28:55,300 --> 00:28:58,470
You can start by setting
the stream output dimension

449
00:28:58,470 --> 00:29:01,106
to 4K in pixel size.

450
00:29:01,106 --> 00:29:06,211
And then, set the output
frame rate to 60 fps

451
00:29:06,211 --> 00:29:10,916
by setting the minimum
frame interval to 1/60.

452
00:29:10,916 --> 00:29:18,323
Next, use pixel format YUV420
for encoding and streaming.

453
00:29:18,323 --> 00:29:20,258
Set the optional source rect

454
00:29:20,258 --> 00:29:25,230
to just capture
a portion of the screen.

455
00:29:25,230 --> 00:29:29,101
Next, change the background
fill color to black,

456
00:29:29,101 --> 00:29:33,372
and then include a cursor
in the frame output.

457
00:29:33,372 --> 00:29:37,542
Configure surface queue depth
to five for optimal frame rate

458
00:29:37,542 --> 00:29:39,778
and performance.

459
00:29:39,778 --> 00:29:45,450
Last, enable audio
on the output stream.

460
00:29:45,450 --> 00:29:48,587
All the stream configurations
you've just seen

461
00:29:48,587 --> 00:29:52,791
in the previous example can be
dynamically changed on the fly

462
00:29:52,791 --> 00:29:55,193
without recreating the stream.

463
00:29:55,193 --> 00:29:59,464
For example, you can live adjust
some properties such as

464
00:29:59,464 --> 00:30:04,302
output dimension, dynamically
change the frame rate,

465
00:30:04,302 --> 00:30:07,472
and update stream filters.

466
00:30:07,472 --> 00:30:10,842
Here's an example to switch
the output dimension

467
00:30:10,842 --> 00:30:14,413
from 4K down to 720p.

468
00:30:14,413 --> 00:30:21,620
And downgrade the frame rate
from 60 fps to 15 fps.

469
00:30:21,620 --> 00:30:25,757
You can then simply call
updateConfiguration

470
00:30:25,757 --> 00:30:28,193
to apply the new settings
on the fly

471
00:30:28,193 --> 00:30:31,530
without interrupting the stream.

472
00:30:31,530 --> 00:30:35,033
In the last example,
I'd like to walk you through

473
00:30:35,033 --> 00:30:39,671
building a window picker
with live preview.

474
00:30:39,671 --> 00:30:41,506
Here is an example

475
00:30:41,506 --> 00:30:45,110
of what a typical window
picker looks like.

476
00:30:45,110 --> 00:30:48,513
It's common for web conferencing
screen sharing apps

477
00:30:48,513 --> 00:30:50,749
to offer users an option

478
00:30:50,749 --> 00:30:55,353
to choose the exact window
to share.

479
00:30:55,353 --> 00:30:58,323
ScreenCaptureKit provides
an efficient

480
00:30:58,323 --> 00:31:02,260
and high-performance solution
to creating large number

481
00:31:02,260 --> 00:31:06,932
of thumbnail-sized streams
with live content update,

482
00:31:06,932 --> 00:31:09,835
and it's simple to implement.

483
00:31:09,835 --> 00:31:12,871
Let's break it down to see
what it takes to build

484
00:31:12,871 --> 00:31:17,008
a window picker like this
using ScreenCaptureKit.

485
00:31:17,008 --> 00:31:20,212
To set up the picker,
you can start by creating

486
00:31:20,212 --> 00:31:23,949
one single window filter
for each eligible window

487
00:31:23,949 --> 00:31:26,952
that your app
allows the user to pick

488
00:31:26,952 --> 00:31:31,890
with desktop independent window
as the filter type.

489
00:31:31,890 --> 00:31:35,127
Next, set up the stream
configuration

490
00:31:35,127 --> 00:31:41,700
that's thumbnail-sized, 5 fps,
with BGRA pixel format

491
00:31:41,700 --> 00:31:48,240
for onscreen display, default
queue depth, no cursor or audio.

492
00:31:48,240 --> 00:31:52,344
Use single window filter and
the stream configuration here

493
00:31:52,344 --> 00:31:57,616
to create one stream
for each window.

494
00:31:57,616 --> 00:32:00,919
To do this in code,
you can start by getting

495
00:32:00,919 --> 00:32:04,623
the SCShareableContent
by excluding desktop

496
00:32:04,623 --> 00:32:07,225
and system windows.

497
00:32:07,225 --> 00:32:10,195
Next, create a content filter

498
00:32:10,195 --> 00:32:16,935
of type desktop independent
window for each eligible window.

499
00:32:16,935 --> 00:32:21,106
Then, move to
the stream configuration part.

500
00:32:21,106 --> 00:32:24,009
Choose an appropriate
thumbnail size --

501
00:32:24,009 --> 00:32:28,647
in this example,
it's 284 by 182 --

502
00:32:28,647 --> 00:32:33,919
and then set the minimum
frame interval to one over five.

503
00:32:33,919 --> 00:32:39,391
With a pixel format of BGRA
for onscreen display,

504
00:32:39,391 --> 00:32:43,361
disable audio and cursor
since we don't need them

505
00:32:43,361 --> 00:32:45,263
in the preview.

506
00:32:45,263 --> 00:32:49,401
And set queue depth to three
because we don't expect updates

507
00:32:49,401 --> 00:32:52,337
that are too often.

508
00:32:52,337 --> 00:32:56,308
With the stream content filter
and the configuration created,

509
00:32:56,308 --> 00:32:59,611
you are now ready
to create the streams.

510
00:32:59,611 --> 00:33:02,914
Create one stream
for each window,

511
00:33:02,914 --> 00:33:06,251
add stream output
for each stream,

512
00:33:06,251 --> 00:33:08,954
and then start the stream.

513
00:33:08,954 --> 00:33:13,925
Last, append it
to the stream list.

514
00:33:13,925 --> 00:33:16,795
This is the window picker
with live preview

515
00:33:16,795 --> 00:33:20,832
created using the sample code
we saw earlier.

516
00:33:20,832 --> 00:33:24,502
Each thumbnail is live updating
and then backed

517
00:33:24,502 --> 00:33:29,474
by an individual stream
with single-window filter.

518
00:33:29,474 --> 00:33:32,677
With ScreenCaptureKit,
you can easily build

519
00:33:32,677 --> 00:33:36,314
a live preview picker like this,
that allows you

520
00:33:36,314 --> 00:33:39,851
to concurrently capture
so much live screen content

521
00:33:39,851 --> 00:33:44,823
simultaneously, without
overburdening the system.

522
00:33:44,823 --> 00:33:47,993
Now let me hand it over
to my colleague, Drew,

523
00:33:47,993 --> 00:33:51,129
who's going to give you
an exciting demo about

524
00:33:51,129 --> 00:33:54,766
OBS adoption
of ScreenCaptureKit.

525
00:33:54,766 --> 00:33:56,268
Drew Mills: Thanks, Meng.

526
00:33:56,268 --> 00:33:59,638
Hi, my name is Drew, and I'm a
Partner Engineer here at Apple.

527
00:33:59,638 --> 00:34:02,607
OBS Studio is an open source
application that allows users

528
00:34:02,607 --> 00:34:04,576
to manage recording
and streaming content

529
00:34:04,576 --> 00:34:05,911
from their computer.

530
00:34:05,911 --> 00:34:08,313
It contains an implementation
of ScreenCaptureKit

531
00:34:08,313 --> 00:34:11,016
that we worked with the project
on integrating this spring.

532
00:34:11,016 --> 00:34:13,885
ScreenCaptureKit was easy
to implement thanks to utilizing

533
00:34:13,885 --> 00:34:18,023
similar code to OBS's existing
CGDisplayStream-based capture.

534
00:34:18,023 --> 00:34:20,292
The ScreenCaptureKit
implementation demonstrates

535
00:34:20,292 --> 00:34:22,060
many of the features discussed

536
00:34:22,060 --> 00:34:24,296
in the "Meet ScreenCaptureKit"
session.

537
00:34:24,296 --> 00:34:26,831
This includes:
capturing an entire desktop,

538
00:34:26,831 --> 00:34:28,700
all of the windows
of an application,

539
00:34:28,700 --> 00:34:30,835
or just one specific window.

540
00:34:30,835 --> 00:34:33,371
ScreenCaptureKit has
lower overhead than OBS's

541
00:34:33,371 --> 00:34:36,441
CGWindowListCreateImage-based
capture.

542
00:34:36,441 --> 00:34:39,210
This means that when capturing
a portion of your screen,

543
00:34:39,210 --> 00:34:41,279
you are left with more
resources that you can use

544
00:34:41,279 --> 00:34:43,081
for producing your content.

545
00:34:43,081 --> 00:34:44,382
Let's dive into a demo

546
00:34:44,382 --> 00:34:46,985
to see what we've
been discussing in action.

547
00:34:46,985 --> 00:34:49,254
On the left, there is
a worst case example

548
00:34:49,254 --> 00:34:51,389
of OBS's Window Capture.

549
00:34:51,389 --> 00:34:55,193
This capture uses the
CGWindowListCreateImage API,

550
00:34:55,193 --> 00:34:56,928
and has significant stuttering.

551
00:34:56,928 --> 00:35:01,533
In our testing, we saw frame
rates dip as low as 7 fps.

552
00:35:01,533 --> 00:35:04,135
Meanwhile, the ScreenCaptureKit
implementation on the right

553
00:35:04,135 --> 00:35:06,938
has a much smoother result,
providing an output video

554
00:35:06,938 --> 00:35:09,374
with significantly
smoother motion.

555
00:35:09,374 --> 00:35:13,912
In this case, delivering 60 fps.

556
00:35:13,912 --> 00:35:16,948
All while OBS uses up
to 15 percent less RAM

557
00:35:16,948 --> 00:35:19,751
than Window Capture.

558
00:35:19,751 --> 00:35:23,755
And while OBS's CPU utilization
is cut by up to half

559
00:35:23,755 --> 00:35:28,660
when using ScreenCaptureKit
instead of OBS's Window Capture.

560
00:35:28,660 --> 00:35:30,395
Let's look at the other
improvements

561
00:35:30,395 --> 00:35:33,498
that ScreenCaptureKit
has to offer OBS users.

562
00:35:33,498 --> 00:35:35,633
I'm still trying to track down
all of the Gold Ranks

563
00:35:35,633 --> 00:35:37,369
in Sayonara Wild Hearts.

564
00:35:37,369 --> 00:35:39,037
I want to show off
my best run,

565
00:35:39,037 --> 00:35:40,939
so I've been
recording my gameplay.

566
00:35:40,939 --> 00:35:43,141
Thanks to ScreenCaptureKit,
I can now capture

567
00:35:43,141 --> 00:35:45,110
direct audio stream
from the game,

568
00:35:45,110 --> 00:35:47,212
so when I get
a notification on my Mac,

569
00:35:47,212 --> 00:35:50,048
it won't ruin my recording's
audio or video.

570
00:35:50,048 --> 00:35:51,583
And this is possible
without having to install

571
00:35:51,583 --> 00:35:54,452
any additional
audio routing software.

572
00:35:54,452 --> 00:35:56,721
♪

573
00:35:56,721 --> 00:35:58,356
Now, using all
of the enhancements

574
00:35:58,356 --> 00:36:00,525
provided by ScreenCaptureKit
on Apple silicon,

575
00:36:00,525 --> 00:36:03,828
I can stream games like
Taiko no Tatsujin Pop Tap Beat

576
00:36:03,828 --> 00:36:06,297
from my Mac to popular
streaming services.

577
00:36:06,297 --> 00:36:08,400
A new constant bitrate option
for Apple silicon's

578
00:36:08,400 --> 00:36:10,435
hardware encoder
means that I can encode

579
00:36:10,435 --> 00:36:12,904
my streaming content
for services requiring constant

580
00:36:12,904 --> 00:36:17,242
bitrate without significantly
impacting my game's performance.

581
00:36:17,242 --> 00:36:19,210
Now, thanks to
ScreenCaptureKit's

582
00:36:19,210 --> 00:36:21,513
lower resource usage
and encoding offloading,

583
00:36:21,513 --> 00:36:23,314
I have even more
performance available

584
00:36:23,314 --> 00:36:24,816
for the content that matters.

585
00:36:24,816 --> 00:36:25,884
Back to you, Meng.

586
00:36:25,884 --> 00:36:28,053
Meng: Thank you, Drew.

587
00:36:28,053 --> 00:36:30,588
Through the demos and examples,

588
00:36:30,588 --> 00:36:34,159
you learned about advanced
screen content filters.

589
00:36:34,159 --> 00:36:38,563
Several ways to configure the
stream for different use cases.

590
00:36:38,563 --> 00:36:42,767
And how to use per-frame
metadata and correctly display

591
00:36:42,767 --> 00:36:44,903
the captured content.

592
00:36:44,903 --> 00:36:49,741
Some best practices to help you
achieve best performance.

593
00:36:49,741 --> 00:36:54,746
And finally, Drew showcased
the significant capability

594
00:36:54,746 --> 00:36:59,884
and performance improvement
ScreenCaptureKit brought to OBS.

595
00:36:59,884 --> 00:37:03,121
I can't wait to see
how you redefine your app's

596
00:37:03,121 --> 00:37:07,192
screen sharing, streaming,
and collaboration experience

597
00:37:07,192 --> 00:37:09,461
using ScreenCaptureKit.

598
00:37:09,461 --> 00:37:11,429
Thank you for watching!

599
00:37:11,429 --> 00:37:14,799
♪

